**Abstract**

If you are in any way affiliated with network and virtual infrastructure troubleshooting and monitoring, you're going to like this book. If you're driven crazy by having to overlap multiple tools to get the information needed to troubleshoot an issue in your environment, you're going to love this book.

As the title suggests, this book will give you a deep dive look at VMware's holistic networking and virtual infrastructure monitoring & troubleshooting product; vRealize Network Insight.

Network Insight is famous for a couple reasons:

1.  It has the capability to kickstart your way to a secure segmented network by creating visibility into what actually happens on your network.

2.  It sucks up all the operational and configuration data of your virtual (vSphere, Kubernetes, Bare metal), public cloud (AWS & Azure), SD-WAN, and physical network environment and allows you to overlay the two to create a holistic view of your entire environment and use that to significantly reduce time spent troubleshooting and gathering data from your environment.

3.  Analytics that go over all the data that's pulled into Network Insight, provide a great deal of useful information; from "who is using my applications?", to "are there any abnormalities in the network behavior?", to all the way to "how much is this cloud egress bandwidth costing me?".

You will be guided through the components and architecture of Network Insight and discover hidden gems and secrets throughout the platform. This book will take you from beginner to a vRealize Network Insight Samurai and we'll have some fun along the way!



Introduction -- About the author
================================

As I'm sitting in the airport, waiting for my flight after a team building exercise with the Networking & Security Business Unit within VMware, the thought going through my head is: why? Why on earth are you starting another big project that's going to take up a ton of time? The reason is simple: Hi, I'm Martijn Smit and I'm an information sharing addict (echo's: "hi Martijn!").

I'm proud to be Dutch and proud to be in the industry I'm in. My career started at a hosting company, in which I spent 8 years moving from the webhosting help desk to colocation & dedicated server support, to managing the internet-network and helping to build a new datacenter from the ground up. After leaving this provider, I joined a value-added reseller company, with which I spent 5 years designing and deploying data center infrastructures, including storage, compute, networking and virtualization. I was also in the innovation group that brought the last two together to support virtual networking; Software-Defined Networking (SDN).

I currently work at VMware in Technical Marketing for vRealize Network Insight, as I fully believe in the way Network Insight is approaching Networking & Security troubleshooting and monitoring and want to spread the word. My previous role was to guide customers to the world of virtual networking; NSBU Solutions Engineer. Having said that; don't worry, this book is not going to be a sales pitch but hardcore technical information (just as I like it. ;-)).

Apart from my passion for technology, I believe in a healthy balance and taking care of yourself, so often take 2 to 3-hour bike rides, exercise every day and eat proper food. One of my favorite hobbies is spending time on doing elaborate meals using my Kamado Egg barbecue. I also tear through books and have a goal to read at least 30 books yearly. As mentioned before, I'm an information sharing addict and mostly do so by giving talks and doing technical blogs.

If you would like to see more of my rants, you can follow me on twitter on [\@smitmartijn](https://twitter.com/smitmartijn) or on my blog at <https://lostdomain.org>

Back to this book; so, I have been dealing with the entire data center stack for years. One of the things that always annoyed me was that there was no good solution to troubleshoot and monitor that entire stack; it was always separate solutions for each layer. In 2014, I came across a company called ArkinNet, which had an amazing product which could collect data from multiple layers (storage, compute and networking) and present this data in a holistic way. After doing some due diligence, I immediately started talks to include Arkin into our product portfolio and I've been in love with the product ever since.

Arkin was later acquired in June of 2016 by VMware and it is now known as vRealize Network Insight.

Let's dive in!

P.S: I've written this book on personal title, not as a VMware employee. Any opinions in here are my own and not per se the opinion of VMware.

Syntax(?) to-do
===============

Underlines = links

search query = which can be placed in the Network Insight search engine

Foreword by Shiv Agarwal
========================

*Founder of ArkinNet, currently Vice-President of Network Insight with VMware*

VMware vRealize Network Insight (or vRNI, or Network Insight) has seen a massive adoption in VMware customer base helping our customers get end-to-end visibility and operational simplicity as they embrace a software defined approach to networking and security. Network Insight completes VMware's Virtual Cloud Network vision and story by providing seamlessly visibility and converged network operations across the data center (virtual and physical) and hybrid cloud as well as branch offices and remote sites (via SD-WAN integration).

Jogging down the memory lane, Network Insight came into VMware through the Arkin (ArkinNet) acquisition. As it happens so often in Silicon Valley, my co-founder and I were at VMware before we went out and started Arkin (in 2013). We had joined VMware (in 2008) as part of the Blue Lane acquisition. At Blue Lane, we had built a virtual firewall which became the first-generation virtual firewall (VMware NSX DFW) inside VMware. During our first tenure at VMware (2008-2013), NSX was in its infancy. We saw enterprise customers struggling to operate their virtual networking stack. They were trying to use their existing legacy processes and toolset. Their people's mindset was geared and tuned to managing physical networks. Virtualization was new to the network operators. That's when my cofounder and I got the idea of starting Arkin. You start a company with a big vision, ours was to transform how networks are operated. Idea was to bring consumer grade simplicity to managing networks. We wanted to challenge the status quo. Our first set of use cases was to help customers implement micro-segmentation and operationalize NSX. NSX was becoming the dominant network virtualization stack and we betted on it. We got the first product out in 18 months with some of the marquee NSX customers using it in production and were acquired by VMware in 36 months. At VMware, it was like a match made in heaven. Thanks to the NSX sales team, the two products together (NSX and Network Insight) started flying off the shelf! It's been fun! I tell my team often that the acquisition by VMware was a mere pit stop in our journey, which, at the time of writing this foreword, is still continuing.

We continue to build. Network Insights expanded charter and scope now includes end-to-end network operations - monitoring, troubleshooting and optimization. By combining the different types of network data (flows, packets, metrics, config, streaming, etc.), we have provided a unique platform for our customers to converge their traditionally silo-ed visibility and realize a multitude of use cases around next generation networking and security. We have also created a unique advantage for ourselves by adding a strong application context to network and security dataset. Applications are the lifeline of an enterprise and Network Insight's powerful application discovery and planning feature enables our customers to see their network and security data through the lens of their applications. We are thus elevating IT and empowering them to have a more business-oriented conversation with their line of businesses.

Over the next few years, we see the operational silos breaking at a rapid pace and a lot of automation happening, ultimately leading to self-driving networks. That's the future. Silos create inefficiency and finger pointing. Our vision is to bring a high degree of efficiency in network operations through convergence, consumer grade experience and analytical insights. We continue to deliver upon our vision by investing in new areas. Recently, we acquired a company, Veriflow, which has pioneered the area of network verification in software. This technique is used in many mission critical industries where failure can be catastrophic such as airlines and space. Networking is mission critical for our customers. With this acquisition, we will be arming our customers with network modeling and prediction and significantly push the frontier of network operations in the enterprises.

I am very happy and excited to be writing this foreword for Martijns book on VMware vRealize Network Insight. Martijn has been the technical face and flag bearer of Network Insight in the EMEA region for a long time. I hope the insights captured in his book will trigger in the mind of its readers a genuine thought about transforming their network and security operations.

Pre-face
========

This book is for people in jobs or interests related to networking and security in private, hybrid and/or public clouds. Managing these networks and security policies becomes a much easier job with Network Insight and this book will try to explain best how to go about managing those networks and how Network Insight itself is positioned to do so.

Sometimes it's not all in the name. This is also true for Network Insight, as it gives you not just insight into your network, but your compute, storage and network layers.

With Network Insight, you can take the guesswork out of deploying micro-segmentation with comprehensive network flow analytics to map out real-time traffic and model security groups and firewall rules to successfully implement micro-segmentation security policies. It also helps to improve performance and availability of the infrastructure by combining and correlating virtual and physical compute, storage and networking components to provide a clear and full picture of the infrastructure.

It does not discriminate between virtual machines or physical servers, provides detailed information about the smallest workloads (containers), has integrations with the VMware Virtual Cloud Network vision and everything that runs beneath the Virtual Cloud Network.

Network Insight collects data from data sources like VMware vSphere, VMware NSX, Physical network devices (switches, routers, load balancers, and firewalls), Physical converged systems, IPAM systems and log collectors. All this information is put in a structured database, correlated and available via the intuitive user interface and API. The way this converged information is disclosed with the user interface is what makes Network Insight unique and such a pleasure to work with.

It\'s all about the fundamentals of the platform, as it's designed from the ground up to be as open as possible. This means you can retrieve any and all the data that is gathered and do all kinds of neat things with it like filtering, grouping, sorting and perform other modifiers on it (more on that in the chapter []{.underline}

[\
Using the Search Engine]{.underline}).

Apart from configuration and operational data, you can also send real-time network flow (NetFlow or sFlow) data to Network Insight to map out which workloads in your environment talk to each other. Because all data is correlated, the network flow data is linked to the source or destination workload (virtual machine or physical host) and you can see the name of the workload related to the flow, instead of just seeing that **10.0.0.10** talks to **10.0.1.11** over port **80**.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   **Configuration data** is meant as the configuration of the data source (i.e. show running-configuration on a physical Cisco device and the inventory of a VMware vCenter, etc.). **Operational data** is meant as dynamic, changing data on data sources (i.e. the route and mac tables on a network device, IP addresses of virtual machines, etc.).
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

This network flow data is typically generated by the vSphere Distributed Switch or a physical network device.

Due to the technical and sometimes very specific nature of this book, it's advised to have a Network Insight instance ready to go while you are reading; so, you can try things out with data from your own infrastructure!

The content of this book is based on Network Insight 5.0 (with some small nuggets on 5.1, because I took too long to write it). Considering the product team is an innovation engine and moves really quickly (delivers major features every 3 months), you need to doublecheck the details when you're using a newer version. This book also does not intend to replace the [official documentation](https://docs.vmware.com/en/VMware-vRealize-Network-Insight/index.html), but rather complement it. The specific technical details in this book will age, and rightly so.








Automating Network Insight
==========================

We've now come to a topic that's very close to my heart: automation. Because deep, deep, deep down I'm really lazy. But mostly because I don't like having to do repetitive tasks.

Automation helps you be more efficient; it gets things done faster and does each time exactly the same. This mostly helps in bringing the control closer to the users of your products and services and freeing up the IT staff to do better things than just provisioning virtual machines and installing applications manually. Like architecting the infrastructure to become more resilient, explore new technologies to push your infrastructure further. You know, doing more fun stuff.

In the data center world, we're usually talking about deploying application stacks using virtual machines with all kinds of configurations including storage, networking & compute options via an automation and orchestration layer.

Now I hear you wondering, "What does that have to do with a troubleshooting & monitoring tool?". Well, a lot!

Pushing Data In
---------------

There are a few reasons to push data into Network Insight. They all have to do with providing more context or pushing in configuration data. Let's start with the context reason first.

As you've learned in the chapter **Application Security Planning**, application context can be discovered from metadata straight from the infrastructures' inventory, or it can be created manually (or via the API). While application discovery works like a charm, it is also good to eliminate the (manual) discovery step by pushing the application construct into Network Insight directly from the infrastructure automation system that is provisioning the application onto the infrastructure. That way, you've got instant context for any newly deployed application.

The other reason to push data into Network Insight is to keep configuration synchronized. Data sources is a good example of this configuration. If you have a lot of physical switches, routers or firewalls deployed in the infrastructure and new ones are added regularly, you could automate the creation of those devices in Network Insight when they are added to the network. That way, they will be instantly monitored and available for troubleshooting exercises, without having to add them manually.

Pulling Data Out
----------------

At the other end of the spectrum, pulling data out of Network Insight for other systems is another reason to start automating. It is a treasure trove of information and other systems you might have put in place could benefit from it.

One widely used example is to take the network traffic flows for very specific virtual machines (the "highly confidential" or "at risk" ones) and forward the details of those flows to a Security Information and Event Management (SIEM) system to correlate those flows to other events that application or other systems generate. Because Network Insight is context rich, you can be very specific with which flows you export. In one of the real-world examples I'll get to later (Exporting Network Flows for Security Analytics), it is as simple as setting a simple tag on a virtual machine for it to be included in the broader security scrutiny.

Another example is to take virtual machine information and export it into a Configuration Management Database (CMDB) and make sure the virtual machine details are always in sync with the actual environment.

If that's not of interest, how about generating a daily report of all the configuration changes that happened in your environment? Every changed firewall rule, every created or deleted virtual machine, virtual machine hardware upgrades, any changes that created a problem inside the infrastructure, you name it.

I could go on with examples but seeing the range of things you can do should spark some ideas. Take any bit of information Network Insight has and combine it with your own systems; endless possibilities.

Automation makes it all possible.

API
---

Now that we've covered why you would want to automate Network Insight, let's take a look at how. Network Insight has a private and public REST API hosted on the Platform appliance.

Taking one step back, a REST API stands for Representational State Transfer Application Programming Interface. This has become an industry standard in the last few years, simply because it's so dead simple. You do extremely advanced automation with REST APIs but in the basics, it's just HTTP calls and you can use any HTTP client (like a browser or cURL) to call on these APIs. When testing with APIs, I recommend you use the [Postman](https://www.getpostman.com/) client, which is perfect for API development.

Inside REST, there's a reference architecture that lets you do HTTP calls in different ways that have different effects. If that sounds fuzzy, here's a technical explanation:

HTTP has several different methods, like GET to retrieve information, POST to deliver information (the content should be put in the body of the request), PUT to modify information and DELETE to remove information. These methods translate to the action you want to take in the API. If you do a GET request, you'll get information back from the API. If you do a DELETE request, the API knows that you want to delete an object.

When receiving the response from the API, there are a few aspects to take into account. The response HTTP status code (200, 400, etc.) will indicate whether the API call was a success (200), or if the request was formatted incorrectly (400), or if you don't have an authorized session (401), or if the API broke something (500). There are other codes, but these will be the most relevant. If you requested content (GET), the returning body will contain the requested information.

Officially (as not all APIs adhere to this), REST APIs should use JavaScript Object Notation (JSON) as the format in which the data is transferred between client and server. This is also an industry standard, which has the benefit that about every programming or scripting language knows how to read JSON and present it back to you in a usable form. It also helps that it's human readable.

This book isn't about teaching you about these standards and technologies and for the rest of this chapter, I'm going to assume you have a basic grasp of REST calls and JSON. I'm also not going through all API calls and functionalities but will give you enough information to get started. Complement this chapter by reading the vRealize Network Insight API Guide.

  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Currently, Network Insight rate limits the amount of API calls per second to 20. When doing API calls, rate limit your own script to not overload the API. You will be throttled, and the API will start giving out error code **429**.
  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### API Explorer

As with many of the VMware products these days, Network Insight has an API Explorer built in to the interface. This API Explorer holds the reference documentation for each API call that's available. If you're looking for parameters to include into the API call, this is the place. It also has a very handy feature where you can try out the API call directly from the interface to help in the process of formatting the right structure for a successful API call.

It can be found under the gear icon on the top right; API Documentation. There will be 2 tabs: API Reference and Documentation. The reference tab lists all API calls and their format and parameters (you'll use this one the most) and the documentation tab contains links to the API Guide and OpenAPI specification.

  ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------
  ![](./media/image96.png){width="1.2012478127734034in" height="1.964601924759405in"}   ![](./media/image97.png){width="4.743362860892389in" height="2.584659886264217in"}
  ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------

[]{#_Toc35170249 .anchor}Figure 91 -- Built in API Explorer

### Swagger / OpenAPI Specification

An [OpenAPI](https://swagger.io/specification/) (previously known as Swagger) specification is a description format for an API which can describe the contents of an API. Each endpoint, input and output parameters, authentication methods and other details around the API. This specification is what the developers use to describe all API endpoints and it is used to generate the documentation you see in the API Explorer.

It can also be used to automatically generate code for client libraries, or otherwise known as software development kits (SDK). While Network Insight does not have those SDKs yet, I'm holding out hope for future availability.

The OpenAPI specification is a very good reference source when you're building automation that consumes the custom objects that the API provides. For instance, when retrieving information about entities (VMs, IP Sets, Hosts, all objects from your infrastructure), there will be an **entity\_type** field inside the returned object data. This **entity\_type** describes the schema of data that will be included in the result. By looking up the entity type inside the OpenAPI specification, you know what schema you can expect to be able to use.

For example, here's a snippet of the "VirtualMachine" entity type:

These definitions can be nested, which the field **allOf** is referencing too. The **VirtualMachine** entity inherits everything from **BaseVirtualMachine**. Then we have the fields that are specific to a VM, like **cpu\_count** and **memory**, but also references to other entities.

If you look at the **cluster** field, it has **Reference** as value. This means that the result will contain references to other entity IDs which you can request separately. In this case, the entity ID that will be returned in the cluster field will be the vSphere DRS Cluster and you can retrieve the details about that DRS cluster by referencing that ID.

### Authentication

Before you can do any other API calls, you need to authorize your session and get an authentication token. This token will be used throughout any subsequent API calls that you want to execute.

To get an authentication token, use the **/auth/token** API endpoint. This is the only place where you'll need to specify a username and password; all the other endpoints rely on the authentication token for proper authorization.

As we're sending data (the credentials) across, the /auth/token endpoint takes a POST request. Formatting the POST body is fairly straight forward using JSON:

This example uses a credentials that is tied to a LDAP directory with the domain name **example.com**. If you were to use credentials that are local to the Network Insight platform, you would use something like this:

If the call is successful (right credentials, formatted correctly and the API or backend isn't on fire), you will receive a HTTP code 200 back and the response body will look something like this:

An authorization token is valid for 5 hours after you've requested it. Usually API calls are done on demand, but if you're scheduling calls continuously; keep in mind to refresh the token at least every 5 hours. Otherwise it will expire, and your subsequent API calls will return a 401 (unauthorized). The **expiry** field is the exact time that the token will expire. It is really exact, as it is formatted as an epoch timestamp in milliseconds (epoch usually stands for the seconds from January 1^st^, 1970 at 00:00:00 GMT). You can use this timestamp to see if your token is due for a refresher.

Then there's the **token** field. This base64 encoded string is to be used in any following API calls in the HTTP headers, like so:

Save the authentication token to a variable that you can reuse inside the script or workflow that you are building.

**Network Insight as a Service Authentication**

As you may remember from the chapter []{.underline}

[Hosted Architecture (SaaS]{.underline}), there is a difference in authentication between the on-premises Network Insight and the one that's delivered as SaaS. There is a single-sign-on platform in place for all VMware Cloud Services (CSP) products, meaning there is no user management within Network Insight, and you'll need to go through CSP to get an authentication token to use in the Network Insight API calls.

CSP works with so-called refresh tokens as a way of authentication. When using the API, you need to exchange a refresh token for an authentication token and use that when talking to the Network Insight API (or any other Cloud Service).

Refresh tokens are linked to an CSP account. To create one, log into <https://cloud.vmware.com> and go to your Console. Then open up your personalized menu (top right) and click **My Account**. Select the **API Tokens** tab and click **Generate a new API token** to get a refresh token. It'll look something like this: **ax22ea9i-139b-344x-lif7-ex6856ce57fa**

These refresh tokens are valid for 6 months, which you need to keep in mind when building automation based on these tokens.

After getting a refresh token, there's a single CSP API call you need to call to exchange a refresh token for an authentication token:

<https://console.cloud.vmware.com/csp/gateway/am/api/swagger-ui.html#/Authentication/getAccessTokenByApiRefreshTokenUsingPOST>

Executing this API call successfully, will give you a result like this:

The **access\_token** is the important field here, which you need to save and consider as the authentication token for the Network Insight API calls. There is, however, a slight difference in how you send this token across to the API. Instead of sending the **Authorization** header in your API call, you'll need to insert a header called **csp-auth-token** with the value of the authentication token that you've retrieved from the CSP API. Like so:

As a final note, it is also worth noting that the URL for the Network Insight as-a-Service API is the same for all environments: <https://api.mgmt.cloud.vmware.com/ni/$api-endpoint>

Once you're authenticated, return to the API Explorer and find the API call that you need to retrieve or push the information you want.

### A Few Examples

When using the API, you most likely have a fixed goal and know what you need to do in order to get there. The API Explorer will be your best friend for getting examples. Below are a few examples which are to illustrate how to work with the API in a broad sense. There are some gotchas you need to take into account.

#### Retrieving a list of VMs

Using Network Insight to get a list of VMs might be useful if you have a large environment with multiple vCenters. Network Insight aggregates all data in one place, so you'd only have to do a single API call to get every VM.

First, we need to find the right API call to get this list. Turn to the API Explorer and you will find a call to the endpoint **/entities/vms**. This has the description "List vms", so it's probably the one we're looking for. If you then look at the available parameters, this is what shows:

![](./media/image98.png){width="6.263888888888889in" height="1.1784722222222221in"}

[]{#_Toc35170250 .anchor}Figure 92 -- Parameters for API endpoint /entities/vms

For all the Entity endpoints, you'll see that the parameters are pretty much the same. There is a **size** parameter for the amount of results returned on a page, a **cursor** parameter to indicate from which page you want to start getting results and a **start\_time** and **end\_time**, which can be used to go back in time. Remember that there is a timeline to show historical data? Using **start\_time** and **end\_time** can get the list of VMs that existed a week ago, including the ones that have been deleted since.

The **cursor** is important to get full results. By default, the results for returned entities are paged in pages of the indicated **size** (default 10 results) and with every returned page, there'll also be a next **cursor** value in there, which you can use to request the next page. Have a look at this example:

![](./media/image99.png){width="6.263888888888889in" height="3.3222222222222224in"}

[]{#_Toc35170251 .anchor}Figure 93 -- Using Postman to execute API endpoint /entities/vms

In this example, I'm using Postman to get a list of VMs, limited by 2 results. The first thing you'll notice is that there are actually any VM attributes listed in the results, just **entity\_id**s. This works the same with all entities; it returns a list of references to entities. You can take the **entity\_id** and get detailed information by using the specific entity type API endpoint. In the case of the first result this will be **/entities/vms/17603:1:1010454414**, but we'll get to that.

Inside the result, the "results" array contains the resulting entities (thanks, captain obvious!). I'd like to get your attention to the other results. As said, there's a **cursor** value that indicates the next page, a **total\_count** with the amount of total results available (regardless the page limit) and the timeline values. The timeline is by default set to the current time, if you do not give a timeline yourself.

We've got 2 results now and there are 109 in total, which makes this next API call:

The result will be the next 2 VMs in the list and another cursor value. Continue on like this until you've got all 109 VMs returned. Do this inside a loop and dynamically look for the **total\_count** and the current count of results in order to determine to do another API call or be satisfied with the results. You could also look out for the **cursor** value. If there's no more pages, this cursor value will be empty.

#### Creating an Application

Now you know how to retrieve information, let's take a look at creating something via the API. Of all API calls that push data towards Network Insight, creating applications is the most used one as it can be used on an ongoing basis. Applications are the most dynamic factor in most environments, usually in a way that there are new applications being spun up all the time.

If you want to get the right context for troubleshooting and monitoring, you need to populate those new applications inside Network Insight. Couple this process closely to your application deployment automation and use the Network Insight API to provision applications while the application is being deployed. Automagically.

There are two steps required to create an application container:

1)  Create the application itself

2)  Create a tier within the newly created application with a filter that points to workloads (using tags, VM names, folders, any logical object in the virtualization layer).

In the API Explorer, there's an entire section devoted to application management. You'll quickly find the endpoints **/groups/applications** (POST) and **/groups/applications/{id}/tiers** (POST), which are needed to create an application.

Creating an application via /groups/application (POST) doesn't require much; just an application name. The result will contain the **entity\_id** that it has given the new application. Store that for the next call. Here's an example using the name **My-New-Application**. The top text area is the body that is being sent to the API and the bottom text area is the result that the API returns:

![](./media/image100.png){width="6.263888888888889in" height="3.3243055555555556in"}

[]{#_Toc35170252 .anchor}Figure 94 -- Using Postman to create an application via the API

You now have an empty application without any tiers. Let's add some!

Here's where the previously saved **entity\_id** comes in handy, as the API endpoint looks like this: **/groups/applications/17603:561:840848559/tiers**

The body of this endpoint is a bit more elaborate though, as it needs not only a name but also a filter to determine which workloads will be added to this tier. The filter is basically a search query, so you can filter on any logical object (tags, VM names, folders, etc.) to get the right VMs in the tier. In this example, I'll use a simple search based on VM name. Here's the formatted API call:

![](./media/image101.png){width="6.263888888888889in" height="3.3243055555555556in"}

[]{#_Toc35170253 .anchor}Figure 95 -- Using Postman to create an application tier via the API

As you can see, there is a **name** field (which is the name the new tier is given) in the body and an array called **group\_membership\_criteria**. This is where you define the search query that looks for workloads to put into the tier.

I've used an **entity\_type** called **BaseVirtualMachine** and a filter that looks for the names **VM01** and **VM02**. The filter can be formatted using the search query logic (throwback to chapter []{.underline}

[\
Using the Search]{.underline} Engine) and the you can find the **entity\_type** options in the OpenAPI specification under the \"definitions\" structure (examples are: Cluster, SecurityTag, EC2SecurityGroup, etc., etc.).

The result of creating the application tier is the tier definition echoed back plus the newly assigned **entity\_id** along with a reference to the parent application.

You now have a new application with a single tier with 2 VMs in it. If you need multiple tiers, rinse and repeat the second call.

Using PowerShell (PowervRNI)
----------------------------

Moving on from using raw APIs, there are tools available to get you faster up and running. When you're integrating with an existing automation or orchestration platform, you might need to use the API directly, but if you just want to execute a simple script to speed up a task; abstraction tools are the way to go. With these, you can simply fire a command and it handles the API endpoint calls for you. Just focus on the bare minimum input and get on with the results.

In this chapter I'm going to walk you through using PowerShell to talk to the Network Insight API.

### Why PowerShell?

This is a question I get a lot. There are a lot of scripting frameworks available and there are usually two camps: Linux based and Windows based tools. This is mostly because these scripting frameworks are built into the operating system itself.

People from the Linux world usually default to scripting languages like python, ruby, or even perl. Because these are (usually) installed by default on a Linux distribution.

People from the Windows world usually default to PowerShell. Again, because it's available by default on the newer versions of Windows.

But there's more. One of the reasons PowerShell is a popular scripting language to use, is because it uses a natural language design of its features. All functions that you can use, are named in a very natural way. If you want to get some information, the function will start with **Get-**. If you want to set an option or parameter, the function will start with **Set-**. If you want to invoke a command of some sort, the function will start with **Invoke-**.

PowerShell is also easily extendable with modules. Modules are basically just text files with custom functions that you can download and load or create yourself and publish. There is a central repository located on [powershellgallery.com](https://www.powershellgallery.com/), from which you can download modules manually and install them or simply install them directly from a PowerShell window with **Install-Module moduleName**. There are currently over 4.200 modules on the PowerShellGallery, so plenty to choose from.

It also helps that PowerShell was made a multi-platform tool for Windows, Linux and MacOS with version 6.0 in the beginning of 2018. I've been running it on MacOS ever since and haven't looked back at my Windows virtual machine. ;-)

If you would like to learn more around PowerShell, I highly recommend the [PowerShell: Getting Started](https://app.pluralsight.com/library/courses/powershell-getting-started/table-of-contents) course by Michael Bender on Pluralsight.

### PowervRNI

Most of the VMware related PowerShell modules, official and community developed, start with the prefix **Power** to relate it to PowerShell. For example, we have [PowerNSX](https://github.com/vmware/powernsx), [PowerCLI](https://code.vmware.com/tool/vmware-powercli), [PowervRA](https://github.com/jakkulabs/PowervRA), and a couple others.

When Network Insight 3.6 with the first version of the public API came out in November 2017, the PowerShell module to make use of this API was already in the making, as it was highly requested amongst the companies I was working with. Adhering to the unofficial naming convention; the module was named [PowervRNI](https://github.com/PowervRNI/powervrni).

It currently has 44 functions and around 95% of API coverage.

My goal with PowervRNI was pretty straight forward: make it easy to get started with the Network Insight public API and make it easy to integrate with other systems. I'm proud to say that it has been used to solve a breath of use cases involving data sharing issues between multiple systems. From security use cases where extra data around network traffic flows and infrastructure info is sent to a SIEM system to better collation, to importing a large amount of data sources (usually physical network devices) into Network Insight during the initial set up, to integrations with CMDB systems to synchronize the CMDB inventory with the real-life situation. I will go into a few example use cases in the upcoming chapters, but up-to-date examples can be found [on my blog](http://lostdomain.org/tag/powervrni/).

#### Getting Started with PowervRNI

There are two ways to get PowervRNI on your system: a manual and automated way.

##### Installing Manually

Installing it manually can be a good option on systems where you don't have permissions to use the cmdlet **Install-Module**. Although the newer PowerShell versions have to ability to install modules just for yourself (parameter "*-Scope CurrentUser*"), it can still be locked down.

A manually install simply means downloading the module source files and placing them locally, where you can load them.

Get the module source files from here: <https://powervrni.github.io/>

And then open up a PowerShell window, change directory to where you have put the module source files and load PowervRNI like this:

##### Installing Automagically

Using the built-in cmdlet **Install-Module** will download the module source files for you and place them somewhere where PowerShell knows to load them. Open up a PowerShell window and execute these commands:

The first command is to make the PowerShellGallery a trusted source. You'll only have to do this once and it prevents showing a notice that asks you for permission to download from the PowerShellGallery because it's an untrusted repository. You can still install the module without adding it to the trusted repositories, but it's just cleaner this way.

After the installation has completed, load PowervRNI like this:

Notice that there's a slight difference in loading the PowervRNI module. When installing a module via **Install-Module**, you can load the modules from anywhere and you don't have to give the relative path to the module source files. That's why I recommend doing it via the automagical way, if you have the option.

##### Getting Familiar

Now that PowervRNI is on your system and loaded, take a little time to explore the available cmdlets to see what's available and which ones you would like to try. Get a complete list of available cmdlets by executing this:

Every cmdlet in PowervRNI is well-documented and has examples of its usage and you can get that documentation via PowerShell:

##### Connecting to Network Insight

In the previous chapters, you've learned about the way Network Insight handles authentication (via authorization tokens). PowervRNI uses the authorization tokens for all API calls, which means you need to connect and authorize first.

There are two cmdlets to connect a Network Insight instance. There's **Connect-vRNIServer** to connect to vRealize Network Insight (the on-prem variant) and there's **Connect-NIServer** to connect to the Network Insight as a Service variant.

**Connect-NIServer** is extremely simple to use and only required the Refresh Token that you have created in chapter [Authentication]{.underline}.

This exchanged the Refresh Token for an authentication token and that will be used for subsequent API calls and you are now free to use the rest of the cmdlets inside PowervRNI.

**Connect-vRNIServer** takes a few more parameters, as the on-premises instance would have more details like the IP or hostname of the Platform VM and the credentials to connect.

There are two ways to handle the credentials. You can input the username and password when you connect (either pass them as parameters or be prompted on them) or you can create a [PSCredential](https://blog.kloud.com.au/2016/04/21/using-saved-credentials-securely-in-powershell-scripts/) file once and refer to that file when connecting. This would be the preferred way to connect if you're running a scheduled task. Remember, plain text passwords make babies cry.

If the connection was a success, you will see the authentication token being returned which is stored and used for subsequent API calls.

Automation Use Cases
--------------------

Now that we've covered the **how** of automation with Network Insight in the previous chapters, let's focus on the **why**.

In the upcoming chapters, I'll give you 4 examples of use cases which might give some inspiration. These examples are not all there is, of course, the amount of value you can get out of automation are as vast as the data that's being collected by Network Insight. The following examples are real-life use cases that I've helped organizations to implement.

### Integrating with Infrastructure Automation & Orchestration systems

Beginning with the first of 2 application focused use cases, let's have a look at an integration between an infrastructure automation and/or orchestration system. In the context of this integration, an infrastructure automation system is used to deploy applications and all its dependencies. From the virtual machines with their compute, storage and network properties, to installing required software packages and configuring them. Full application deployment.

Why is that important? Well, remember that having the application context in Network Insight enriches your experience immensely. How great would it be to have the application context be created at the same time as the actual application is being deployed? That's where an integration to your automation system comes into play.

#### Example

vRealize Automation (vRA) is an infrastructure lifecycle management and automation platform, which can be compared to an octopus; it extends its reach to other systems to execute actions (like deploying a virtual machine) and can grow extra (custom) arms to systems that it does not out of the box talk to.

As an example, I'll be using a 3-tiered application blueprint that contains a web server, application server, and database server tier. Of the web and application tiers, there can be multiple VMs deployed but there's just one database server. They are linked to vSphere templates which will be cloned when a deployment is requested.

![http://lostdomain.org/wp-content/uploads/2018/11/vrni-vra-blueprint-tiers-1024x550.png](./media/image102.png){width="6.263888888888889in" height="3.3618055555555557in"}

[]{#_Toc35170254 .anchor}Figure 96 -- Example vRealize Automation 3-tiered Application Blueprint

This blueprint design relates directly to an application construct within Network Insight, using the blueprint name as application name and the different types of machine deployments (Web, App, DB) as the names for the tiers. When this blueprint is deployed by someone, vRA will deploy the virtual machines, networks, storage and the software packages on the newly created virtual machines. After that work is done, we can insert a custom vRealize Orchestrator (vRO, the octopus' engine) workflow that will take this newly created application and creates the application context inside Network Insight.

Inside vRA, there's an Event Broker which you can use to kick off workflows during specific stages of a deployment. You can create a subscription on the event that signals that a deployment is done, and all virtual machines have been deployed. This subscription also indicates which vRO workflow should be started.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   The vRO workflow and a step by step guidance of how to install it, can be [found on my blog](http://lostdomain.org/2018/11/08/integrating-vrealize-automation-with-network-insight/). The actual code is not the point of this chapter; I'm giving you an example of how it can work with vRA, but this can be applied with any and all infrastructure automation & orchestration systems.
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Here's a graphical overview of how the process works, so you can translate it to your own system.

![](./media/image103.tiff){width="6.263888888888889in" height="2.4131944444444446in"}

[]{#_Toc35170255 .anchor}Figure 97 -- Push Applications from Automation workflow

### Importing Applications from Configuration Management Databases

Application Discovery is important to get the right application context in Network Insight. While you can natively integrate the ServiceNow CMDB, there are ways to integrate other CMDBs using the API. If you are not using ServiceNow for your CMDB needs, don't fret. I think it's pretty safe to say that all relevant CMDB systems have a way to export data from its systems and most will even have an API to talk to.

If it has an API; good! You can set up a periodical synchronization between the CMDB and Network Insight. This workflow should retrieve a list of application names, optional tiers and all the virtual machines and/or physical IP addresses attached to that application. You then use that list and ask the Network Insight API if this application already exists and compare the virtual machines and physical IP addresses to see if anything has changed (and then update it). If the application doesn't exist; create it with the info from the CMDB.

Here's a visual representation of this workflow:

![](./media/image104.tiff){width="6.263888888888889in" height="3.1930555555555555in"}

[]{#_Toc35170256 .anchor}Figure 98 -- Import Applications from CMDB workflow

#### Example

Importing data from a CMDB can be easy when it has an API. iTop is an open source CMDB system which can track infrastructure inventory and changes to it. I use it to track my own inventory (yes, I need a system for that. Don't judge me. ;-)).

In the examples directory of PowervRNI, there is an example script that pulls out application items from iTop, traverses the relationship tree and discovers VMs that are attached to that application. Then it adds that application tree as an application construct into Network Insight.

As the script is just a bit too big to paste here, I'll leave you with a link to it:

### Exporting Network Flows for Security Analytics

Getting out of the application realm, let's focus on a security use case. As Network Insight gathers all network flows going through the network, it has visibility on what's actually happening with your applications. Is it behaving accordingly, sending and receiving traffic that it is supposed to? For instance, a web server should only send out connections that it needs to support its website (usually just HTTP\[S\]). If it starts sending out SSH traffic, it's probably compromised and is trying to compromise other systems.

While you can create user-defined events based on anomalies like that and have an alert sent out when that starts happening, it's usually more prevalent to send the network flow information to a SIEM system. That system would also be able to take the application generated logs and correlate them together for an end to end view.

Sending all network flows all the time might not be a preferable situation, as the amount of data can overwhelm the SIEM and it might not be interesting to record every network flow. Instead, what I've seen is more a reactive setup based on other events. The SIEM or other monitoring system catches something that seems off and sets a tag on a virtual machine, which in turn triggers the network flow import to SIEM.

Of course, you can customize this to your own requirements.

#### Example

Using PowervRNI, exporting flows and sending them to another system is fairly simple as there's a cmdlet needed to retrieve the network flows: **Get-vRNIFlow**. Here's an example:

Flow records have a bunch of correlated information attached, as you can see in the example above. I'd like to highlight a few fields on which you could filter, which would be beneficial when looking for specific flows:

  **Field**              **Description**
  ---------------------- ----------------------------------------------------------------------------------------------------------------------
  **traffic\_type**      Which way is the traffic going? **INTERNET\_TRAFFIC** or **EAST\_WEST\_TRAFFIC** are possibilities.
  **source\_\***         Source of traffic; not only IP address, but also context like **vm**, **vnic**, **datacenter**, etc.
  **destination\_\***    Same as above, only for the destination (including context)
  **firewall\_action**   When integrated with VMware NSX Data Center, this can show flows which are blocked by the Distributed Firewall (DFW)

### Tenant Bandwidth Chargeback / Showback

Using the network flow data in Network Insight, you can also make money. I used to work for a provider which had a range of services, like leasing out physical data center room and network connectivity to or simple virtual machines. All services had something in common; we charged for bandwidth. This is fairly common in provider land and everyone has their way of metering, we had a custom application (that I created) that listened on a mirror (span) port and looked at the actual traffic of our tenants. It saved the byte size of the packets linked to a source IP and saved that number to a database. At the end of every month, we generated reports from this database in order to invoice the customers for the amount of bandwidth they used, that month.

While we had our issues, this was a pretty clean approach. Other service providers didn't have the option of creating their own program to do this and relied on multiple data sources to tell them the total bandwidth usage. I've heard many stories about losing revenue because they couldn't get the right data to invoice their customers.

This bandwidth data is available within Network Insight and there are ways to get a clean list of bandwidth usage per IP (source or destination) in several formats. Using the API is one of those formats. In the below example, I'll go through an extremely simple example on how to use the API and retrieve bandwidth usage per source IP address.

####  Example

There is an API endpoint called aggregation ([/api/ni/search/aggregation]{.underline}), which can be used to fetch sums or averages of a specified metric. In this case, we'll be using the aggregation endpoint to retrieve the sum of flows coming and going to a specific IP address. To understand what's going on in that script, here's the API call:

Inside this call, the aggregations field is where we specify the operation the aggregation needs to perform. In this case, it's a **SUM** operation on the field **flow.totalBytes.delta.summantion.bytes**. This translates to "SUM(Bytes) of Flow" in the regular UI search bar, as the API search uses the internal naming convention of objects.

Also take note of the filter, where the search condition is given. This can be a single condition as in the example above, but also multiple conditions. For example, if you don't care about splitting out download and upload and want a single number for all bandwidth combined, use:

You can modify the filter to use VMs or any other of the objects inside Network Insight. Get creative!

Lastly, the **start\_time** and **end\_time** fields indicate the time window that the result should be based on.

As a result of this API call, you will get a recap of the aggregation request and the value of the query:

The field **aggregations.value** is the number of bytes that matches the filter.

You can find the PowervRNI example script here: <https://github.com/PowervRNI/powervrni/blob/master/examples/get-bandwidth-usage-per-ip.ps1>

Automation Conclusion
---------------------

I hope the examples in the previous pages have been helpful to get your imagination going on what is possible when you start automating Network Insight. These examples have just scraped the surface of what's possible, and there's a whole integration ecosystem possible that takes advantage of the data.

If you have any other use-cases that you are building -- please do reach out to me via any of my communication channels; I'd like to learn from you!

Shout Outs
==========

This book wouldn't be possible without the amazing team behind Network Insight. From providing me with insights what's going on behind the scenes to putting up with my incessive stream of questions, these people stood by me and have credit in making this book happen. Let me introduce them:

Shiv Agarwal

Abhijit Sharma

Rohit Reja

Dave Overbeek

Manish Virat

Karthic Kumar

Naveen Chaudhary

Taruna Gandhi

Thank you for your support and putting up with my continuous stream of questions.

Keyword Index
=============

**API Endpoint** URL of an API that calls a specific function (i.e. /api/ni/groups/applications)

**Cloud** A collection of computers that are not your own. Typically paid for per usage.

**CMDB** Configuration Management DataBase

**CSP** Cloud Services Portal -- VMwares' management portal for their cloud services

**DBA** DataBase Administrator

**DFW** VMware NSX Data Center -- Distributed Firewall

**DMZ** De-Militarized Zone

**East-West** Network traffic that stays within the boundary of the data center.

**EC2** Elastic Compute Cloud -- virtual machines in AWS.

**ENI** Elastic Network Interface -- virtual network interface, typically attached to an

EC2 instance

**REST API** A REpresentational State Transfer API is an application program interface

> (API) that uses HTTP requests to GET, PUT, POST and DELETE data.

**JSON** JavaScript Object Notation

**PII** Personally Identifiable Information

**S3** Simple Storage Service -- AWS object storage services. Delivered in buckets.

**SDDC** Software Defined Data Center

**SDK** Software Development Kit

**SDN** Software Defined Networking

**SIEM** Security Information and Event Management

**NI** Network Insight

**North-South** Network traffic that goes beyond the boundary of the data center. Usually

> internet traffic.

**VPC** Virtual Private Cloud -- AWS container for compute resources

**vRA** vRealize Automation

**vRNI** vRealize Network Insight

**vRO** vRealize Orchestrator

**PKS** Pivotal Container Service

**Workload** Something that runs an application: VM, container, cloud instance or

> physical server.

Figures
=======

[Figure 1 - Global numbers of Network Traffic movement 12](#_Toc35170156)

[Figure 2 -- Recommended Firewall Rules -- Grouped by Application 13](#_Toc35170157)

[Figure 3 - Topology chart: gluing physical and virtual together 14](#_Toc35170158)

[Figure 4 - Health Check and Health Alerts 15](#_Toc35170159)

[Figure 5 -- CNCF 2018 Survey results 17](#_Toc35170160)

[Figure 6 -- VMware NSX Portfolio 20](#_Toc35170161)

[Figure 7 -- VMware Virtual Cloud Network 21](#_Toc35170162)

[Figure 8 -- Micro-Segmention; logical security boundaries between applications. 23](#_Toc35170163)

[Figure 9 -- Enabling NetFlow on a vCenter data source 26](#_Toc35170164)

[Figure 10 -- Adding a Physical Flow Collector data source 26](#_Toc35170165)

[Figure 11 -- High level overview of network traffic behaviour 27](#OLE_LINK3)

[*Figure 12 -- Micro-Segmentation Planner; the donut of joy* 28](#_Toc35170167)

[Figure 13 -- Recommended Firewall Rules grouped by Application 30](#_Toc35170168)

[Figure 13 -- Recommended Firewall Rules YAML export 32](#_Toc35170169)

[Figure 14 -- Recommended Firewall Rules grouped by Tier 35](#_Toc35170170)

[Figure 15 -- Example application construct 38](#_Toc35170171)

[Figure 16 -- vCenter Custom Attribute definition 40](#_Toc35170172)

[Figure 17 -- Custom Attributes on a VM 40](#_Toc35170173)

[Figure 18 -- Application Discovery using Tags 41](#_Toc35170174)

[Figure 19 -- Application Discovery Results 43](#_Ref13144669)

[Figure 20 -- Application Discovery Results - Form 44](#_Toc35170176)

[Figure 21 -- Application Discovery with a Naming Convention 47](#_Toc35170177)

[Figure 22 -- Application Discovery -- Pattern Builder 47](#_Toc35170178)

[Figure 23 -- Application Discovery -- ServiceNow Application Map 49](#_Toc35170179)

[Figure 24 -- Application Discovery -- ServiceNow Result 50](#_Toc35170180)

[Figure 25 -- Application Migration Planning -- Dependency mapping 52](#_Ref29044160)

[Figure 26 -- Application Migration Planning -- Application Details 53](#_Ref29044197)

[Figure 27 -- Application Migration Planning -- Traffic per Country 54](#_Toc35170183)

[Figure 28 -- Application Migration Planning -- Egress traffic per Country 55](#_Ref29045562)

[Figure 29 -- Application Migration Planning -- Egress traffic total 55](#_Ref29045561)

[Figure 30 -- Application Migration Planning -- All application traffic 56](#_Toc35170186)

[Figure 31 -- Application Migration Planning -- Migration Wave Dependency Mapping 59](#_Toc35170187)

[Figure 32 -- Application Migration Planning -- CPU & Memory requirements 60](#_Toc35170188)

[Figure 33 -- Application Migration Planning -- Internet Traffic of Migrate Wave 1 61](#_Toc35170189)

[Figure 34 -- Application Migration Planning -- Peak internet Traffic of Migrate Wave 1 61](#_Toc35170190)

[Figure 35 -- Application Migration Planning -- Flow Types 62](#_Toc35170191)

[Figure 36 -- Application Migration Planning -- Internet Packets p/s of Migrate Wave 1 62](#_Toc35170192)

[Figure 34 -- Application Migration Planning -- Peak internet packets p/s of Migrate Wave 1 63](#_Toc35170193)

[Figure 34 -- Application Migration Planning -- Validate Application with the Time Machine 63](#_Toc35170194)

[Figure 37 -- AWS Master account link diagram 68](#_Toc35170195)

[Figure 38 -- AWS: Setting up VPC Flow Logs 69](#_Toc35170196)

[Figure 39 -- Adding AWS Account 70](#_Ref24444888)

[Figure 40 -- AWS Search options 71](#_Toc35170198)

[Figure 41 -- AWS CloudWatch listing network flow logs 72](#_Toc35170199)

[Figure 42 -- AWS Network topology between two VMs in different VPCs 73](#_Toc35170200)

[Figure 43 -- AWS Network topology between on-premises and an AWS VPC 73](#_Ref24463962)

[Figure 44 -- Adding an Azure data source 77](#_Toc35170202)

[Figure 45 -- Azure Search options 78](#_Toc35170203)

[Figure 46 -- Azure flow logs structure 79](#_Toc35170204)

[Figure 47 -- VMware Cloud on AWS -- spanning networking & security across clouds 81](#_Toc35170205)

[Figure 48 -- VMware Cloud on AWS -- Adding the vCenter 82](#_Toc35170206)

[Figure 49 -- VMware Cloud on AWS -- Adding the NSX Manager 83](#_Toc35170207)

[Figure 50 -- VMware Cloud on AWS -- Hybrid Path 85](#_Toc35170208)

[Figure 51 - Platform Architecture Diagram 86](#_Toc35170209)

[Figure 52 - Platform VM Internal Architecture 87](#_Toc35170210)

[Figure 53 - Private API in action 88](#_Toc35170211)

[Figure 54 - Searching your data center 88](#_Toc35170212)

[Figure 55 - Platform & Collector relationships 90](#_Toc35170213)

[Figure 56 - Collector VM internal architecture 91](#_Toc35170214)

[Figure 57 - Collector NetFlow processing 92](#_Toc35170215)

[Figure 58 -- Architecture for Network Insight as a Service 101](#_Toc35170216)

[Figure 59 -- Command line list of commands 103](#_Toc35170217)

[Figure 60 -- Restarting services via CLI 104](#_Toc35170218)

[Figure 61 -- CLI Output for show-connectivity-status 104](#_Toc35170219)

[Figure 62 -- Listing available log components and following the saasservice 105](#_Toc35170220)

[Figure 63 -- Searching in logs 106](#_Toc35170221)

[Figure 64 -- Configuring the vRealize Log Insight agent 107](#_Toc35170222)

[Figure 65 -- Enabling web proxy 108](#_Toc35170223)

[Figure 66 -- Changing the IP address of a clustered node 109](#_Toc35170224)

[Figure 67 -- Moving a Collector between Platforms 109](#_Toc35170225)

[Figure 68 -- Outlier configuration options 113](#_Toc35170226)

[Figure 69 -- Outlier detection result 115](#_Toc35170227)

[Figure 70 -- Outlier detection event 116](#_Toc35170228)

[Figure 71 -- Creating a threshold 118](#_Toc35170229)

[Figure 72 -- Search query & results example 124](#_Toc35170230)

[Figure 73 -- Search query structure 125](#_Toc35170231)

[Figure 74 -- Search help: find all supported properties 126](#_Ref22480916)

[Figure 75 -- Search for a meta entity type and get all included entity types 126](#_Toc35170233)

[Figure 76 -- Search Metric Properties: example on switch port 127](#_Ref22484064)

[Figure 77 -- Search filters; condition and comparison operators 129](#_Toc35170235)

[Figure 78 -- Searching with property projection 130](#_Toc35170236)

[Figure 79 -- Searching with property projection, including metrics 131](#_Toc35170237)

[Figure 80 -- Searching with a count operator 132](#_Toc35170238)

[Figure 81 -- Searching with a list operator 132](#_Toc35170239)

[Figure 82 -- Searching with a max operator 133](#_Toc35170240)

[Figure 83 -- Searching with a sum operator 133](#_Toc35170241)

[Figure 84 -- Searching with an avg operator 134](#OLE_LINK9)

[Figure 85 -- Search; using the series() projection to combine metrics 135](#OLE_LINK15)

[Figure 86 -- Search; using multiple series() projections to combine metrics 135](#OLE_LINK11)

[Figure 87 -- Search; using the group by operator 136](#OLE_LINK17)

[Figure 88 -- Search; using the group by operator and aggregate functions for L2 traffic 136](#OLE_LINK21)

[Figure 89 -- Search; using the group by operator and aggregate functions for AWS rules 137](#OLE_LINK35)

[Figure 90 -- Search; time control in the web interface 139](#_Ref24291822)

[Figure 91 -- Built in API Explorer 143](#_Toc35170249)

[Figure 92 -- Parameters for API endpoint /entities/vms 147](#_Toc35170250)

[Figure 93 -- Using Postman to execute API endpoint /entities/vms 148](#_Toc35170251)

[Figure 94 -- Using Postman to create an application via the API 150](#_Toc35170252)

[Figure 95 -- Using Postman to create an application tier via the API 151](#_Toc35170253)

[Figure 96 -- Example vRealize Automation 3-tiered Application Blueprint 158](#_Toc35170254)

[Figure 97 -- Push Applications from Automation workflow 159](#_Toc35170255)

[Figure 98 -- Import Applications from CMDB workflow 160](#_Toc35170256)

Tables
======

[Table 1 -- PCI Dashboard; PCI sections explained 37](#_Toc35170257)

[Table 2 -- CLI Commands reference 110](#_Toc35170258)

[Table 3 -- Threshold metric options 119](#_Toc35170259)

[Table 4 -- Search examples, mapping out entity types 126](#_Toc35170260)

[Table 5 -- Search filter condition examples 130](#_Toc35170261)

[^1]: <https://www.cncf.io/blog/2018/08/29/cncf-survey-use-of-cloud-native-technologies-in-production-has-grown-over-200-percent/>

[^2]: <https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/support/product-lifecycle-matrix.pdf>

[^3]: <https://en.wikipedia.org/wiki/Regular_expression>

[^4]: In 2018, according to Gartner: <https://www.gartner.com/en/newsroom/press-releases/2019-07-29-gartner-says-worldwide-iaas-public-cloud-services-market-grew-31point3-percent-in-2018>

[^5]: In 2018, according to Gartner: <https://www.gartner.com/en/newsroom/press-releases/2019-07-29-gartner-says-worldwide-iaas-public-cloud-services-market-grew-31point3-percent-in-2018>

[^6]: Online Flow Size Prediction for Improved Network Routing: <https://cs.uwaterloo.ca/~pjaini/downloads/main.pdf>

[^7]: This guide is currently not available publicly; ask your VMware representative for it.

[^8]: <https://dictionary.cambridge.org/dictionary/english/outlier>

[^9]: <https://en.wikipedia.org/wiki/Median_absolute_deviation>

[^10]: <https://en.wikipedia.org/wiki/Packet_loss>

[^11]: <https://en.wikipedia.org/wiki/Mean>

[^12]: <https://en.wikipedia.org/wiki/Standard_deviation>
