**Abstract**

If you are in any way affiliated with network and virtual infrastructure
troubleshooting and monitoring, you're going to like this book. If
you're driven crazy by having to overlap multiple tools to get the
information needed to troubleshoot an issue in your environment, you're
going to love this book.

As the title suggests, this book will give you a deep dive look at
VMware's holistic networking and virtual infrastructure monitoring &
troubleshooting product; vRealize Network Insight.

Network Insight is famous for a couple reasons:

1.  It has the capability to kickstart your way to a secure segmented
    network by creating visibility into what actually happens on your
    network.

2.  It sucks up all the operational and configuration data of your
    virtual (vSphere, Kubernetes, Bare metal), public cloud (AWS &
    Azure), SD-WAN, and physical network environment and allows you to
    overlay the two to create a holistic view of your entire environment
    and use that to significantly reduce time spent troubleshooting and
    gathering data from your environment.

3.  Analytics that go over all the data that's pulled into Network
    Insight, provide a great deal of useful information; from "who is
    using my applications?", to "are there any abnormalities in the
    network behavior?", to all the way to "how much is this cloud egress
    bandwidth costing me?".

You will be guided through the components and architecture of Network
Insight and discover hidden gems and secrets throughout the platform.
This book will take you from beginner to a vRealize Network Insight
Samurai and we'll have some fun along the way!

Table of Contents {#table-of-contents .TOC-Heading}
=================

[Introduction -- About the author 6](#introduction-about-the-author)

[Syntax(?) to-do 7](#syntax-to-do)

[Foreword by Shiv Agarwal 8](#foreword-by-shiv-agarwal)

[Pre-face 10](#pre-face)

[Introduction to Network Insight 12](#introduction-to-network-insight)

[Use Case -- Application Security Planning (Micro-segmentation)
12](#use-case-application-security-planning-micro-segmentation)

[Use-Case -- Getting actual visibility into your environment
14](#use-case-getting-actual-visibility-into-your-environment)

[Use-Case -- Doing the health check boogy
15](#use-case-doing-the-health-check-boogy)

[Use-Case -- Migrating to the Cloud (or anywhere)
16](#use-case-migrating-to-the-cloud-or-anywhere)

[Use-Case -- Visibility for Containers
17](#use-case-visibility-for-containers)

[vRealize Network Insight versus vRealize Network Insight Cloud (SaaS)
19](#vrealize-network-insight-versus-vrealize-network-insight-cloud-saas)

[Virtual Cloud Network 20](#virtual-cloud-network)

[Application Security Planning 22](#application-security-planning)

[Micro-Segmentation? 22](#micro-segmentation)

[The Challenge of Micro-Segmentation
23](#the-challenge-of-micro-segmentation)

[Speeding up Micro-Segmentation 24](#speeding-up-micro-segmentation)

[How does it work? 24](#how-does-it-work)

[NetFlow, IPFIX & sFlow 24](#netflow-ipfix-sflow)

[Configuring Data Sources for NetFlow, IPFIX & sFlow
25](#configuring-data-sources-for-netflow-ipfix-sflow)

[Analyzing Network Flows 27](#analyzing-network-flows)

[Group By 28](#group-by)

[Scope 28](#scope)

[Flow Type (NSX Flows) 29](#flow-type-nsx-flows)

[Recommended Firewall Rules 29](#recommended-firewall-rules)

[Exporting Recommended Firewall Rules
31](#exporting-recommended-firewall-rules)

[Using the Recommended Firewall Rules
34](#using-the-recommended-firewall-rules)

[Step 1 -- Application Segmentation
34](#step-1-application-segmentation)

[Step 2 -- Tier Segmentation 34](#step-2-tier-segmentation)

[Step 3 -- Micro-segmentation 35](#step-3-micro-segmentation)

[Details I left out 36](#details-i-left-out)

[Proving Security & Auditing for PCI
37](#proving-security-auditing-for-pci)

[Application Discovery 38](#application-discovery)

[Application Constructs 38](#application-constructs)

[Tags or Custom Attributes 39](#tags-or-custom-attributes)

[Naming Conventions 44](#naming-conventions)

[CMDB (ServiceNow) 48](#cmdb-servicenow)

[Application Migration Planning 51](#application-migration-planning)

[Application Discovery & Assessment
51](#application-discovery-assessment)

[Traffic Patterns 54](#traffic-patterns)

[Per Application 54](#per-application)

[Bandwidth Egress Costs 55](#bandwidth-egress-costs)

[Looking at all Applications 56](#looking-at-all-applications)

[Creating Migration Waves 57](#creating-migration-waves)

[Limitation Check 60](#limitation-check)

[Compute & Storage 60](#compute-storage)

[Network 61](#network)

[Migrating the Applications 63](#migrating-the-applications)

[Validating Application Behavior 63](#validating-application-behavior)

[Network Insight into Public Clouds
65](#network-insight-into-public-clouds)

[Amazon Web Services (AWS) 66](#amazon-web-services-aws)

[AWS Networking Tools 66](#aws-networking-tools)

[Adding AWS to Network Insight 67](#adding-aws-to-network-insight)

[Inventory Collection 71](#inventory-collection)

[Network Flows 71](#network-flows)

[Network Path Visibility 72](#network-path-visibility)

[Security Group Tracking 74](#security-group-tracking)

[Azure 75](#azure)

[Azure Networking Tools 75](#azure-networking-tools)

[Adding Azure to Network Insight 76](#adding-azure-to-network-insight)

[Inventory Collection 77](#inventory-collection-1)

[Network Flows 78](#network-flows-1)

[Network Path Visibility 80](#network-path-visibility-1)

[Security Group Tracking 80](#security-group-tracking-1)

[VMware Cloud on AWS (VMC) 81](#vmware-cloud-on-aws-vmc)

[Adding VMware Cloud on AWS to Network Insight
82](#adding-vmware-cloud-on-aws-to-network-insight)

[Network Flows 83](#network-flows-2)

[Network Path Visibility 84](#network-path-visibility-2)

[Architecture 86](#architecture)

[Platform 86](#platform)

[Presentation Service Layer 87](#presentation-service-layer)

[Data Service Layer 89](#data-service-layer)

[Collector 89](#collector)

[Collector Services 90](#collector-services)

[Flow Processor 91](#flow-processor)

[Connecting to Data Sources 95](#connecting-to-data-sources)

[Connecting to the Platform 97](#connecting-to-the-platform)

[Hosted Architecture (SaaS) 101](#_Toc35169916)

[Using the Command Line and Troubleshooting
102](#using-the-command-line-and-troubleshooting)

[Logging In 102](#logging-in)

[Commands for Troubleshooting 103](#commands-for-troubleshooting)

[Logs 105](#logs)

[Configuring Syslog 106](#configuring-syslog)

[Configuring a Proxy 107](#configuring-a-proxy)

[Platform Specific Commands 108](#platform-specific-commands)

[Collector Specific Commands 109](#collector-specific-commands)

[Command Reference 110](#command-reference)

[Analytics 112](#analytics)

[Outlier Detection 112](#outlier-detection)

[Static Thresholds 116](#static-thresholds)

[Monitored Metric 119](#monitored-metric)

[Aggregation 119](#aggregation)

[Threshold Breach Value 120](#threshold-breach-value)

[Alerting 120](#alerting)

[Dynamic Thresholds 121](#dynamic-thresholds)

[Using the Search Engine 123](#using-the-search-engine)

[Building Searches 125](#building-searches)

[Entity Types 125](#entity-types)

[Meta Entity Types 126](#meta-entity-types)

[Entity Property 127](#entity-property)

[Configuration Property 127](#configuration-property)

[Reference Property 127](#reference-property)

[Metric Property 127](#metric-property)

[Meta Property 128](#meta-property)

[Filter 128](#filter)

[Projections 130](#projections)

[Property 130](#property)

[Count 131](#count)

[List 132](#list)

[Aggregate Functions 133](#aggregate-functions)

[Series 134](#series)

[Ordering 135](#ordering)

[Grouping 136](#grouping)

[Limiting 137](#limiting)

[Reference Traversal Queries 137](#reference-traversal-queries)

[Nested Queries 138](#nested-queries)

[Time Control 139](#time-control)

[Automating Network Insight 141](#automating-network-insight)

[Pushing Data In 141](#pushing-data-in)

[Pulling Data Out 141](#pulling-data-out)

[API 142](#api)

[API Explorer 143](#api-explorer)

[Swagger / OpenAPI Specification 143](#swagger-openapi-specification)

[Authentication 145](#authentication)

[A Few Examples 147](#a-few-examples)

[Using PowerShell (PowervRNI) 153](#using-powershell-powervrni)

[Why PowerShell? 153](#why-powershell)

[PowervRNI 153](#powervrni)

[Automation Use Cases 157](#automation-use-cases)

[Integrating with Infrastructure Automation & Orchestration systems
157](#integrating-with-infrastructure-automation-orchestration-systems)

[Importing Applications from Configuration Management Databases
159](#importing-applications-from-configuration-management-databases)

[Exporting Network Flows for Security Analytics
160](#exporting-network-flows-for-security-analytics)

[Tenant Bandwidth Chargeback / Showback
162](#tenant-bandwidth-chargeback-showback)

[Automation Conclusion 164](#automation-conclusion)

[Shout Outs 165](#shout-outs)

[Keyword Index 166](#keyword-index)

[Figures 167](#figures)

[Tables 170](#tables)

Introduction -- About the author
================================

As I'm sitting in the airport, waiting for my flight after a team
building exercise with the Networking & Security Business Unit within
VMware, the thought going through my head is: why? Why on earth are you
starting another big project that's going to take up a ton of time? The
reason is simple: Hi, I'm Martijn Smit and I'm an information sharing
addict (echo's: "hi Martijn!").

I'm proud to be Dutch and proud to be in the industry I'm in. My career
started at a hosting company, in which I spent 8 years moving from the
webhosting help desk to colocation & dedicated server support, to
managing the internet-network and helping to build a new datacenter from
the ground up. After leaving this provider, I joined a value-added
reseller company, with which I spent 5 years designing and deploying
data center infrastructures, including storage, compute, networking and
virtualization. I was also in the innovation group that brought the last
two together to support virtual networking; Software-Defined Networking
(SDN).

I currently work at VMware in Technical Marketing for vRealize Network
Insight, as I fully believe in the way Network Insight is approaching
Networking & Security troubleshooting and monitoring and want to spread
the word. My previous role was to guide customers to the world of
virtual networking; NSBU Solutions Engineer. Having said that; don't
worry, this book is not going to be a sales pitch but hardcore technical
information (just as I like it. ;-)).

Apart from my passion for technology, I believe in a healthy balance and
taking care of yourself, so often take 2 to 3-hour bike rides, exercise
every day and eat proper food. One of my favorite hobbies is spending
time on doing elaborate meals using my Kamado Egg barbecue. I also tear
through books and have a goal to read at least 30 books yearly. As
mentioned before, I'm an information sharing addict and mostly do so by
giving talks and doing technical blogs.

If you would like to see more of my rants, you can follow me on twitter
on [\@smitmartijn](https://twitter.com/smitmartijn) or on my blog at
<https://lostdomain.org>

Back to this book; so, I have been dealing with the entire data center
stack for years. One of the things that always annoyed me was that there
was no good solution to troubleshoot and monitor that entire stack; it
was always separate solutions for each layer. In 2014, I came across a
company called ArkinNet, which had an amazing product which could
collect data from multiple layers (storage, compute and networking) and
present this data in a holistic way. After doing some due diligence, I
immediately started talks to include Arkin into our product portfolio
and I've been in love with the product ever since.

Arkin was later acquired in June of 2016 by VMware and it is now known
as vRealize Network Insight.

Let's dive in!

P.S: I've written this book on personal title, not as a VMware employee.
Any opinions in here are my own and not per se the opinion of VMware.

Syntax(?) to-do
===============

Underlines = links

search query = which can be placed in the Network Insight search engine

Foreword by Shiv Agarwal
========================

*Founder of ArkinNet, currently Vice-President of Network Insight with
VMware*

VMware vRealize Network Insight (or vRNI, or Network Insight) has seen a
massive adoption in VMware customer base helping our customers get
end-to-end visibility and operational simplicity as they embrace a
software defined approach to networking and security. Network Insight
completes VMware's Virtual Cloud Network vision and story by providing
seamlessly visibility and converged network operations across the data
center (virtual and physical) and hybrid cloud as well as branch offices
and remote sites (via SD-WAN integration).

Jogging down the memory lane, Network Insight came into VMware through
the Arkin (ArkinNet) acquisition. As it happens so often in Silicon
Valley, my co-founder and I were at VMware before we went out and
started Arkin (in 2013). We had joined VMware (in 2008) as part of the
Blue Lane acquisition. At Blue Lane, we had built a virtual firewall
which became the first-generation virtual firewall (VMware NSX DFW)
inside VMware. During our first tenure at VMware (2008-2013), NSX was in
its infancy. We saw enterprise customers struggling to operate their
virtual networking stack. They were trying to use their existing legacy
processes and toolset. Their people's mindset was geared and tuned to
managing physical networks. Virtualization was new to the network
operators. That's when my cofounder and I got the idea of starting
Arkin. You start a company with a big vision, ours was to transform how
networks are operated. Idea was to bring consumer grade simplicity to
managing networks. We wanted to challenge the status quo. Our first set
of use cases was to help customers implement micro-segmentation and
operationalize NSX. NSX was becoming the dominant network virtualization
stack and we betted on it. We got the first product out in 18 months
with some of the marquee NSX customers using it in production and were
acquired by VMware in 36 months. At VMware, it was like a match made in
heaven. Thanks to the NSX sales team, the two products together (NSX and
Network Insight) started flying off the shelf! It's been fun! I tell my
team often that the acquisition by VMware was a mere pit stop in our
journey, which, at the time of writing this foreword, is still
continuing.

We continue to build. Network Insights expanded charter and scope now
includes end-to-end network operations - monitoring, troubleshooting and
optimization. By combining the different types of network data (flows,
packets, metrics, config, streaming, etc.), we have provided a unique
platform for our customers to converge their traditionally silo-ed
visibility and realize a multitude of use cases around next generation
networking and security. We have also created a unique advantage for
ourselves by adding a strong application context to network and security
dataset. Applications are the lifeline of an enterprise and Network
Insight's powerful application discovery and planning feature enables
our customers to see their network and security data through the lens of
their applications. We are thus elevating IT and empowering them to have
a more business-oriented conversation with their line of businesses.

Over the next few years, we see the operational silos breaking at a
rapid pace and a lot of automation happening, ultimately leading to
self-driving networks. That's the future. Silos create inefficiency and
finger pointing. Our vision is to bring a high degree of efficiency in
network operations through convergence, consumer grade experience and
analytical insights. We continue to deliver upon our vision by investing
in new areas. Recently, we acquired a company, Veriflow, which has
pioneered the area of network verification in software. This technique
is used in many mission critical industries where failure can be
catastrophic such as airlines and space. Networking is mission critical
for our customers. With this acquisition, we will be arming our
customers with network modeling and prediction and significantly push
the frontier of network operations in the enterprises.

I am very happy and excited to be writing this foreword for Martijns
book on VMware vRealize Network Insight. Martijn has been the technical
face and flag bearer of Network Insight in the EMEA region for a long
time. I hope the insights captured in his book will trigger in the mind
of its readers a genuine thought about transforming their network and
security operations.

Pre-face
========

This book is for people in jobs or interests related to networking and
security in private, hybrid and/or public clouds. Managing these
networks and security policies becomes a much easier job with Network
Insight and this book will try to explain best how to go about managing
those networks and how Network Insight itself is positioned to do so.

Sometimes it's not all in the name. This is also true for Network
Insight, as it gives you not just insight into your network, but your
compute, storage and network layers.

With Network Insight, you can take the guesswork out of deploying
micro-segmentation with comprehensive network flow analytics to map out
real-time traffic and model security groups and firewall rules to
successfully implement micro-segmentation security policies. It also
helps to improve performance and availability of the infrastructure by
combining and correlating virtual and physical compute, storage and
networking components to provide a clear and full picture of the
infrastructure.

It does not discriminate between virtual machines or physical servers,
provides detailed information about the smallest workloads (containers),
has integrations with the VMware Virtual Cloud Network vision and
everything that runs beneath the Virtual Cloud Network.

Network Insight collects data from data sources like VMware vSphere,
VMware NSX, Physical network devices (switches, routers, load balancers,
and firewalls), Physical converged systems, IPAM systems and log
collectors. All this information is put in a structured database,
correlated and available via the intuitive user interface and API. The
way this converged information is disclosed with the user interface is
what makes Network Insight unique and such a pleasure to work with.

It\'s all about the fundamentals of the platform, as it's designed from
the ground up to be as open as possible. This means you can retrieve any
and all the data that is gathered and do all kinds of neat things with
it like filtering, grouping, sorting and perform other modifiers on it
(more on that in the chapter []{.underline}

[\
Using the Search Engine]{.underline}).

Apart from configuration and operational data, you can also send
real-time network flow (NetFlow or sFlow) data to Network Insight to map
out which workloads in your environment talk to each other. Because all
data is correlated, the network flow data is linked to the source or
destination workload (virtual machine or physical host) and you can see
the name of the workload related to the flow, instead of just seeing
that **10.0.0.10** talks to **10.0.1.11** over port **80**.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   **Configuration data** is meant as the configuration of the data source (i.e. show running-configuration on a physical Cisco device and the inventory of a VMware vCenter, etc.). **Operational data** is meant as dynamic, changing data on data sources (i.e. the route and mac tables on a network device, IP addresses of virtual machines, etc.).
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

This network flow data is typically generated by the vSphere Distributed
Switch or a physical network device.

Due to the technical and sometimes very specific nature of this book,
it's advised to have a Network Insight instance ready to go while you
are reading; so, you can try things out with data from your own
infrastructure!

The content of this book is based on Network Insight 5.0 (with some
small nuggets on 5.1, because I took too long to write it). Considering
the product team is an innovation engine and moves really quickly
(delivers major features every 3 months), you need to doublecheck the
details when you're using a newer version. This book also does not
intend to replace the [official
documentation](https://docs.vmware.com/en/VMware-vRealize-Network-Insight/index.html),
but rather complement it. The specific technical details in this book
will age, and rightly so.

Introduction to Network Insight
===============================

With all that data the actual use cases for Network Insight are
limitless, but there are four main use cases that will help you get
started get an idea on what to use it for.

Use Case -- Application Security Planning (Micro-segmentation)
--------------------------------------------------------------

Security in the data center is evolving and micro-segmentation is a
technique that's being applied more and more. You can write an entire
book about the technique itself, but I'll give you a quick summary in
chapter [Application Security Planning]{.underline} when we go into the
depths of the micro-segmentation planner.

The hard part about micro-segmentation is where to get started. As a
security person, you need a lot more information about the workloads
then you normally get from the application team or vendor, to properly
perform micro-segmentation.

Using the network flow data and workload information that is collected
by Network Insight, it provides you with a jumping board to accelerate
any micro-segmentation implementation. You'll get clear views into the
communication between workloads and applications and you have the
ability to export recommended security policies that can be applied to
VMware NSX.

![](./media/image1.png){width="6.263888888888889in"
height="3.426388888888889in"}

[]{#_Toc35170156 .anchor}Figure 1 - Global numbers of Network Traffic
movement

![](./media/image2.png){width="6.263888888888889in"
height="3.6458333333333335in"}

[]{#_Toc35170157 .anchor}Figure 2 -- Recommended Firewall Rules --
Grouped by Application

Use-Case -- Getting actual visibility into your environment
-----------------------------------------------------------

Besides using NetFlow data to provide insight into the traffic going
through your network, Network Insight also gathers data from your
private cloud running on vSphere, public cloud on AWS and physical
equipment that helps run those environments. It uses all that data to
paint a complete picture of your workloads, from a virtual machine to
the physical wire between 2 routers to the public cloud instance where
your web server is running.

When it comes to troubleshooting, that is where the gold is. Network
Insight provides a holistic view of your entire environment, which means
you can quickly and easy find root-causes to any issues you're having.

![](./media/image3.png){width="6.263888888888889in"
height="3.1798611111111112in"}

[]{#_Toc35170158 .anchor}Figure 3 - Topology chart: gluing physical and
virtual together

Using the network topology maps, you can quickly determine issues on a
specific network path or using the search engine to look for network
devices that are misbehaving or showing anomalies, your troubleshooting
process can be much more efficient and quicker.

Use-Case -- Doing the health check boogy
----------------------------------------

After getting all of this data from your virtual and physical
environment, Network Insight will check the configuration of virtual and
physical devices against the VMware Knowledge Base (KB) and best
practices. It will provide you with a list of problems in the
configuration and ways on how to fix them.

These problems will be categorized into severities: Critical, Moderate,
Warning & Info and example might be that it has discovered an MTU
mismatch (important when using an overlay) on the physical networking
equipment or if high availability on an NSX Edge is not enabled and
you're at risk for downtime when it needs a fail over.

![](./media/image4.png){width="6.263888888888889in"
height="4.379166666666666in"}

[]{#_Toc35170159 .anchor}Figure 4 - Health Check and Health Alerts

These health checks are a good way to keep your environment in check and
configured as per the latest best practices.

Use-Case -- Migrating to the Cloud (or anywhere)
------------------------------------------------

These days, it's not surprising to have a cloud-first strategy when it
comes to developing and deploying new applications. Public Clouds like
Amazon Web Services (AWS), Microsoft Azure or Google Cloud Platform have
extensive services that save you a lot of trouble having to build your
own. Solidified services like Infrastructure- (workloads), Database-,
Storage- and CDN-as-a-Service are making way for services that can be
used to kickstart application development. Things like Artificial
Intelligence & Machine Learning, Containers, IoT management, facial
recognition, forecasting, serverless, are all being offered as-a-Service
so developers can focus on their actual business requirements and
churning out code for that purpose. Not be side-tracked by creating
their own generic (but mandatory) services which they only need to
support their applications and isn't core business.

What does this have to do with Network Insight, you ask? Well, unless
your organization is starting from scratch and has no history
whatsoever, you're going to have existing infrastructure and
applications. In certain cases, strategies come into life to use public
clouds with IaaS instead of on-premises and applications need to be
migrated towards the public cloud.

This use-case is also valid for migrations in general. Whether it be to
the public cloud, to a different on-premises data center or migration
away a piece of your company. Any scenario where you have an existing
application infrastructure and need to migrate those existing workloads.

Here is where Network Insight can help you out map the application
landscape and discover what talks to each other. Applications are
usually interconnected, even if they shouldn't be, at all. As it's in
the best interest for application performance to keep a grasp on those
interconnections, you need to have a proper map of your application
landscape.

As Network Insight understands application constructs and sees
everything that happens on the network, it will give you the map of your
application landscape on a silver platter. Besides network data, this
map will be supplemented by compute and storage performance data to get
a handle on the needed resources for the migration. You can then turn
around and use this map and plan out your migration.

With a good understanding of the application map, it is much easier to
retain application performance when doing migrations.

A deep dive on this topic can be found in the chapter [Application
Migration Planning]{.underline}.

Use-Case -- Visibility for Containers
-------------------------------------

According to results of a survey that the Cloud Native Containers
Foundation did in 2018, the main concerns around moving containerized
applications into production (and keeping them there & healthy) is
around **Complexity**, **Monitoring**, **Networking** and **Security**.

![](./media/image5.tiff){width="6.263888888888889in"
height="3.9298611111111112in"}

[]{#_Toc35170160 .anchor}Figure 5 -- CNCF 2018 Survey results[^1]

VMware has seen these challenges and is taking them on in several ways.
One of those ways is through NSX Data Center for Containers, where
network virtualization is delivering simplicity, flexibility and
security up to the container level. Operations engineers can use the
same security controls over containers as they can over VMs and make
sure the applications are put into production safely -- whether the
application is hosted on-premises or in the public cloud. That's
**Networking** and **Security** covered.

Network Insight comes in to provide clarity of the container
environment, reducing the **Complexity** and allows you to **Monitor**
this environment for any **Networking** and **Security** related events.
It does this by making connections between the container world,
virtualized world and physical world. In doing so, it creates full
end-to-end visibility in order to make sure the production environment
is up to snuff and no components are acting up.

Network Insight can also be used to plan out the security for these
container workloads. Due to the tight integration with NSX Data Center
for Containers, Network Insight gains the same network flow visibility
as with VMs. This means the same security planner can be used to map out
network connectivity between the different levels of the containerized
application and the best part is that Network Insight can generate
recommended firewall rules based on those real-time network flows. Oh,
and it also allows these recommended firewall rules to be exported in a
format that Kubernetes understands (YAML). Applying these rules is as
simple as performance the export and using kubectl to apply them
directly to a running application.

More on how to do this in the chapter [Application Security
Planning]{.underline}

vRealize Network Insight versus vRealize Network Insight Cloud (SaaS)
---------------------------------------------------------------------

When reading about Network Insight, you might come across two versions
of the name: vRealize Network Insight (or vRNI) and vRealize Network
Insight Cloud (or vRNI Cloud). The reason for this is that there is an
on-premises and a software-as-a-service (SaaS) version.

In 2018, VMware came out with a SaaS version which is hosted on their
Cloud Services (<https://cloud.vmware.com>) infrastructure. The reasons
for this are to simplify deployments and unburden organizations with
upgrades or availability of the platform. VMware takes care of the
upgrades and availability and you can simply consume the product.
Capability-wise, the 2 are equal; they have the same features and same
interface. Everything in this book pertains to both versions.

The architectural components in the on-premises version and SaaS version
are similar, they're only hosted in different locations. The chapter
[Architecture]{.underline} goes deeply into the architecture of both
versions, but here's a sneak peek: Network Insight consists out of
collector nodes and platform nodes. The collectors talk to your
infrastructure endpoints to collect data and the platform is the central
data repository and it is your entry point (the user-interface).

In the on-premises version, both components run on your own
infrastructure (which can even be air-gapped) and you keep everything
local. With the SaaS version, the collectors run locally (in order for
them to connect to your infrastructure) and they send their data towards
the cloud hosted platform nodes.

This usually brings up 2 security questions; how is the data transferred
and what exactly is stored in the cloud? Stay tuned for details on the
transfer in the [Architecture]{.underline} chapter, but let's have a
look at what data is stored inside the platform.

Collectors look at data center infrastructure equipment (switches,
routers & firewalls) configuration like firewall rules and switchport
configurations, virtual workload environments for virtual machines,
network traffic flow data (optional but valuable) where source,
destination and protocol are recorded. Of the virtual machines the
metadata is recorded (network settings, hostname, OS type, etc.) and
cross-linking is done between the different data types. For instance, a
network flow can have a VM tagged to it if the VM was either the source
or destination of the flow.

It is contained to infrastructure metadata and network flows though, no
user or application data from inside the VM is collected. This makes it
a lot easier to determine whether you could host this metadata in the
Cloud, as most governmental regulations about data locality pertain to
user and/or application data.

If you can make use of hosted version, it does save you a bunch of
management effort by outsourcing that to VMware.

 Virtual Cloud Network
=====================

Network Insight fits neatly into the Virtual Cloud Network (VCN) vision
of VMware and to set the stage, let's talk about the Virtual Cloud
Network for a moment.

Networking itself is not new to VMware. They have been doing virtual
networking for more than a decade in the core of virtualization and it's
been said VMware is the leading vendor with most used switch ports on
the virtual switches inside vSphere. In 2009 VMware released vShield
Networking & Security to branch out to all kinds of networking services,
such as firewalling, routing, load balancing, VPN, NAT, etc. That
evolved into NSX for vSphere and NSX for Multi-Hypervisor Center, which
were released in 2013.

Since then, NSX has turned into a platform for networking & security
that extends throughout the entire enterprise network. With NSX Data
Center providing services for applications hosted in the data center,
NSX Cloud that integrates natively into public clouds to allow the same
security policies everywhere (instead of point-solutions per cloud), NSX
SD-WAN by VeloCloud to bridge the gap between branch locations and the
data centers and clouds, AppDefense for zero trust application security
on the operating system level, to NSX Hybrid Connect (HCX) that makes it
possible to migrate workloads between the different places where these
workloads can live.

![](./media/image6.tiff){width="6.263888888888889in"
height="1.2979166666666666in"}

[]{#_Toc35170161 .anchor}Figure 6 -- VMware NSX Portfolio

This translates to uniform networking & security policies and services
that can be delivered anyplace that can run software (so, everywhere).
As application workloads keep spreading out from the data center towards
more locations to be either close to their data and operating spaces
(IoT is really becoming a thing), or locations that have specialized
services (AI/ML as a Server, Function as a Service, things like that),
we can keep the same network & security policies in place, we can
deliver the required networking services on all locations, and we can do
that without having to learn the platform specific networking
components.

The Virtual Cloud Network is already being delivered by this family of
products and will only get better whilst they get more and more
integrated.

Network Insight is at the center of these developments, integrating
tightly with NSX and the underlying transport networks, making sure you
can monitor and troubleshoot the Virtual Cloud Network and the
underlying physical networks that are being used. It is the main
operational dashboard from where the health of the network is found and
where each individual component can be found and be seen in the big
picture of the entire network. You can zoom in on components that are
misbehaving and troubleshoot them in context of the configuration and
status of neighboring components.

Network Insight is used for planning purposes to determine what
dependencies there are in order to migrate applications between
locations and determine what impact such an operation has on network
performance. The same insights can be used to properly plan security
policies for the applications living inside the network, making sure you
can secure your applications -- where ever they might go.

![](./media/image7.tiff){width="5.581395450568679in"
height="5.486102362204725in"}

[]{#_Toc35170162 .anchor}Figure 7 -- VMware Virtual Cloud Network

Network Insight is the key to making the Virtual Cloud Network vision a
reality. By broadening the insights to everything in and around the
Virtual Cloud Network, it allows you to execute on this vision, while
keeping it easy to operate and maintain.

Application Security Planning 
=============================

The Security Planner (or micro-segmentation planner) inside Network
Insight is arguably the most used feature, for organizations just
starting out. It is the least impactful and most easy feature to turn on
for an infrastructure and results are almost instant. Point it towards
the infrastructure and turn on network flow collection, and it will
provide insights in 1 to 2 hours after installation.

Micro-Segmentation?
-------------------

If you're never heard of micro-segmentation, you're succeeding in
staying very, very far away from the networking and security world and
probably not reading this book. ;-)

For a quick refresher; micro-segmentation is a least-privilege
architecture for the network. It is a security concept that is used to
allow only the minimal amount of network access to applications and
users within the data center. In the hypervisor world (and growingly
outside hypervisors), VMware NSX™ allows network, security and/or
infrastructure admins to define granular security policies that lay the
foundation for a zero-trust architecture.

Zero-trust is basically security turned on its head: we don't allow
anything, unless specifically defined in a security policy. Traditional
security architectures only do this in the DMZ, if at all, leaving the
doors wide open in the data center itself. Applications that have
nothing to do with each other can talk to one and other. These
applications have different security levels, making the weakest link the
highest barrier to get over in order to gain access to the internal
network and, by extension, other applications.

With a zero-trust architecture, using micro-segmentation, security
policies (which are translated to basic firewall rules) lock down each
workload, whether it be a virtual machine, container or a user, making
sure that workloads can only access necessary network resources and
nothing more. A simple example of this would be that your company blog
based on WordPress, should never be allowed to talk to your CRM system.

To learn more about VMware NSX and how it helps you to do
micro-segmentation, have a look at the free eBooks named [VMware NSX®
Micro-segmentation Day 1]{.underline} and [VMware NSX®
Micro-segmentation Day 2]{.underline}.

![](./media/image8.tiff){width="5.336633858267716in"
height="3.2966437007874014in"}

[]{#_Toc35170163 .anchor}Figure 8 -- Micro-Segmention; logical security
boundaries between applications.

The Challenge of Micro-Segmentation
-----------------------------------

When you start treating all your applications in a zero-trust way,
there's usually one big question that arises: "Do I actually have to put
in work to achieve zero-trust? Can't I just click a button?"

Achieving zero-trust, while never unachievable, indeed needs work. When
you start treating your applications as if they are all in a separate
DMZ, security policies need to be formed for it to work and those
security policies need to contain all network connectivity that an
application needs. Forget to include a critical port in the security
policy and the application simply doesn't work.

If you put in the work, the rewards of securing your applications are
worth it. Organizations around the world are doing it.
Micro-Segmentation is real progress towards a more secure
infrastructure, or at least it will help in limiting the blast radius of
any incident.

Getting the information needed in order to implement micro-segmentation
is the hard part. Legacy applications are everywhere, and application
vendors used to be pretty bad at documenting anything related to the
network (as networks were pretty flat and should "just work" -- right?
Dude?). And before the voice in your head gets too loud: yes, we're
still not always good with documentation. But at least most application
vendors now know networks and security are a thing they need to
consider.

So, there are a lot of applications that aren't documented, which forces
you to resort to primitive methods of finding out what applications
need. Like using port mirrors to sniff all traffic, logging into servers
and checking which ports are opened by applications, logging all traffic
to a massive syslog repository and manually create reports on which
ports you need. This all translates to a lot of manual labor.

Speeding up Micro-Segmentation
------------------------------

The micro-segmentation planner feature in Network Insight listens in on
real-time network traffic and analyses that information to provide you
with a starting point for implementing micro-segmentation. It does this
by accepting protocols like NetFlow, IPFIX and sFlow which almost all
networking components (switches, routers, firewalls) can generated. More
on the protocols later, but they all generate reports on real-time
network traffic with an IP source, IP destination, protocol and port
number. The metadata of your actual network traffic.

Network Insight takes these reports with the metadata of the network
traffic, links them to application data (virtual machines, physical
servers; workloads that form the application) and generates recommended
security firewall rules for your existing applications.

It provides you with a starting point for micro-segmentation. After
collecting network flows for a few weeks, you can generate the
recommended firewall rules and do a reality check on them. It'll tell
you what exactly is happening in an unsecured infrastructure, which not
necessarily means that all that is actually supposed to be happening.
You'll discover cross-application communication, which is not supposed
to happen, find that admins are accessing management interfaces
(RDP/SSH) from anywhere but the management network. In any case,
security policies on paper that aren't being followed. It happens
anywhere where it's possible, don't be surprised.

How does it work?
-----------------

Network Insight ingests metadata from real-time network traffic and
relates that to other data it already sees from the infrastructure. This
way it can determine which network flows belong to which virtual
machine, container or application. It knows which network flows are
currently in use by the application, show this in a very presentable way
and will make recommendations on the required firewall rules needed to
micro-segment an application.

It is also keenly aware of the VMware NSX dynamic security policies and
uses Security Groups and Security Policies to group VMs, networks,
applications (or whatever fits the best scope) to make sure the amount
of firewall rules are minimized to the bare minimum, so it creates the
best manageable configuration.

NetFlow, IPFIX & sFlow
----------------------

Ingesting of the network traffic flows can happen via three different
protocols: **NetFlow**, **IPFIX** and **sFlow**. All three protocols do
basically the same thing, only in different formats. They usually run on
switches or routers where all the network traffic goes through.

In the basis, they listen to all network traffic sent over the network
device and keep a list of traffic flows in a format of source IP,
destination IP, protocol (TCP/UDP/etc), network port number, the number
of packets and the size of the packets in bytes.

This list is then sent out to a collector for processing. In this case,
Network Insight is the collector.

NetFlow originated from Cisco in 1996 and can be used on a plethora of
physical switches. Of course (most) of Cisco's own network devices, but
also Juniper, Brocade, Palo Alto Networks and a bunch of other vendors
support it. Network Insight supports NetFlow version 5 through version
9.

IPFIX is a spinoff from NetFlow (version 10) where devices can put
custom information into the headers. vSphere uses version this when it's
enabled on the vSphere Distributed Switch (VDS). When you enable flows
via the VMware vCenter registration when adding it as a Data Source,
Network Insight will configure the VDS to send IPFIX to the Collector.

sFlow is short for sampled-flow, which means it stores 1 out of *N*
packets. Standards for *N* are in the range of 200, 500 or even 2000.
The higher you go, the lower the completeness will be of the incoming
data. This is done to ensure scalability of the protocol and to make
sure the network device is not overloaded. Most devices that only
support sFlow, don't have a lot of processing power for anything other
than forwarding traffic.

+------+--------------------------------------------------------------+
| INFO | There's much more to these protocols that I'll share here.   |
|      | If you want to get a deep dive (including what the headers   |
|      | look like), their Wikipedia pages are a good start:          |
|      |                                                              |
|      | NetFlow: <https://en.wikipedia.org/wiki/NetFlow>             |
|      |                                                              |
|      | IPFIX:                                                       |
|      | <https://en.wikipedia.org/wiki/IP_Flow_Information_Export>   |
|      |                                                              |
|      | sFlow: <https://en.wikipedia.org/wiki/SFlow>                 |
+------+--------------------------------------------------------------+

An important note is that you cannot use sampling if you want to capture
the right flows. Sampling means that just a sample of the data is
reported, for example 1 out of 10 flows. Considering Network Insight
will recommend firewall rules to be applied on an application, you don't
want to have 10% of the required firewall rules, you want 100%. If your
network device cannot do non-sampled flows, find another way to get full
visibility.

While sFlow is supported, I generally would not recommend using it if
you have the choice between NetFlow and sFlow. If you only have the
option for sFlow, try to get a non-sampled data stream and be more
vigilant in determining whether the recommended firewall rules are
complete.

More information on how Network Insight ingests and processes incoming
network flows, is described in the chapter [Flow Processor]{.underline},
which is under [Architecture]{.underline}.

Configuring Data Sources for NetFlow, IPFIX & sFlow
---------------------------------------------------

To collect network flows from your environment, a flow data source has
to be added to Network Insight. If you're running a vCenter data source,
you can enable the IPFIX configuration straight from the data source
configuration page. This option will configure NetFlow on the vSphere
Distributed Switch and have it send flows to the Collector the vCenter
is added.

![](./media/image9.png){width="6.263888888888889in"
height="1.3534722222222222in"}

[]{#_Toc35170164 .anchor}Figure 9 -- Enabling NetFlow on a vCenter data
source

Because the VDS is the only virtual switch that supports sending
NetFlow, it is required to have your VMs run on the VDS and not a
standard vSwitch.

This process is the same for NSX data sources (both NSX-V and NSX-T)
where you can configure NSX, so it starts sending NetFlow to the
Collector, straight from the Network Insight interface.

Besides using the VDS and/or NSX to collect NetFlow data, you can also
configure physical network devices to send NetFlow or sFlow to Network
Insight. With this, you gain insight into the traffic flows between
physical only hosts and not only see the flows where a virtual machine
is involved. To prepare Network Insight to receive these flows from
physical network devices, you need to add a "Physical Flow Collector"
data source.

![](./media/image10.png){width="3.8157895888013997in"
height="1.9743110236220471in"}

[]{#_Toc35170165 .anchor}Figure 10 -- Adding a Physical Flow Collector
data source

This has to be a separate Collector VM and cannot be a Collector where
other data sources have already been added. The decision to do so, is
purely related to performance of the Collectors. The one that will be
used for these physical flows is exactly the same as a Collector that's
being used to gather data from vCenter and has exactly the same services
running.

Ingesting and processing network flows is the most resource intensive a
Collector can do.

  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   In order to receive NetFlow and/or sFlow from physical devices (not vCenter or NSX), you need a dedicated Collector appliance for that specific purpose. You will only be able to add a flow data source on a Collector that's not already used by other data sources.
  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Analyzing Network Flows
-----------------------

Let's get into the meat of the Micro-Segmentation Planner and how to use
it. The network traffic flow data is presented from a very high-level
for your entire infrastructure, to a per object level (per network,
application, resource pool, these kind of objects) to a very granular
per flow record level.

Starting from the high level; this is a good view to see what kind of
behavior is happening inside your infrastructure. It shows how much of
your traffic is North-South and how much is East-West, how much of it is
VM to VM and how much is routed versus switched traffic. It also gives a
quick view of which network ports are being used most.

![](./media/image11.png){width="3.548672353455818in"
height="3.6686668853893263in"}

[]{#OLE_LINK3 .anchor}Figure 11 -- High level overview of network
traffic behaviour

On the left of the high-level overview is what I like to call the "donut
of joy". You have to find joy in the little things of life and for me
this is one of those things. This donut presents a very clear view of
what network traffic flows are happening, grouped per object. By
default, the slices are grouped by network (vCenter port group) and you
can change the grouping to any available workload object, for example;
application, VM, subnet, vCenter folder, NSX Security Tag or an AWS VPC.

![](./media/image12.png){width="3.786324365704287in"
height="3.909185258092738in"}

[]{#_Toc35170167 .anchor}*Figure* *12 -- Micro-Segmentation Planner; the
donut of joy*

As with most of the Network Insight interface, you can click on any of
the slices or connection lines and get the data that's behind the
picture.

It is worth noting that the micro-segmentation planner can also be used
to plan out regular zone security. While the network security industry
is mostly focused on micro-segmentation these days, it is a very valid
approach to have a layered security architecture. Use a
micro-segmentation approach for your important applications ("crown
jewels" with access to important data) and regular zone-based security
for your less important applications. Especially in the beginnings of a
micro-segmented (brownfield) network, you should start with enabling
micro-segmentation for the important applications and work your way
down.

If you either group by network or subnet, you can use the provided data
to enable zone-based security.

### Group By

Each slice in the donut is represented by the group you select in the
**Group By** option. You can group the slices by all available objects
inside Network Insight, from Applications, to Networks, to AWS VPCs, to
Cluster, etc. This way, you can create the view that you need, whether
you're just inspecting traffic flows between logical data centers or
working to micro-segment your applications. The grouping also affects
the way recommended firewall rules are displayed, which I'll talk about
later.

### Scope

The donut can also be limited to a **Scope**. Put in a certain parent
object (vCenter, resource pool, etc.) and the donut and recommended
firewall rules will be limited to that specific scope. This is very
handy when you're working on micro-segmentation on a per data center or
per cluster basis.

When grouped by application, the donut displays connections between
applications and the outside world (physical servers and/or the
internet). When grouped by VM and scoped for a specific application, the
donut will reveal all connections between VMs inside that application,
making it easy to determine how the application is structured.

### Flow Type (NSX Flows)

You will also see a "Flow Type" select box, where the integration with
VMware NSX comes in to play. When you have enabled IPFIX on the NSX Data
Source, the Distributed Firewall of NSX also starts sending IPFIX to
Network Insight. The added value of doing so, is that NSX will also send
flows that are blocked from going on the network by the Distributed
Firewall. It will also flag allowed flows with a matching firewall rule
ID (if any), which makes it possible for Network Insight to correlate
flows to existing firewall rules.

This means you can easily see any unprotected flows, which are not
protected by any firewall rules, and create sort of a 'to-do' diagram of
network flows you still need to micro-segment.

  ------ ------------------------------------------------------------------------------------------------------------
  INFO   In order to see protected, unprotected and blocked flows, you need to enable IPFIX on the NSX Data Source.
  ------ ------------------------------------------------------------------------------------------------------------

At the time of writing Network Insight does not run intelligence over
the discovered firewall rules from either NSX or other virtual or
physical firewall to determine whether a network flow 'could' hit a
specific firewall. The flow output of NSX is the only that contains an
actual firewall rule ID which the flow is hitting, making it definitive
that it's using that specified rule. For other network flow sources,
Network Insight would have to deduce which firewall rule would overlap
with which firewall rule to say, 'it *might* be hitting rule x' as
there's no definitive proof it's hitting those rules. The Network
Insight has currently opted for certainty in this feature.

  --------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  PRO-TIP   When working to micro-segment your environment, use the unprotected flow type to see your progress and use it to export the missing recommended firewall rules that you need to finish securing your applications.
  --------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Recommended Firewall Rules
--------------------------

Behind every slice of the donut and every directional line (the line
between slices) is a popup that displays a couple of things:

-   **Services in this group**: Port numbers of services inside this
    slice that are being used by external hosts. For example; port 443
    as a webserver by users.

-   **External Services Accessed**: Port numbers of services that this
    slice is using. For example; port 123 for NTP synchronization.

-   **Flows (Incoming and Outgoing)**: The raw network flows on which
    the rest of the data is based upon. It'll display a list of source &
    destination IP, protocol and port number and a nice bandwidth graph
    of that specific flow.

-   **Recommended Firewall Rules**: Based on the services inside the
    slice and the external services accessed data, Network Insight will
    provide a list of recommended firewall rules you should use to
    micro-segment the workloads in this slice.

While the Services tabs and Flow tab provides some great insight into
what's running in a specific slice and you'd be able to use that
information to quickly determine what services are running in it and
what services it is consuming, the Recommended Firewall Rules are the
real actionable results.

![](./media/image13.png){width="6.263888888888889in" height="4.225in"}

[]{#_Toc35170168 .anchor}Figure 13 -- Recommended Firewall Rules grouped
by Application

These firewall rules are what you need to enable micro-segmentation for
the workloads inside the slice.

Important to note is that the Recommended Firewall Rules will group its
rules based on the slice grouping you've selected for the donut. If you
selected the network ("VLAN/VXLAN Overlay") as the group, you will get
Recommended Firewall Rules on a per network basis. If you select VM to
group by, the recommended rules will be on a per VM basis, and so on.
This is why I'll always recommended to put the donut in the per
application view and focus on your applications.

In real-life, you will want to micro-segment based on applications,
which is in the sweet spot between being too granular and too high
level. Go too granular (per VM) and you will end up with way too many
rules and will the firewall rule list unmanageable. Go too high level
(per resource pool, data center, etc.) and your applications will not be
fully protected. Of course, there are exceptions where you'd want to
allow shared services to have a single firewall rule, allowing the
entire data center to use the shared DNS servers, but the application is
what it should be all about.

Now that you know where to find the Recommended Firewall Rules and what
to use them for, let's talk about how to use them.

### Exporting Recommended Firewall Rules

These Recommended Firewall Rules can be the basis for your
micro-segmentation project and there are a few ways you can consume
them, depending on how you're doing the actual micro-segmentation.

First thing which you should decide is how the source and destination
groups will be determined. As you might recall, the source and
destination groups are decided by the Group By option. Only by necessity
should you use different groupings in different firewall rules,
otherwise it will quickly get very confusing. So, first decide on what
your micro-segmentation will be based on.

This will also depend on what technology is used to do the actual
micro-segmentation. VMware NSX Data Center would be a natural choice,
but Network Insight is not biased in providing the right information
(except for the NSX targeted export, more on that in [Export as
XML]{.underline}). If you can group workloads into applications and
effect firewall rules on that level, do so. Otherwise you can choose the
lowest applicable grouping to get the rules that you can use in your
security solution.

#### Export by 'Looking at it' ™

After choosing the right grouping, there are a few ways you could use
the generated recommended firewall rules. The first one is the easiest;
just look at them and translate them to your security solution of
choice. Manageable for a small environment with not that many firewall
rules.

When the environment gets a little bigger and the firewall rules grow,
this method may not be scalable. But fear not, there are other ways!

At the top right of every donut or table that shows the network flow
data, is a menu. Three dots represent that menu and can be opened to
reveal a few options. Exporting options include exporting as comma
separated values (CSV), extensible markup language (XML) and YAML (YAML
Ain't Markup Language).

  ------ -----------------------------------------------------------------------------------------------------------------------------------------
  INFO   Currently, only exporting of recommended firewall rules is supported when you group by application, application tier or security group.
  ------ -----------------------------------------------------------------------------------------------------------------------------------------

I'll go through each option below.

#### Export as CSV

A CSV is a plain text file that holds values that are separated by a
comma. It can be used to input into a scripting language and act on the
data, or simply be transformed into an Excel sheet where the data can be
manually modified.

This option is used most to aggregate multiple exports together and
apply the rules in one big change window. It also often happens that a
micro-segmented environment already has a security policy model in
place, which dictate how the configuration should be applied. It'll have
a naming scheme for the security policies, groups and tags.

Network Insight will provide you with suggestions on how to name these,
but you might want to change those suggestions. That's where you can
take the recommended firewall rules in a CSV format to get a starting
point on which rules should be in place and then translate that to your
own security model.

#### Export as YAML

When integrating Network Insight with VMware PKS (PKS stands for Pivotal
Container Service), Red Hat OpenShift, or vanilla Kubernetes, the option
to export recommend firewall rules in a YAML format is enabled. As
Kubernetes takes its configuration in the same format, you can use this
export format and feed it directly into the container configuration
files.

Keep in mind that the option to export as YAML, will only be enabled
when the **Group By** setting is set to Kubernetes Namespace or
Kubernetes Service. These are the only objects that can have security
policies implemented. When exporting as YAML, Network Insight will
provide you with a zip file to download, which contains separate YAML
files per network policy between different Kubernetes services.

![](./media/image14.png){width="6.263888888888889in"
height="1.8208333333333333in"}

[]{#_Toc35170169 .anchor}Figure 13 -- Recommended Firewall Rules YAML
export

There are different files per security policy, so it's easy to edit the
security policies that you actually want to apply. There could be
communication between services that should not have anything to do with
each other. As as example, here's the recommended security policy that
makes sure my yelb-ui service has access to the centralized DNS service:

Because the files are split up per security policy, they are easy to
read. It also helps that the Kubernetes network policy format is not
that hard. Applying these security policies to Kubernetes is *really*
simple; it's just one command. After making sure all the security
policies are to be added, run this command: **kubectl apply -f \*.yaml**

Make sure kubectl is connected to the right cluster and it's selected
the right namespace, of course. After applying the policies, Kubernetes
will make sure they are applied to the services (or namespaces). This
could be enforced by VMware NSX, or any of the other security tools that
Kubernetes supports.

#### Export as XML 

Lastly, there's the option to export the rules in an XML format. This
export function will provide you with a zip bundle that contains all
needed configuration for VMware NSX for vSphere (NSX-v). XML is the
format of choice when it comes to API calls for NSX-v. As Network
Insight uses the 'proper' way of micro-segmenting within NSX-v, the
contents of the zip bundle contain multiple XML files that contain API
body to create certain things: security tags, security groups, security
policies and the assignment of security tags to VMs.

You would only use this export to feed it into the NSX Importer Tool.
This tool reads in the zip bundle, retrieves the XML files and feeds
them to the NSX-v API. Because this is only based on NSX for vSphere,
which has been announced to go end-of-support in 2023[^2]; I don't
expect this format to be used anymore (and won't go into it here).

Because [VMware NSX
Intelligence](https://www.vmware.com/products/nsx-intelligence-analytics-engine.html)
in NSX-T 2.5 and above has the same feature, a direct import from
Network Insight into NSX Security Policies doesn't make much sense.
Network Insight has a broader view of the network and can recommend
security policies on a much larger scale, taking physical servers, or
physical zones (end-users, DMZ, test, etc.) into account, it remains to
be the best way to implement security policies across the entire
network. NSX Intelligence can take care of the micro-segmentation inside
the NSX network fabric.

Using the Recommended Firewall Rules
------------------------------------

Armed with all the information from the previous chapters, you are now
able to generate recommended firewall rules based on a specific
application and scope it so that you can discover its dependencies.
Taking this information and fueling a micro-segmentation project is a
different beast, as there are steps to be taken in a certain order.
After working with different types and sizes of organizations going
through segmentation projects, here's what I see as a best practice.

### Step 1 -- Application Segmentation

First, start with the application boundary and implement segmentation on
that boundary. Here's where you look at the Security Planner grouped by
Applications. You'll get 2 things of out this view; application
dependencies (because you can see which applications use other
applications) and the recommended firewall rules to segment the
application.

For example, a standard 3-tiered application (web, app and db) would
show other applications using this application, but typically it would
only show the web servers (or maybe the app servers) being addressed by
these other applications. By implementing application segmentation, you
protect the application itself from unauthorized network connectivity
from outside and would typically result in only the web servers being
accessible from outside the application over ports 80 and/or 443.

### Step 2 -- Tier Segmentation

Depending on how big the application and its tiers are, this step could
be skipped. It's also a matter of how much resources (read: time) there
are available for the segmentation project and how strict any
regulations are that apply to an application. If the application is
small enough and you want to spare some time, go straight to step 3.

It is also possible that you do not need complete micro-segmentation and
the tier level segmentation is good enough, depending on your defined
security policies and risk analysis. If so, this could be your last
step.

I see you're still here; good! You've already protected the application
from unauthorized outside connections, let's move on to
intra-application connectivity. Tier segmentation is all about
protecting the tiers from each other, inside the same application. Only
allowing the necessary traffic between the web and app and then between
the app and database tier. Typically, the web tier does not have any
business connecting to the database tier.

Go ahead and use the Scope feature on the Security Planner to limit the
view to the specific application you're working on. The default view
that pops up is the view we need; grouped by Tier.

![](./media/image15.png){width="3.9074070428696412in"
height="4.21844050743657in"}

[]{#_Toc35170170 .anchor}Figure 14 -- Recommended Firewall Rules grouped
by Tier

From here, you have the option to look at intra-application
communication flows, get the services running inside each tier and
generate the recommended firewall rules based on the tiers. Meaning
you'll get recommended firewall rules like "web needs port 80 and 443
from source any" and "web needs port 8443 to the app tier" -- etc. Take
these rules and implement tier segmentation. After which, you'll have
protected the tiers from each other; i.e. web servers can no longer talk
to the database servers.

### Step 3 -- Micro-segmentation

Now for the final step; complete micro-segmentation. This is where we
limit connectivity between VMs inside the same tier. For example; no web
to web server connectivity (unless there's a clustering mechanism in
play).

Use the Security Planner, Scope on the application you're working with
and then group by VM. The view that is presented to you, is all
intra-application communication on a per-VM level and recommended
firewall rules will be available that will tell you which firewall rules
to implement on each individual VM.

If you have VMware NSX integrated and also receiving network flows from
it, you can also select **All Unprotected Flows** on the **Flow Type**
option, to make it even easier on yourself. This option will only show
network flows that are not going through an NSX Distributed Firewall
rule, excluding the previously implemented inter-application
segmentation and the previously implemented tier segmentation. This
should only leave the communication that's happening between VMs inside
the same tier. Take the recommended firewall rules of the intra-tier
communication and implement them. And voila! You have now implemented
micro-segmentation.

### Details I left out

Obviously, these 3 steps are only about Network Insight and how to use
the data that it collects and correlates to go about a segmentation
project. I did not go over how you should take these recommended
firewall rules and design a security policy framework around it, using
everything that VMware NSX (or the other security product that you're
using) has to offer. Security groups, security policies and security
tags should all be used to make management of the micro-segmented
network easier and faster. There is a lot of content out there that
defined how to put together such a security framework.

Proving Security & Auditing for PCI
-----------------------------------

Apart from planning out application security using the
micro-segmentation planner, the donut of joy can also help speed up
auditing processes. It lays out all communications between applications,
networks, VMs, and more. Using the graphical display (the donut), you
can instantly confirm, visually, that an application is not talking to
anything that it's not supposed to talk to. You can save the donut for
each critical application into a report and present that data to the
auditors.

What also helps is the PCI Compliance Dashboard, which takes the PCI
sections that are relatable to infrastructure and shows you their data
in a single dashboard. Along with the snapshots of the
micro-segmentation planner donut to prove network traffic flows, you can
export the PCI Compliance Dashboard as a PDF and attach that to the
information for the auditor to speed up the audit.

As audits are not only geared towards technical configurations, this
data is not going to be enough for you to pass an PCI audit. It is only
supporting for the technical aspects of PCI or other compliancy
certifications and you will still need to put processes in place in
order to achieve a compliancy certification.

The PCI Compliance Dashboard currently helps by displaying the following
data behind these PCI sections:

  PCI Section   Description                                                                                                                                        How Network Insight helps
  ------------- -------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------------------------------------------------------
  1.1.1         *A formal process for approving and testing all network connections and changes to the firewall and router configurations.*                        Shows all firewall rules applicable, network config changes and network flows.
  1.1.2         *Network diagram that identifies all connections between the data environment and other networks.*                                                 Shows network topology maps & inter- and intra-application network flows.
  1.1.3         *Network diagram that shows all data flows across systems and networks.*                                                                           Shows network flows in donut and raw form.
  1.1.4         *Requirements for a firewall at each Internet connection and between any demilitarized zone (DMZ) and the internal network zone.*                  Shows firewall rules applicable to workloads, to determine DMZ-yness.
  1.3.1         *Implement a DMZ to limit inbound traffic to only system components that provide authorized publicly accessible services, protocols, and ports.*   Same as above.
  2.3           *Encrypt all non-console administrative access using strong cryptography.*                                                                         Shows all network flows that are using known unencrypted protocols.
  6.4           *Follow change control processes and procedures for all changes to system components.*                                                             Shows all security changes (firewall rules, security groups, tags & policies).

[]{#_Toc35170257 .anchor}Table 1 -- PCI Dashboard; PCI sections
explained

Application Discovery
---------------------

Micro-segmentation was first focused on the workloads themselves (VMs,
containers), but it gradually shifted towards the application as a
whole. Which makes sense, because the application is what's really
important. That the application is powered by some VMs doesn't matter
anymore; we just want the application to be available and secure.

There's been a shift towards application context inside Network Insight
as well. For example, the Application Dashboard is a relatively new page
where you can troubleshoot the application itself directly, with all
components (VMs, network devices, etc.) that support this application
listed and monitored. You can directly look at the application network
flows in real-time and notice any problems with the infrastructure on
the application level.

To get to this application dashboard, we need to have so-called
application constructs inside Network Insight.

### Application Constructs

Inside Network Insight, there are application constructs which you can
create. An application construct is pretty straightforward: it is a
logical container with a name and tiers. These tiers define what
components are associated with the application, by providing a virtual
machine pattern (or simple the exact name), static IP addresses,
Kubernetes objects; all workloads that have a specific network service
running, or other vCenter or NSX objects (like resource pool, security
tag, folders, you name it). You can also provide a custom search query
which can determine which virtual machines are included.

Here's an example with a simple 3 Tier Application. It's made up out a
Web tier, App tier and Database tier. All tiers will have VMs in there
which are responsible to serve as a web, application or database server.

![](./media/image16.png){width="6.263888888888889in"
height="2.3333333333333335in"}

[]{#_Toc35170171 .anchor}Figure 15 -- Example application construct

If you put application context together with the data already in Network
Insight, you get a full-stack view and will be able to do application
specific tasks like micro-segmentation planning, monitoring and
troubleshooting.

You should always aim to have your entire application context
synchronized to Network Insight. Meaning; create those application
containers.

Through the magic of telepathy, I hear you thinking "I have a couple
thousand applications with more virtual machines supporting those
applications, there's no way I'm going to create those application
containers manually!"

Well, you're right. Don't do it manually because each time you execute a
repetitive task, a kitten dies. That's why there is application
discovery.

Now, these application constructs can be added in a few ways; manually,
via the API, and they can be discovered directly from the infrastructure
metadata or be fetched from a Configuration and Management Database
(CMDB) like ServiceNow (just ServiceNow, at the time of this writing).

You can automate the creation of these application constructs by using
the API and have your infrastructure automation tool (such as vRealize
Automation) call Network Insights API to create it, when there's an
automated application deployment happening. I've got an example doing so
in the chapter **Automation Use Cases**. You can also use a pretty
simply script to import a list of application constructs and get them in
that way. Those methods depend on either having an automation tool or a
complete list of your applications, which is not always the case. That's
why Network Insight also does application discovery using metadata from
the infrastructure itself. It can use tags (vCenter custom attributes,
public cloud tags, Kubernetes labels. Basically, any tag that can be
placed on a workload), a naming convention or it can match up workloads
listed in the ServiceNow CMDB and pull the information from there.

Important to note is that these discovery methods work independently
from each other and can be run multiple times with different values. If
you have multiple naming conventions in the infrastructure; just run the
discovery multiple times, using different expressions for the right
naming convention.

All discovery methods have the same output and workflow to use, which
makes it easy to get the hang on them. Let's go through each of the
discovery methods and see how they work. I'll use the first method,
tags, to go through the wizard in depth in order to lay out the flow and
use that foundation in the discovery methods that follow. So, even if
you don't use tagging, it's wise to go through the next chapter before
you move on to the naming convention or the CMDB discovery methods.

### Tags or Custom Attributes

VMs, instances in public cloud (AWS EC2) and Kubernetes workloads can
have tags or labels to give them a little more context into what they
are for. These tags are free text, so they can indicate anything that
you'd like. A common use case for these tags is to indicate which
application a certain workload is a part of and what role (tier) it
fulfills inside that application.

Infrastructure automation platforms like vRealize Automation can also
tag deployed workloads with their respective application name and tier
name, as defined inside the blueprint that is being used to deploy these
applications. In any case, let's focus on an example using vCenter
custom attributes.

Tags and custom attributes are going to be used intertwined in the
upcoming paragraphs, as Network Insight uses the generalizing term tags
when it's referring to a key value tag. Inside vCenter, the key value
tag is called a custom attribute.

Inside vCenters' Tags & Custom Attributes page, you can define a custom
attribute that exists of a key and value set. Both are free text; the
key can be used to name the custom attribute and the value can be set on
each VM separately.

![](./media/image17.tiff){width="6.263888888888889in"
height="1.8631944444444444in"}

[]{#_Toc35170172 .anchor}Figure 16 -- vCenter Custom Attribute
definition

In the above screenshot, I have defined 2 custom attributes called
**Application-Name** and **Application-Tier**. These attributes can then
be placed on a VM and given a value. Here's an example of 2 VMs that are
a part of 2 different applications and also 2 different tiers.

![](./media/image18.png){width="4.930435258092738in"
height="1.959601924759405in"}

[]{#_Toc35170173 .anchor}Figure 17 -- Custom Attributes on a VM

These VMs are a part of 2 different 3-tiered applications consisting of
a Web, App and DB tier. As you might deduct from the screenshots, the
left VM is a part of an application called **VMworld-3TA01** and resides
in the **App** tier. The right VM is a part of the **VMworld-3TA02**
application and is a part of the **Web** tier.

Once these custom attributes are in place and can be used to discover
the application constructs, head to the applications page in Network
Insight. Once you're there, you will have 2 tabs presented to you: Saved
Applications and Discovered Applications. The saved applications are
available throughout the system and will have infrastructure data (VMs,
flows, events, etc.) correlated to them. Using the discovered
applications makes it easy to fill up the saved applications.

There will be 3 discovered methods available, and each will have their
own sub-tab: Tags, ServiceNow and Name. Let's focus on the Tags page for
now.

You're presented with a brief wizard-like flow where you first can
indicate a Scope. This scope is a way to limit the discovery to a
specific section of the infrastructure. For example, you can select a
vCenter, AWS VPC, Resource Pool, Subnet; any object that Network Insight
can relate back to a workload.

![](./media/image19.tiff){width="6.263888888888889in"
height="3.5555555555555554in"}

[]{#_Toc35170174 .anchor}Figure 18 -- Application Discovery using Tags

After selecting the scope, it'll ask you for the name of the tag for the
application name. In the case of this example, I've selected
**Application-Name** as the custom attribute that it will be using to
discover the application names from. You can also limit the tag value
discovery by changing the "and Any value" that's to the right of the tag
name. This will allow you to limit the discovery to very specific
application names and ignore the rest.

When the name of the tag for the application names is in place, you can
move on to specifying the tag name for the tier discovery. I've selected
the custom attribute **Application-Tier** here. You can also limit the
discovered tiers by specific names. For instance, if you only want to
discover the tiers called App, DB and Web; you can fill out those names
to the right of the tier tag name.

On each step, you'll see how many applications and tiers the discovery
is actually discovering. You can click on the **Found x Applications
\[Tiers\]** links and get a list of the results to see if it's matching
your expectations.

One other thing to note is the mention of **Unclassified VMs**. This
will show up on the other discovery methods as well and is a way to see
which VMs are not involved in the current discovery. In this case, it
means that there are **352** VMs that do not have the application tag
and that they will not be a part of the application discovery results.

This brings me back to an earlier point of that you might have multiple
ways of documenting applications in your environment. You might have
different tag names for applications or tiers, or you might have
multiple different naming conventions. This just means that you would
have to run the discovery process multiple times with different
settings. The goal is to get the Unclassified VMs counter to 0.

But there's a caveat; the unclassified VM counter is only counting VMs
that are not classified within the current discovery settings. When
you've already got saved applications based on different tags, it will
not exclude the VMs that are already part of a previously discovered
(and now saved) application. To get around this and exclude VMs that are
already a part of an application from the discovery, use the following
scope:

This will effectively only discover VMs that are not already part of an
existing application. Be careful doing this if you know that there are
VMs that are a part of multiple applications (like a shared database
server).

Once you're done filling out the wizard, hit the **Discover** button.
This will take you to the results page, with an absolutely gorgeous way
of display the discovered applications.

![](./media/image20.png){width="6.263888888888889in" height="4.59375in"}

[]{#_Ref13144669 .anchor}Figure 19 -- Application Discovery Results

Using a honeycomb type widget, the discovered applications are plotted
out in such a way that you can easily go through them and focus on the
ones that you're looking for or filter out the ones you do not want.

There are filters available to show only the applications that are
talking to the internet. Or only show the top 10/20/50/100 applications
based on the amount of member VMs. You can also focus on the unprotected
VMs (the ones that do not have NSX firewall rules attached to them) or
filter out the applications that are shared in the infrastructure (like
DNS, NTP, AD, etc.) and or being used by a multitude of other
applications.

Using all of these filters; figure out which applications you want to
save and use for troubleshooting, monitoring or security planning and
hit the Save buttons on each application row of the table next to the
widget.

Note: the save button is hidden on the screenshot (Figure 19) but
appears when you hover over the table row.

When you click the save button, the form to save the application to the
system pops up -- already filled out with the application structure and
ready for you to double check and save:

![](./media/image21.png){width="6.263888888888889in"
height="4.540972222222222in"}

[]{#_Toc35170176 .anchor}Figure 20 -- Application Discovery Results -
Form

Once you hit the Submit button, the application will be saved to the
system and Network Insight will start correlating other objects (network
flows, VMs, events, etc.) with it.

### Naming Conventions

When your infrastructure uses a naming convention that indicates which
application a VM belongs to and what tier of the application the VM is a
part of, you can use the naming convention discovery method.

This discovery method takes a regular expression that you put together
and applies it against the entire inventory of Network Insight. All VMs
and AWS EC2 instances will be combed through and be checked against that
regular expression and the matches will be used to form the application
constructs.

Let's take a look at that regular expression first. According to
Wikipedia, a regular expression is the following:

> *"A regular expression, regex or regexp (sometimes called a rational
> expression) is a sequence of characters that define a search pattern.
> Usually such patterns are used by string searching algorithms for
> \"find\" or \"find and replace\" operations on strings, or for input
> validation."* [^3]

Regular expressions are used in scripting and programming languages to
grab specific bits of text out of a large text. Ask one of your
developer friends and they will most have used it, and there's a big
chance they hate it (I do). The reason to hate it, is mostly because can
be used to do really complex things. However, we can keep it pretty
simple for the usage of application discovery. Here's an example:

This example matches **APP-TIER-VM01**, using "**-"** as a separator and
grabs **APP** as the result. There are a few things to know about this
example. First; "**.\***" represents a wildcard, any type of text will
be matched here. The "**-**" is the separator used in the workload
naming convention. And lastly, the round brackets indicate that we want
to grab the bit of text that matches the expression in between those
round brackets. This is what we're effectively saying with this
expression: match workloads that are named
**SOMETHING-ANYTHING-EVERYTHING** and grab **SOMETHING** as the result.

We can get creative with the expression and demand that there are only
numbers in the last section of the name, which would result into this
expression:

This would match workloads named **SOMETHING\_ANYTHING\_01234** and grab
**ANYTHING** as the result. The brackets at the end indicate that it
will match on anything that is in between those brackets. In this case;
anything between 0 and 9 (so 0, 1, 2, etc.). The plus at the end
indicates that you're allowing multiple of the characters inside the
brackets; so multiple numbers.

There's one more example I'd like to go through before I move on: a
naming convention without separators. It happens that someone decides to
name their workloads something along the lines of **APPTIERVM01**, where
the **APP** and **TIER** are fixed sizes; 3 or 4 characters each. In
this case, we can't use the previous regular expressions as they depend
on separators. In case, we have to use a fixed size regular expression,
something like this:

Taking what we've learned earlier and add the fact that the curly
brackets indicate how long the characters between the straight brackets
should be. Then you'll see that the first bit (which we are grabbing as
the result) is matching on characters between a-z and A-Z, both lower-
and upper-case letters, and the 3 characters that match it. The second
bit looks for letters again, for 4 characters. Then there's a wildcard
that allows anything after the first 7 letters.

This will match workloads called **APPTIERVM01** and grabs **APP** as
the result. Keep in mind that it will not match **APPWEB1VM01**, as that
includes a number in the second bit. You can fix that by making the
second bit look like this: **\[a-zA-Z0-9\]{4}** -- This will look for
both letters and numbers for the next 4 characters.

Armed with these examples, you should be able to make your way through
any naming convention that is out there. However, if you do have a
different convention; there's little that regular expressions cannot
match.

If you would like to learn much more about regular expressions and all
possibilities, there's a lot out there. Ask your developer friends and
they'll have some examples. The implementation that Network Insight
uses, is the Elastic Search Regexp Query and you can learn all about its
syntax here:
<https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-regexp-query.html#regexp-syntax>

Another excellent resource is the website <https://regex101com> -- which
can help you learn regex and test out your knowledge.

Going through the naming convention wizard should be pretty familiar.
When you go to the **Name** tab on the **Discovered** **Applications**
page, you will be presented with a wizard. It will ask you to scope the
discovery and limit the results to a specific vCenter, Resource Pool,
etc.

Then you fill out the regular expression that will grab the application
name. As you're typing, underneath the input box you will be presented
with a small list of workloads from the inventory and it will underline
the matching bit of the workload name; you can check your syntax whilst
you're typing. How cool is that?!

Have a look at the **Found x Applications** and **Unclassified VMs**
lists to see if your results are as you expect. If so, move on to the
tier regular expression and rinse and repeat the steps you made on the
application.

![](./media/image22.png){width="6.263888888888889in"
height="3.8756944444444446in"}

[]{#_Toc35170177 .anchor}Figure 21 -- Application Discovery with a
Naming Convention

Looking at regular expressions can do a few things to a person: they can
comprehend it perfectly and become a wizard, they can understand it and
get away with googling the syntax they need, or they can start to ask
existential questions about life itself and go on strike. If you're not
a wizard, there's something inside Network Insight that can help you
build the right regular expression to use called the Pattern Builder.

To the right of the input for the regular expression is a button to open
it. Once you do, a new screen is opened where you can search for an
example workload (or just type the name of a workload) and build a
regular expression to match on it, just by clicking the positions or
groupings you want to match.

![](./media/image23.png){width="6.263888888888889in"
height="1.9361111111111111in"}

[]{#_Toc35170178 .anchor}Figure 22 -- Application Discovery -- Pattern
Builder

In the example above I've selected the first group as the match, and you
can see the regular expression building dynamically, just above the big
workload name. It will automatically recognize groups based on the
available separators, but you can also select specific character
positions (remember the curly brackets?).

The Pattern Builder is there to make your life a bit easier. I know what
you're thinking though; "You saved this for \*after\* the crash course
on complicated regular expressions?!?". Why, yes! And on purpose. You
should know what's going on with these regular expressions, even though
if you're using the Pattern Builder in the end; understand what the
result means. There's a lot of other places where knowledge on regular
expressions will be of use.

+------+--------------------------------------------------------------+
| INFO | Starting vRealize Network Insight 5.1, you can use different |
|      | metadata as the discovery method for the application name    |
|      | and tier name. For example, you can extract the application  |
|      | name from a workload name and use the content of a tag as    |
|      | the tier name.                                               |
|      |                                                              |
|      | Also, in version 5.1, is the ability to use **Security       |
|      | Groups** and **Security Tags** the same way as the naming    |
|      | conventions; extracting parts of the security group or tag   |
|      | to use as an application and/or tier name.                   |
+------+--------------------------------------------------------------+

### CMDB (ServiceNow)

Lastly, we've arrived at the last (and probably most boring) application
discovery method; pulling data from CMDBs. Network Insight supports
adding ServiceNow as a data source and it will start looking at the
configuration items (inventory) of the CMDB and their relation to each
other to form the application constructs. I called this method boring,
as all you have to do is add it as a data source and the **ServiceNow**
tab on the **Discovered** **Applications** page will simply list the
results and you'll be able to save the discovered applications.

I'm going to assume you have knowledge about ServiceNow and the jargon
that comes with it. I'm not go into how to create the applications and
relations between the application, services and virtual machines
attached to those services. Instead, let's have a look at a 3-tiered
application relationship map:

![](./media/image24.png){width="6.263888888888889in"
height="3.7090277777777776in"}

[]{#_Toc35170179 .anchor}Figure 23 -- Application Discovery --
ServiceNow Application Map

It's focused on an Application Service called **3TierApp02**, which has
an entry point of a load balancer listening on port 80 and 443. The load
balancer is then [distributed by]{.underline} (also the relationship
type) 3 Nginx web servers, which in turn [run on]{.underline} (also the
relationship type) their respective VMware VMs. The Nginx web servers
[depend on]{.underline} (relationship type) on 2 application services
which [run on]{.underline} another 2 VMware VMs. Lastly, the application
services [depend on]{.underline} a MySQL database service, which again
[runs on]{.underline} a VMware VM.

I've underlined the relationship types in the above description, as it's
important to have the right relationships in place in order for Network
Insight to recognize them. Especially the service link to a workload is
important, use any of these:

-   **Hosted on::Hosts**

-   **Instantiates::Instantiated by**

-   **Runs on::Runs**

-   **Virtualized by::Virtualizes**

All the VMware VMs in this example have been discovered from the virtual
infrastructure by the ServiceNow Discovery module and MID Server, so
they exist in the Network Insight inventory. You could also add these
VMs to ServiceNow manually, the only thing that matters is that they
actually exist somewhere in a vCenter that Network Insight has as a data
source.

Once you've got the application maps and relationships towards workloads
configured inside ServiceNow, they will start showing up in Network
Insight; ready to be saved.

![](./media/image25.tiff){width="6.263888888888889in"
height="2.472916666666667in"}

[]{#_Toc35170180 .anchor}Figure 24 -- Application Discovery --
ServiceNow Result

 Application Migration Planning
==============================

When the decision is made to migrate applications to Public Clouds, like
AWS, Azure, or even VMware Cloud on AWS (VMC on AWS), a few critical
considerations should be kept in mind. First and foremost, insight into
your applications and application behavior is critical.

Questions to ask yourself are:

1.  "Which components make up an application?"

2.  "To what resources does it need access to function?"

3.  "How much data is being shipped from and to that application?"

4.  "What is the network throughput profile (packets per second, routed
    or switched traffic, throughput) of the application?"

5.  "What components of the application are worth migrating?"

There are four steps in the application migration process:

1.  Assess the current application landscape and get insight into the
    application blueprints.

2.  Use this insight to determine suitable applications for migration,
    and create migration waves aka "Move Groups", which are groups of
    applications that are migrated together.

3.  Bandwidth requirements and related cloud costs cannot be skipped.
    For internet-facing applications, these bandwidth requirements
    depend on the end-users, and where in the world they are coming
    from.

4.  Migrate the selected applications.

5.  Validate application behavior, post-migration.

vRealize Network Insight Cloud can help with step 1, 2, 3, and 5.
[VMware HCX](https://cloud.vmware.com/vmware-hcx) -- workload migration
tool extraordinaire, can help with step 3. This chapter focuses heavily
on step 2, and 3 which are critical in the planning phase. For the scoop
on step 1, refer back to the chapter about [Application
Discovery]{.underline}.

Application Discovery & Assessment
----------------------------------

It's quite common to have an incomplete CMDB or to have multiple sources
where applications and the associated workloads are documented. vRealize
Network Insight can use a combination of sources (tags, naming
conventions, CMDB input) to discover the applications from the
infrastructure metadata. For more details on application discovery,
refer back to the chapter about [Application Discovery]{.underline}.

After getting the applications into Network Insight, there is a clear
view of application dependencies and network requirements. Navigate to
the Security Planner (refer back to [Analyzing Network
Flows]{.underline} for a refresher) and group the donut by Applications.

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-crm-records-donut.png](./media/image26.png){width="4.871287182852144in"
height="5.275787401574803in"}

[]{#_Ref29044160 .anchor}Figure 25 -- Application Migration Planning --
Dependency mapping

By hovering over a slice or using the search bar at the top right of the
widget, you can find the application you want to map dependencies for.
By clicking the slice, the details of that application are brought up.

What you're doing here ([Figure 25]{.underline}), is called
**Application Dependency Mapping**. Because it's really clear that the
application CRM-Records has only incoming connections from 5 other
applications, it can be concluded that CRM-Records does not have any
dependencies on other applications, however it is used by 5 other
applications, making CRM-Records a dependency for those other
applications. This becomes important when you're planning a migration,
as applications that are heavily dependent on each other, should be
grouped together and migrated simultaneously, in order to prevent
slowing down the connections between these applications.

![](./media/image27.png){width="6.263888888888889in"
height="3.7215277777777778in"}

[]{#_Ref29044197 .anchor}Figure 26 -- Application Migration Planning --
Application Details

I've focused on the CRM-Records application here, which consists of a
MySQL database server. You can see the other applications that are
talking to this application in [Figure 25]{.underline}. When you zoom in
on the application itself, the network requirements for this application
present themselves ([Figure 26]{.underline}). By adding up the different
Service Endpoints, you can determine that this application is using up
**1.1MB** of total traffic, with a peak throughput of **343bps**.
Service Endpoints is a way of classifying specific services, because
multiple services can live on the same workload. Obviously, this example
application isn't representable for an actual production application;
except higher numbers in real life.

When looking at this window, you can clearly see the types of network
ports being used as service endpoints within this application. These
network ports could also be involved in the decision whether or not to
migrate this application to the cloud. Or determine to which cloud
locations you are allowed to migrate it. There might be some service or
network port that, for security reasons, your security policies would
prevent from hosting outside the private data center. Databases with
Personally Identifiable Information (PII) data, might fall under
regional laws and these laws would prohibit the data to be hosted on
another country or continent.

While doing this exercise per application, it might turn out that the
application is extremely bandwidth hungry towards the internal users.
The **External Services Accessed** tab is where the dependent service
endpoints for this application can be found. It provides the same view
as in [Figure 26]{.underline}, only the other way around; from this
application to other services in the infrastructure.

This same window can be used to implement security policies when
migrating the application, as the [**Recommended Firewall
Rules**]{.underline} tab shows the exact firewall rules that need to be
implemented for this application.

Traffic Patterns
----------------

One of the perks of migration to a public cloud is that you can choose
the optimal location in the world to make sure your users benefit. But,
without networking insights, this is often overlooked. For
internet-facing applications, Network Insight can help with determining
where in the world the network traffic is coming from, so you can choose
the most optimal cloud location. It does this by attaching geolocation
properties (City, Country, Region, and Continent) to each network flow
that it processes, using the widely used GeoIP database from
[MaxMind](https://www.maxmind.com/en/geoip-demo). Considering that it is
possible to filter, group, and sort by every property, you can get a
clear insight into where the end-users of your applications are located.

### Per Application

One way to go about it, is looking up bandwidth requirements per
application. In this case, you would determine that a set of
applications need to be migrated because of business reasons
(availability, flexibility, etc.), and you then go about to verify the
possibility and impact of migration these applications.

In this case, the application called **CRM-Records** is one of the
applications that is selected for migration, and I'll show you how to
get the required information. First, let's start with the geographical
distribution of network traffic for this application. Execute the follow
search query:

sum(bytes) of Flows where Application = 'CRM-Records' group by Country

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-app-country-flows-1024x434.png](./media/image28.png){width="6.263888888888889in"
height="2.654861111111111in"}

[]{#_Toc35170183 .anchor}Figure 27 -- Application Migration Planning --
Traffic per Country

The above search query gives the amount of traffic for the
**CRM-Records** application, grouped by country. As you can see, most of
the traffic is coming from Northern Europe. To ensure users have the
best experience, this application should be migrated to London (which is
currently the most prominent, central, and connected location in
Northern Europe).

### Bandwidth Egress Costs

By not specifying a source or destination country, both egress and
ingress traffic numbers are combined. As you might know, ingress network
traffic to public clouds costs nothing (or very little); it's the egress
network traffic where they get you. To prevent financial surprises, be
sure to identify the egress network traffic numbers by using this search
query:

sum(bytes) of Flows where Source Application = \'CRM-Records\' group by
Destination Country

![](./media/image29.png){width="6.263888888888889in"
height="2.839583333333333in"}

[]{#_Ref29045562 .anchor}Figure 28 -- Application Migration Planning --
Egress traffic per Country

This will paint a clear picture of how much egress network traffic this
application is sending out, which would be leaving the public cloud, and
which will be charged for. It's also possible to make it easier, by
removing the group by statement like so:

sum(bytes) of Flows where Source Application = \'CRM-Records\' and Flow
Type = 'Destination is Internet'

![](./media/image30.png){width="6.263888888888889in"
height="2.229861111111111in"}

[]{#_Ref29045561 .anchor}Figure 29 -- Application Migration Planning --
Egress traffic total

*Note: the results of search queries in* *[Figure 28]{.underline} and*
*[Figure 29]{.underline} have been taken on different dates, which is
why they differ in numbers.*

Keen observers will have noticed that I replaced group by Destination
Country with Flow Type = 'Destination is Internet' in the last two
examples. The reason for this is simple; when using the Country property
in a search query, the results will automatically be internet flows, as
those are the only ones that have a geolocation attached. When not
looking for a location property, the results will include all network
flows, including the flows that stay within the datacenter. By using the
Flow Type filter, the results are limited to the flows going to the
internet.

### Looking at all Applications

A different way of going about it, is by looking at bandwidth
requirements for all applications, and determining the migration waves
based on that information. This typically happens when the entire
application landscape is migrated, and not specific applications.

This process starts by getting a list of the applications that are the
most bandwidth hungry and looking at their dependencies. Let's start by
getting a list of the top applications by executing this search query:

sum(bytes) of Flows where Source Application = \'CRM-Records\' and Flow
Type = 'Destination is Internet'

![](./media/image31.png){width="6.263888888888889in"
height="3.216666666666667in"}

[]{#_Toc35170186 .anchor}Figure 30 -- Application Migration Planning --
All application traffic

Focus on the top 10 applications and map out their dependencies, as
we've talked about in the chapter [Application Discovery &
Assessment]{.underline}. When going through that exercise, migration
waves will automatically start to form, as the dependencies
(applications) of the top 10 applications should be put in the same
migration wave.

Creating Migration Waves
------------------------

After gaining visibility into the existing applications and their
behavior, it's time to define the migration waves and put together the
applications that should be migrated together. From the application
list, that is curated inside Network Insight; assign priorities. This is
typically done based on business reasons, as there are always some
applications more important than others (e.g. production vs. test).
Priority can be given to applications that badly need to be able to
expand using cloud resources. Priority can be given to applications that
are now hosted on infrastructure that's beyond their end-of-life status
and there's a risk of downtime. I could go on, there are a lot of
reasons why certain applications can get priority, it usually comes down
to the reasons why your organization decided to migrate to the cloud in
the first place! ;-)

Now, while I'm focusing on a per-application process (as most
organizations tend to focus on applications), this same exercise can be
done on a per-network (VLAN) basis; just change the grouping. If
everything is being migrated, there's also a possibility that the
migration waves are formed on a per-network basis. If the entire
application landscape is to be migrated, it might even be easier to
migrate on a per-network basis, as there is no need for complicated
networking configurations during the migration (i.e. stretching the
networks between the locations to keep the network of the workloads
available).

**Fun fact**: it is possible to get a list of applications that are on a
network by executing the following search query:

Application where IP Endpoint.Network Interface.L2 Network = \'VLAN-10\'

After assigning priorities, creation of the applications migration wave
groups can begin. While doing this, the following questions should to be
considered:

1.  What are the network requirements in order to move this migration
    wave?

    1.  How much traffic will the migration wave create between the
        cloud and on-prem network?

    2.  Have you sized the connection to the cloud to support this
        traffic?

    3.  What ports and protocols do the applications need to communicate
        on, and will the network allow this communication?

2.  Will there be any limits triggered on the destination cloud?

    1.  Is there a limit for the number of VMs in a network?

    2.  Is there a limit of the amount of throughput or packets per
        second?

        1.  There might be a difference between the maximum throughput
            or packets per second for internal traffic and internet
            traffic.

3.  Is a temporary layer-2 bridge necessary?

    1.  If you are migrating on a per-application basis, it might be
        required to create a layer-2 bridge to allow the IP subnet to
        exist in both the on-prem infra as the cloud infra. VMware HCX
        can create these layer-2 extensions, but there will be a limit
        to how much throughput and the number of layer-2 extensions it
        can handle.

    2.  Should proximity routing be enabled while the layer-2 extension
        is online?

While network requirements (number 1) are the most important to check;
as it directly impacts application performance during or after
migration, the rest of these questions can prevent the migration from
finishing. If not checked properly and in advance, you might hit these
limits while in the middle of the migration and need to halt the
migration, or even reverse the migration. Unfortunately, this has
happened to plenty organizations, costing them user-experience by
causing downtime, extra time to either revert or changing the migration
plan.

To start answering these questions, create another application within
Network Insight that's called "Migration Wave X" and place the
applications that are in each migration wave inside. Essentially, you
are creating nested applications. To know which applications should be
in the same migration wave, map out application dependencies as I talked
about in [Application Discovery & Assessment]{.underline}.

After creating these applications, it is possible to scope the security
planner on each migration wave and see its dependencies.

As an example, the below screenshot lists the security planner for
Migration Wave 1, which is built with the previously used application
CRM-Records. This migration wave 1 includes the CRM-Records app, and all
of its dependents (Test-CRM, Webshop, SAP, VDI, and tanzu tees).

![https://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-wave-1.png](./media/image32.png){width="4.740457130358705in"
height="5.481481846019247in"}

[]{#_Toc35170187 .anchor}Figure 31 -- Application Migration Planning --
Migration Wave Dependency Mapping

Just like with the previous application dependency mapping exercise,
zooming in (clicking) on each of these connections is possible. Make
sure the requirements to move this migration wave are clear, by
investigating all connections that flow to the remaining infrastructure
(shared physical/virtual service slices) are not overly excessive. If it
turns out the requirements between this migration wave and some physical
service is something like 1Gbit per second, you might need to reexamine
the migration wave.

By the way, this migration wave is absolutely perfect, as it has no
dependencies to other migration waves. Typically, you would see some
connections going to other migration waves. That will help you
determining the order of when to migrate the migration waves, in order
to limit the time that the dependency network traffic has to flow from
the cloud to the yet-to-be migrated waves.

Before moving on, make sure you have a full picture of the network
requirements within this migration wave; click the Migration Wave slice
and check internal traffic requirements, and check the connections
between the internet, and lastly all remaining infrastructure
connections. Use the same data to determine what security policies
should be in place between the cloud and your on-premises data center,
to prevent connections being blocked while migrating.

Limitation Check
----------------

The cloud is not unlimited, no matter what the cloud providers say.
There will be limits to how big workloads can be, limits to how many
workloads can share a single network, limits to the number of security
policies, limits to the number of networks inside a virtual cloud
construct, I can go on. Before attempting to migrate anything, create a
design for your new cloud infrastructure and use the cloud provider
limits to make sure everything fits.

At this phase, the data collected in the previous chapters comes into
play. You now have a clear picture of the network requirements, which
applications to move and the number of VMs serving to those
applications, differences between network throughput and packets per
second, for internal traffic, internet traffic, and traffic flowing to
your on-premises data center.

### Compute & Storage

Network Insight also has compute and storage data, which can be used to
understand the requirements to size the target cloud. For example, to
get the number of CPU cores and consumed memory by all workloads in a
migration wave, use this search query:

sum(CPU Cores), sum(Memory Consumed) of VMs where application =
\'Migration Wave 1\'

![https://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-wave-compute.png](./media/image33.png){width="6.263888888888889in"
height="2.2666666666666666in"}

[]{#_Toc35170188 .anchor}Figure 32 -- Application Migration Planning --
CPU & Memory requirements

While the same can be achieved for disk usage and make the picture
complete; Network Insight is focused on the networking aspects of your
applications, not the compute & storage. It's perfectly possible to get
an overview of the current usage, but Network Insight should not be used
for capacity management and prediction for compute and storage
resources. [vRealize Operations](http://vmware.com/go/vrops) (vROps) is
much better in getting that full picture.

Have vROps monitor your environment for a few weeks, and it will
construct a dynamic picture of the compute and storage resources needed
to host the applications; past, current, and future requirements. It
also has a built-in [Migration Planning
feature](https://docs.vmware.com/en/vRealize-Operations-Manager/8.0/com.vmware.vcom.core.doc/GUID-A0D6E8A5-58F9-43CC-BB29-AB0AFDBCE1A2.html),
which will provide you with the resources needed for the migration
(including future growth), and even provide the costs of hosting these
resources in a number of different clouds (native AWS, VMware Cloud on
AWS, IBM Cloud, Azure, Google Cloud).

### Network

Back to the comfort zone of Network Insight. To properly plan the
destination cloud infrastructure, we need to know the network throughput
and packet per second usage of the workloads inside the migration wave.
Because Network Insight correlates all possible information together, we
can find these metrics and link them back to the migration wave group
directly.

Uncovering the required information can be done by using the search
engine. Let's start by looking up the network traffic that is purely
internet traffic. Execute the following search query:

series(sum(byte rate),300) of flow where source application =
\'Migration Wave 1\' and flow type = \'Destination is Internet\'

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-wave-1-traffic-rate-1024x178.png](./media/image34.png){width="6.263888888888889in"
height="1.0895833333333333in"}

[]{#_Toc35170189 .anchor}Figure 33 -- Application Migration Planning --
Internet Traffic of Migrate Wave 1

To really understand the mechanics of this search, wait until you've
reached the [Using the Search Engine]{.underline} chapter. For now, know
that this result shows you the sum of the byte rate (network traffic),
of network flows where Migration Wave 1 is the source, talking to the
internet. While this example shows a lack of internet traffic (having a
whopping 2bps at some point), it gives a clear picture of the internet
traffic behavior, and therefor requirements.

The above search shows the internet traffic over a period of time (by
default the last 24 hours). You should also get the maximum peak
throughput of all historical flow data that Network Insight has stored.
This is possible by adding the max() operator:

max(series(sum(byte rate),300)) of flow where Source Application =
\'Migration Wave 1\' and Flow Type = \'Destination is Internet\'

![](./media/image35.png){width="1.7430555555555556in"
height="1.3371380139982503in"}

[]{#_Toc35170190 .anchor}Figure 34 -- Application Migration Planning --
Peak internet Traffic of Migrate Wave 1

This will show you the peak network throughput. If Network Insight has
been running for 1 month, the maximum peak of traffic per second in that
month, was **901.1 kbps**. This number can be used for sizing the
internet gateway at the destination cloud.

#### Traffic Types

Get these graphs and maximum values for a few different traffic types;
internet, east-west, and within the migration wave. Splitting up the
different types of traffic is easy; the **flow type** can be changed to
view a bunch of different traffic types. From the Internet, to
East-West, to Routed, to Switched, and a lot more. Have a look at the
auto-completion and scroll through the options:

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-flow-types.png](./media/image36.png){width="2.9559241032370953in"
height="2.8680555555555554in"}

[]{#_Toc35170191 .anchor}Figure 35 -- Application Migration Planning --
Flow Types

There are over 50 different flow types, which all categorize different
types of network behavior. Depending on what limitations the target
cloud has, different flow types should be used to see the requirements.

#### Packets per second

Let's go through one more example with another metric. In most cases,
there will be a limit of packets per second at the destination cloud. To
make sure there are no surprises, get the packets per second as well.
All you have to do is to change the focus property in the search query,
like this:

series(sum(flow.totalPackets.delta.summation.number),300) of flow where
Source Application = \'Migration Wave 1\' and Flow Type = \'Destination
is Internet\'

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-wave-1-packets-1024x179.png](./media/image37.png){width="6.263888888888889in"
height="1.0944444444444446in"}

[]{#_Toc35170192 .anchor}Figure 36 -- Application Migration Planning --
Internet Packets p/s of Migrate Wave 1

Make sure the packet per second rate is also sized properly, and use the
max operator to get the maximum number of packets per second:

max(series(sum(flow.totalPackets.delta.summation.number),300)) of flow
where source application = \'Migration Wave 1\' and flow type =
\'Destination is Internet\'

![](./media/image38.png){width="1.7743044619422572in"
height="1.3611111111111112in"}

[]{#_Toc35170193 .anchor}Figure 34 -- Application Migration Planning --
Peak internet packets p/s of Migrate Wave 1

Rinse and repeat this for other flow types, such as routed and switched
traffic by changing the flow types. This will get all network data you
need to determine the minimum requirements.

After determining the minimum requirements for the network at the
destination cloud, make sure you add a buffer on top. Remember, all data
is current data and does not take into account application growth.
Typically, adding a buffer of 40 to 50 percent for healthy growing
applications, is a good practice.

Migrating the Applications
--------------------------

Now that the planning is done, the migrations itself can begin. I highly
recommend [VMware
HCX](https://cloud.vmware.com/vmware-hcx?int_cid=70134000001CaZ5&src=WWW_us_VMW_0cnHu1FmS2pidRE57WJU)
for this task, and not only because it's one of VMware's products. It
allows for cold and live migrations from and to different vSphere
platforms, using already built-in tooling, such as vSphere replication.
HCX can extend layer-2 networks to stretch an IP subnet between
on-premises and VMC on AWS.

Learn more about [VMware HCX
here](https://cloud.vmware.com/i-need-to/migrate-to-the-cloud?int_cid=70134000001CaZ5&src=WWW_us_VMW_0cnHu1FmS2pidRE57WJU).

Validating Application Behavior
-------------------------------

Once an application is migrated, I would advise to validate its behavior
by going into the security planner and checking connectivity from before
the application was migrated and after. This is done by using the
built-in time machine on every page:

![http://blogs.vmware.com/management/files/2019/12/vrni-plan-migration-verification-time-machine.png](./media/image39.png){width="6.263888888888889in"
height="0.28958333333333336in"}

[]{#_Toc35170194 .anchor}Figure 34 -- Application Migration Planning --
Validate Application with the Time Machine

There are more ways to validate an applications behavior. For example,
the Application Dashboard will show a topology of the application, all
metrics that relate to it, any and all events that might cause problems.

Go through at least the Security Planner and the Application Dashboard.
These will provide a good pre-migration and post-migration picture, and
you can make sure the application is still communicating with the right
services. If the network fabric of the target cloud is based on VMware
NSX (like VMware Cloud on AWS, IBM Cloud, or a private cloud), Network
Insight will also log network flows that are denied by the security
policies. Meaning, the Security Planner and Application Dashboard will
also show network traffic that is being denied by the firewall. This is
especially good to check when doing the post-migration validation.

Network Insight into Public Clouds
==================================

The concept of a cloud is nothing new. Organizations have been hosting
their applications on other people's computers for ages. We were running
vCloud Director 1.5 at a data center service provider that was renting
out VMs to customers (Infrastructure as a Service), back in 2011. Before
using vSphere VMs and a portal like vCloud Director, we were using
FreeBSD jails and Virtuozzo (based on CentOS) to deliver VPSs (Virtual
Private Server). These services were mostly contained to Infrastructure
as a Service (IaaS) and added manual services (monitoring, backups,
pro-active maintenance, etc.). Fun times!

While it's not new, the speed at which the cloud provider industry has
evolved in the last few years, is pretty ridiculous. Going from
providing simple infrastructure as a service to database, storage,
machine learning, blockchain, IoT, and all other current buzzwords, all
as a service. Certain business cases of running entire companies in the
public clouds are a no-brainer (some cases are not, so always do your
homework) and it's never been easier to start a new project and getting
it off the ground. Get your new product to your customers in days, if
not hours. All you need is a credit card.

That's where the problem lies, as well. Because it's so easy to get up
and running, developers and/or business groups start to run their
products in the cloud, without informing the IT infrastructure
department where the responsibility to keep the company's digital
footprint up and running. Even if IT gets involved and there's a proper
master account set up with linked/sub accounts for the business groups
and gets a proper view of what's happening, there's another problem
rearing its head.

Public clouds are starting to specialize in specific services. While
every single one will keep the basis of IaaS and complementary things as
databases as a service, specific public clouds are better with certain
services. For example, things like machine learning, artificial
intelligence, ARM CPUs, GPUs; certain clouds are just better than other
clouds. Amazon even has a satellite ground station as a service, these
days. In any case, the probability that your organization will be
adopting multiple public cloud services, while keeping an on-premises
data center presence, is high. Meaning you will be tasked with managing
and securing multiple clouds eventually, if that's not the case already.

Do to this successfully, while not growing grey hair along the way, you
need a tool that can span multiple clouds and present all different
clouds in a universal way. Network Insight will inventory all networking
and security aspects of the on-premises data center, public clouds and
branch locations and present its feature set over all these different
locations; the same way.

That last bit sounds very salesy, but basically it means this: network
traffic flows are correlated between all these locations and the
security planner is available to make sure all workloads are secured
across all locations, network traffic analytics can detect anomalies no
matter where the workloads are being hosted, application discovery spans
private, hybrid, and public clouds, there is a global inventory of all
network and security objects (virtual networks, security policies,
gateways, VPNs, those sort of things) which can be used to troubleshoot
issues and monitor the network, all in the same interface, providing the
same experience.

Amazon Web Services (AWS)
-------------------------

With 47.8%[^4] of the public cloud market in its pocket, Amazon Web
Services is a clear leader. It pays to be the first, but it also helps
that AWS has over 165 (and counting) different services. Ranging from
infrastructure as-a-service, to database, analytics, application
services, deployment management, mobile, developer tools and
internet-of-things enablement services.

You're most likely most familiar with their Elastic Computing Cloud
(EC2), the Simple Storage Service (S3), and the Relational Database
Service (RDS). These services get used to most by organizations that are
looking to the public cloud for workload placement, i.e. get some
cheaper infrastructure. I'm not going to go into whether moving existing
workloads (instead of refactoring them to take advantage of native
public cloud services), is a good or bad idea, but how Network Insight
helps you in managing the pain if your organization decides to go.

On whether it's a good idea or not, just please make sure the homework
and cost projections are done before you go.

### AWS Networking Tools

There are a few native network monitoring and troubleshooting tools
inside AWS:

-   **Mirror sessions**; essentially a port mirror that can be placed on
    an Elastic Network Interface (ENI). You do some advanced things
    here, like creating filters to only mirror specific traffic based on
    source, destination, protocol, and ports. The traffic is delivered
    to another ENI, meaning you have to run an EC2 instance where you
    then catch the traffic using something like Wireshark or tcpdump.
    Another cool fact about these mirror sessions, is that each session
    is encapsulated into a separate VXLAN network, meaning you can
    separate out the different mirror sessions by looking at the VXLAN
    ID on the target ENI.

-   **Flow Logs**: the ability to log all IP traffic that is incoming
    and outgoing to network interfaces in a specific VPC. Think hit
    count logs, but only for all IP traffic. You can configure it only
    for the entire VPC and determine whether you want to only log
    accepted traffic, or also log rejected traffic by the security
    groups that are in place. These logs will be sent either to
    CloudWatch or an S3 bucket.

-   **Status Checks**: checks whether services are running, reachable,
    and performing. This is more on the application level, where the
    network is used to do these checks.

-   **CloudWatch Logs**: you can send all kinds of logs and metrics to
    CloudWatch. It allows you to access, and correlate all this data,
    between different AWS services. It is comparable to something like
    Splunk or vRealize Log Insight.

These tools are point solutions; solving 1 issue per tool. The mirror
sessions are great for on demand troubleshooting but needs an EC2
instance to direct the traffic to (which you need to set up yourself).
The Flow Logs can also serve their purpose but that has its scalability
limits. It's literally structured logs with the following format:

No friendly names of the account name or EC2 instance, just the IDs. You
would need to find the EC2 instance, look at the network interface and
grab its ID, before this would make sense.

Using Network Insight for the same job, is a lot easier & quicker. As
mentioned before, it will correlate everything together -- meaning it
will look up the network interface IDs, attach them to the EC2 instance
and allow you to look up all flows from a specific (or a group) EC2
instance.

It won't only collect the flow logs, but also all inventory (EC2, VPC,
and everything attached to those) to do inventory tracking over time.
The timeline functionality will be available for all AWS compute and
network inventory. It will generate events for certain best practices
(like security rule maximums against security groups), and you can
create user defined events to get alerts when something changes in AWS.

And it will do this in the same interface where you have your
on-premises workloads, making it easy to get the global overview.
Because unless you're a unicorn (congrats!), you'll also have
on-premises networks to manage. At least, you'll have something more
than just AWS.

### Adding AWS to Network Insight

There are two ways to add AWS to Network Insight. Using a standard
account which houses network & compute instances directly or using a
master account that holds a number of different standard accounts, which
in turn hold the network & compute instances.

When you have a larger organization that uses AWS, the chance is that
separate accounts are created to hold different departments, projects,
or persons. This is to separate out management of the resources or
having the ability to figure out which department or project is costing
the most money. In short; a master account is, as the name suggests, a
master of all linked accounts and has visibility into all of them. A
linked account has only a small portion of the organization's resources.

If you do have a master account you can add that to Network Insight, and
it will discover all linked accounts under it (existing and new) and
start collecting data from the network & compute resources that are
under those linked accounts.

![](./media/image40.tiff){width="4.638298337707787in"
height="1.662347987751531in"}

[]{#_Toc35170195 .anchor}Figure 37 -- AWS Master account link diagram

If you do not have a master account, simply add the standard account. If
you have more than one account, simply add them all; there is no limit
to the amount of added accounts.

**Requirements**

There are not many. Firstly, an account with read access on the account,
EC2 instances and the log repository (to get the flow logs). For a full
account policy template, check out the
[documentation](https://docs.vmware.com/en/VMware-vRealize-Network-Insight/5.0/com.vmware.vrni.using.doc/GUID-122546CC-FB0F-4D8F-B4E8-225B372CDC31.html).

Secondly, the collector appliance which will poll AWS, will need to be
able to access the AWS API over the internet (so, open up the firewall).
If you're using vRealize Network Insight Cloud, the connection will go
from the VMware Cloud to the AWS API, no local connections needed.

  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   When adding an AWS account for Network Insight, make sure it has programmatic access. You'll need the generated access key and secret access key, to add it to Network Insight.
  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

**Enable VPC Flow Logs**

In order to collect network flow logs from AWS, it has to be set up
first. Flow Logs is an option per VPC, meaning you need to enable in
inside the AWS console on a per-VPC basis. In order to do so, create a
Log Group inside CloudWatch where the logs will go, and configure these
settings on the VPC:

![](./media/image41.png){width="6.263888888888889in"
height="3.652083333333333in"}

[]{#_Toc35170196 .anchor}Figure 38 -- AWS: Setting up VPC Flow Logs

Set the **Filter** option to **All**. It will determine to log both
allowed network flows and the blocked network flows by any security
group rules that are in place. Currently, Network Insight only grabs the
allowed flows, but that might change in the future.

The IAM role should be a role that is allowed to write to the CloudWatch
Log Group.

**Geo-location Blocking**

When you're dealing with a global cloud presence, and different parts of
your organization are located in different public cloud regions, it is
possible that the persons managing the EMEA resources are completely
different from the persons that are managing the AMER resources -- and
have nothing to do with each other. Picture this; a global organization
with a single master account for billing purposes, but linked accounts
for the localized teams.

In that case, you might want to have different instances of Network
Insight, in order to have the localized teams only look at their own
resources. This is possible with the geo-location blocking support
inside Network Insight.

During the process of adding the AWS master access as a data source, you
can specify from which AWS regions Network Insight is allowed to collect
information from. It will leave the unselected regions alone.

![](./media/image42.png){width="6.263888888888889in"
height="4.963888888888889in"}

[]{#_Ref24444888 .anchor}Figure 39 -- Adding AWS Account

The above [Figure 39]{.underline} depicts the screen that allows you to
add an AWS account. Select a collector appliance that will connect to
the AWS API (over internet), supply the access key and secret access
key, and hit the Validate button. The collector will now go out to the
AWS API and validate the credentials. If it succeeds, the rest of the
options will be made available.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   vRealize Network Insight Cloud has a shared collector for public cloud discovery. You don't have to set up a collector to add a public cloud, meaning you don't have to select the collector in the above process.
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

If you're adding a master account and would like to collect all linked
accounts, tick the first checkbox.

Once you've set up the Flow Logs on your VPCs, also tick the checkbox to
enable flow data collection. It will make sure that the collector will
start looking at the CloudWatch logs to collect network flows from AWS.

Lastly, you can determine if you want to limit the collection process to
only selected AWS regions. Tick the last checkbox, and select the
regions you want to collect from, if that is the case.

Give it a nickname and save the new data source. Next, inventory
collection will start.

### Inventory Collection

Once AWS has been added as a data source, the collector appliance will
start collecting information from AWS via its APIs. This happens every
**10 minutes**.

All computing, networking, and relevant administrative objects are
pulled in. Things like the AWS account, EC2 instances, firewall rules,
security groups, IP subnets, VPCs, and VPC peering connections are given
their own dashboards. It'll be possible to use the Network Insight
search to uncover the inventory of the AWS environments. This will list
all AWS objects across all added AWS accounts; having everything in the
same place. Just type in AWS, in order to see the options:

![](./media/image43.png){width="2.1041951006124235in"
height="3.1489359142607176in"}

[]{#_Toc35170198 .anchor}Figure 40 -- AWS Search options

During the inventory, the incoming data is correlated to each other. EC2
instances will have a direct link to its network interface, the
applicable firewall rules, availability zone, region, network flows, all
the way up to the AWS account. This means you can use all these linked
entities to filter, for example; search for all EC2 instances that
belong to a specific account or VPC.

### Network Flows

When flow logging is configured on a VPC to log towards CloudWatch, the
network flows can be seen from the CloudWatch console. The log streams
are grouped by elastic network interface and the action taken by the AWS
Security Rule (accept or deny). This is the exact view that Network
Insight retrieves using the API.

![](./media/image44.png){width="6.263888888888889in"
height="2.407638888888889in"}

[]{#_Toc35170199 .anchor}Figure 41 -- AWS CloudWatch listing network
flow logs

What Network Insight does with the flow logs and how they are processed,
is similar for both AWS and Azure -- and it is described in the chapter
[AWS & Azure Flow Processing]{.underline}, which is located in the
chapter about the [Architecture]{.underline}.

When network flows are retrieved from CloudWatch, AWS entities will show
up in the [Application Security Planning]{.underline}. Flow visibility
will be there throughout Network Insight and you'll be able to generate
recommended firewall rules that can be applied onto AWS security groups.

### Network Path Visibility

While retrieving the networking configuration from AWS, Network Insight
also constructs a view of the network topologies that are available
within AWS, and also any VPN connectivity that connects back to an
on-premises (or any of the other platforms that is supported by Network
Insight) infrastructure.

While Amazon does not allow you insights into the actual physical
equipment that is used to host your AWS resources, there are several
logical networking components that we *can* see.

EC2 instances are hosted on a subnet, subnets are connected using a
routing table, internet connectivity will go over an internet gateway,
VPN connections over a virtual private gateway, and different VPCs can
be connected via a VPC peering connection. Network Insight can construct
a logical network topology, based on all those components.

![](./media/image45.png){width="6.263888888888889in"
height="3.216666666666667in"}

[]{#_Toc35170200 .anchor}Figure 42 -- AWS Network topology between two
VMs in different VPCs

We can also monitor these logical network components separately, and for
example, monitor the connection from the EC2 instance to the subnet or
routing table. Using routing algorithms, Network Insight constructs
these topologies on demand, whenever you request a path, by searching
for path from AWS EC2 xxx to AWS EC2 yyy.

You can request paths between EC2 instances, or between an EC2 instance
and a vSphere VM that's either hosted on-premises or in VMware Cloud on
AWS.

![](./media/image46.png){width="6.263888888888889in"
height="3.216666666666667in"}

[]{#_Ref24463962 .anchor}Figure 43 -- AWS Network topology between
on-premises and an AWS VPC

The above Figure 43 shows a network topology coming from an on-premises
vSphere VM behind VMware NSX for vSphere, with a NSX Edge connecting
with a layer-3 VPN to a Virtual Private Gateway on AWS.

  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Drawing network topologies into and from AWS is currently only supported with layer-3 VPN tunnels, except for connections going to the internet (as that uses the AWS internet gateway).
  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Because AWS is pretty restrictive in how you configure the network
components that might show up in the network topology, there's not a
whole lot to keep in mind. Just make sure connectivity is actually
online, and Network Insight will be able to discover the topology. If a
path does not show, it is most likely because there's an actual problem
on the connectivity and Network Insight will indicate where that problem
might be.

### Security Group Tracking

When a network is virtualized and connected directly to the internet, as
public clouds typically are, I'd say it's more important to keep control
of the security policies, then it would be when your workloads are all
on-premises behind an internet firewall which you control. It's way
easier to misconfigure security policies and allow all kinds of unwanted
incoming connections.

AWS makes it super easy to configure security groups when deploying new
EC2 instances; simply create a security group with specific firewall
rules for that EC2 instance or select an existing security group. It's
when you need to start managing the infrastructure, when they start to
bite you.

Security groups in AWS are separately managed. They have a dedicated
section in the AWS console. This makes sense. What does not make sense,
is that there's no overview of all EC2 instances that are connected to a
specific security group. It also doesn't help that the security groups
that are attached directly to EC2 instances, can be superseded by
something called Network ACLs, which are attached to the VPC.

Network ACLs are global firewall rules which are applied to everything
inside the VPC. These ACLs can overrule security group firewall rules.
If a Network ACL denies incoming HTTP traffic and the security group
firewall rules allow it, the traffic will be denied as the Network ACL
takes precedence. It makes sense if you think of the network ACLs to be
the border firewall. However, these overlapping rules are not displayed
together anywhere, which makes it hard to troubleshoot connectivity
issues.

The first thing Network Insight helps with in AWS security management,
is putting all the firewall rules that are applicable (security groups)
on the same page, when you're looking at a specific EC2 instance.
Furthermore, the dashboard for a security group shows all EC2 instances
that are attached to the security group. You can execute searches to
look for all security groups that allow a certain port from the
internet. In short, Network Insight makes it a lot easier to view the
security configuration.

The second thing is that for each object in Network Insight, there's a
timeline created. Meaning you can scroll back in time and look at the
configuration at a specific point in time. Every time a configuration
change is detected, a new version is created and there will be a 'blip'
on the time line, indicating that there's been a change at that time. If
the rules of a security group are changed (added, edited, or removed),
an audit log will be created that will list what exactly has been
changed and when.

Azure
-----

Microsoft has been hammering on the road of their Azure public cloud
offering for a while now. While they're not the first, they're making it
pretty easy for Microsoft customers to consume Azure and place Windows
workloads in their cloud. With about 15.5%[^5] of the public cloud
market share, they are the number two cloud.

While I'll focus mostly on the Azure VM service and the services that
support computing resources, Azure has an enormous portfolio of
services. Ranging from infrastructure services, to databases,
blockchain, identity, application development, and (not limited to)
internet-of-things services. They claim they have over 600 services, but
they also count sub-services like virtual networks (which I think is a
part of the infrastructure/compute service), something which AWS does
not count as a separate service.

I'm not going to repeat all the added value that Network Insight brings
to Azure, it's exactly the same as with AWS. To recap; Network Insight
will bring all networking & security objects into the same interface as
on-premises networking & security objects (including the time machine
with point in time versions of configurations), it will create
correlations between all Azure objects which cannot be easily seen in
the Azure Portal (for example; all VMs connected to an Application
Security Group), all in the same interface.

### Azure Networking Tools

I'm pleasantly surprised by Microsoft in this case. Azure is a lot more
network & security admin friendly then AWS is. It has a bunch of tools
that are similar to what AWS but Azure certainly offers more elaborate
and extensive tools. Here's a list of the most useful ones:

-   **Security Center**: advises on the 'secureness' of security rules.
    For example, it detects and alerts on 'allow any any' rules.

-   **Network Watcher**: this is a suite of tools, such as:

    -   **Packet capture**: start a capture of all network traffic and
        dump the logs in a storage account. No destination VM is needed,
        like with AWS, and there are options to filter the traffic based
        on IP source, destination, protocol, and ports.

    -   **IP flow verify**: simulates whether a given network flow (you
        can input the IP source, destination, protocol, and port) will
        be allowed through the security policies. It'll display the
        exact security rule that is allowing or blocking the flow.

    -   **VPN troubleshoot**: does several health checks on a VPN
        connection and displays a possible cause for the VPN tunnel or
        the connectivity going over it being down.

    -   **Traffic Analysis**: this comes close to what Network Insight
        does. Reports will be generated on the NSG flow logs (see
        below), which contains statistics like; top talkers, geographic
        traffic distribution, VPN utilization, and some cool network
        topology diagrams.

-   **Network Security Group Flow logs**: this will log all traffic
    going over the NSG to a storage account. It's stored in a similar
    fashion as AWS, as in security rule hit logs.

-   **Virtual Network Tap (vTAP)**: tech preview of distributed port
    mirroring for virtual networks. The traffic will be sent to a
    third-party appliance (Gigamon, Flowmon, Ixia, etc.) for analysis.

Although the network & security troubleshooting tooling is relatively
complete, these are still point solutions for Azure. If your
organization hosts everything on Azure, you can definitely get away with
it. But chances are that not everything is there and there are hybrid
applications. That's when you need a solution like Network Insight to
not have to jump between interfaces and look at your entire network as a
whole. Anyway, let's see how that looks!

### Adding Azure to Network Insight

Before adding Azure as a data source, make sure the Network Security
Group (NSG) flow logs are configured and sending network flow logs to a
storage account. More on that later in [Network Flows]{.underline}.

Network Insight uses an application identity registration in order to
get access to the Azure APIs. Application registrations can span a
single or multiple Azure accounts, allowing it to see collect data from
all Azure accounts under an organization. This application registration
will have separate permissions, which can be managed for the sole
purpose to let Network Insight collect data.

Meaning, you can determine to which resources it has access, by giving
or revoking permissions. Where the application registration will not
have access, Network Insight will not see. While I'd recommend giving it
access to the entire inventory, you can hide certain parts. Maybe
because of confidentially reasons, maybe because of Network Insight
licensing reasons (and you just don't want to pay for the development
VMs).

More information on the application registration process can be found in
the [Azure
documentation](https://docs.microsoft.com/en-us/graph/auth-register-app-v2).
In any case, make sure the application registration has the following
permissions:

Alternatively, you can also use the built-in roles: **Storage Account
Key Operator Service** **Role**, **Network Contributor**, and
**Reader**.

Once your application registration is done, you'll have an **Application
ID**, **Directory (tenant) ID**, and an **Application Secret Key** to
show for it. In order to complete the registration inside Network
Insight, you also need the Subscription ID. This ID can be retrieved by
looking at the Subscriptions page in the Azure portal.

All IDs will look something like this:
*77fb6532-da95-4a50-b00f-190ae836b2d8*

![](./media/image47.png){width="6.263888888888889in"
height="3.990972222222222in"}

[]{#_Toc35170202 .anchor}Figure 44 -- Adding an Azure data source

Just like with AWS; the collector appliance which is selected, needs
internet connectivity to go to the Azure API and collect data. Make sure
the firewall(s) are opened up to allow it to connect. When using
vRealize Network Insight Cloud, the collector will be the cloud-based
collector -- in which case you do not have to deploy one yourself.

  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   When using vRealize Network Insight Cloud, it is only supported to use the shared collector with public clouds. In theory you can deploy a collector and configure AWS or Azure on that collector, but keep in mind that that is not supported.
  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Inventory Collection

Once Azure has been added to Network Insight, it will start collecting
data every **10 minutes**.

All computing, networking, and relevant administrative objects are
pulled in. Things like the Azure Data Sources (accounts), Azure VMs,
Network Security Groups, Application Security Groups, Azure
Subscriptions, Network Interfaces, Virtual Networks, and more, are given
their own dashboards. It'll be possible to use the Network Insight
search to uncover the inventory of the Azure environments. This will
list all Azure objects across all added Azure subscriptions; having
everything in the same place. Just type in Azure, in order to see the
options:

![](./media/image48.png){width="2.745725065616798in"
height="3.4361701662292212in"}

[]{#_Toc35170203 .anchor}Figure 45 -- Azure Search options

During the inventory, the incoming data is correlated to each other. The
Azure VM dashboard will display all its network interfaces, VNets,
Subnets, all applicable security rules (both from Application Security
Groups and Network Security Groups), and all network flows.

Just like with everything else in Network Insight; after it is
correlated, you can use it to filter searches on. For example; searching
for all Azure VMs of a specific type, all VMs that are a part of a
certain Application Security Group, or all VMs that are receiving
incoming traffic from a specific country, all of this is possible.

### Network Flows

To get Azure network flows to show up in Network Insight, these flows
need to be logged first. Flow logging is a part of the Network Watcher
suite and is enabled on a per Network Security Group (NSG) basis. An NSG
can be assigned on a per VM Network Interface or per Virtual Network
Subnet basis, so you have great flexibility with where flow logging is
enabled. Honestly, the easiest way to do it; is to enable it on the NSG
that is used for the entire virtual network.

On each NSG, there's also a target **Storage Account**. The logs will be
stored as **BLOBs** in that storage account. The logs will be readable
through the Azure Portal, so you can verify whether logging is actually
happening.

Before enabling NSG flow logging, make sure you have storage accounts
that are located in the same regions as your NSGs are located, to avoid
inter-region traffic costs.

![](./media/image49.png){width="6.263888888888889in"
height="2.220833333333333in"}

[]{#_Toc35170204 .anchor}Figure 46 -- Azure flow logs structure

The structure of the NSG flow logs is *really* elaborate. If you browse
to the blobs of the target storage account, you will find a folder
structure that holds a folder per subscription, resource group, virtual
network, NSG name, and a folder per date & time; separating out the
year, month, day hour, and even minute in a separate folder. The lowest
folder is for the MAC address of the Azure VM that is receiving or
transmitting the network flows. Getting to the actual flow logs requires
a dive into 15 levels (!!) of this folder structure. You can't say it's
not organized, though!

The JSON file which holds the actual network flows, is also really
structured, and looks a bit like the example below. This is one record
from these JSON files:

The keen observer would notice a few things: the flows that are logged
are 5-tuple (source IP, destination IP, source port, destination port &
protocol), and the security rule that allows or denies this traffic is
also listed. This means that Network Insight will be able to show
**blocked flows**. Also, the 5-tuples are trimmed down and deduplicated
to the 4-tuple flows that Network Insight shows; we don't really care
about the source port.

### Network Path Visibility

As of vRealize Network Insight 5.0, there is no network path visibility
into Azure network topologies. All objects are collected, and you can
manually see what is connected to each other, but there's no
visualization of a VM to VM path.

Please talk to your VMware representative to get extra priority on this
feature, if you are using Azure and on-premises infrastructure. The
network path visibility is the best way to troubleshoot end to end
topologies.

### Security Group Tracking

Inside Azure, there are two kinds of security groups; Network Security
Groups (NSG), and Application Security Groups (ASG). The ASG is higher
level and essentially is a collection of VMs. The NSG is the group that
holds the security rule configuration, and can be applied to VM Network
Interfaces, or Virtual Network Subnets. Inside NSGs, you'll have inbound
and outbound security rules that dictate network traffic. These security
rules are where the ASG comes back, as you can ASGs as source or
destination. So, you can create an ASG, put the VMs in it which make up
an application, then security that application using inbound and
outbound security rules inside NSGs.

In some interviews with organizations that are using Azure constructs,
it seems as though the way to go is: use application security groups to
allow everything the application itself needs (i.e. API access to an
internet service, incoming web traffic to the web servers, etc.), and
use network security groups to set global security rules (i.e.
everything is allowed to use DNS, to be contacted by an internal IP
range, etc.), and internal application micro-segmentation, if needed.

  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   The effective firewall rules for an Azure VM can be a combination of Network- and applied Security Rules to Application Security Groups. It's wise to create a security rule design and designate rule priority ranges to NSGs and ASGs.
  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Although Azure does a good job at presenting the applicable firewall
rules on the VM dashboards, it hard to find out what changed at a
certain time. The time line functionality in Network Insight gives all
Azure the same version history as any other object. This allows you to
get notifications when security groups change, and to look at a time
line of changes when you're troubleshooting a connectivity issue.

VMware Cloud on AWS (VMC)
-------------------------

VMware and AWS have partnered to provide solutions that help
organizations adopt hybrid cloud to increase flexibility and reduce
cost, while leveraging their existing IT investments and expertise. Due
to the nature of VMware Cloud on AWS (VMC), managing workloads in the
hybrid cloud is not that different from managing them on-premises,
existing tools can be used to manage, monitor, and troubleshoot the
workloads, and there's not an entire re-education needed of the persons
that will manage it.

![](./media/image50.png){width="5.187703412073491in"
height="4.101851487314086in"}

[]{#_Toc35170205 .anchor}Figure 47 -- VMware Cloud on AWS -- spanning
networking & security across clouds

When you have on-premises infrastructure and want to offload the
workloads to a cloud provider, in order not to have to manage a data
center anymore; VMware Cloud on AWS (VMC) is one of the easiest options.
As VMC is essentially a VMware Software-Defined Data Center (SDDC) with
all infrastructure components that you would have on-premises (vSphere,
vSAN, and NSX), it is not that different to manage. VMC will also run
the same Virtual Machine format as on-premises vSphere runs, so it's
easy to migrate existing VMs from on-premises to VMC.

The fact that it's almost the same as an on-premises SDDC, makes it
behave the exact same way inside Network Insight as well. All inventory
will be discovered, from VMs, to NSX switches, routers, firewall rules,
the vSAN datastore; everything. This inventory will blend in with
regular VMs, NSX objects, they will just have a differentiated property
called SDDC Type. This property can have ONPREM and VMC as its value.

SDDC Type can be used in searches and will be displayed on dashboards.
For example, to get a list of all VMs that are running on VMC, execute
this search query: VMs where SDDC Type = VMC

  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Multiple VMware Cloud on AWS SDDCs can be added to Network Insight, converging all inventory, network flows, and other metrics into a single interface.
  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------

Everything else within Network Insight is exactly the same as an
on-premises SDDC. There's one exception, which is how you add VMC as a
data source. Let's take a look in the next chapter.

### Adding VMware Cloud on AWS to Network Insight

Just like with a regular vCenter and NSX Manager, there's an order in
which to add VMC as a data source. First, add the vCenter and then the
NSX Manager.

Adding the vCenter is simple; all you need is the IP address or
hostname, and credentials for read-only access and read the inventory.
The IP address or hostname can be the external facing connection to the
vCenter, or the internal IP address -- provided you have connectivity to
the internal network of the SDDC via VPN or Direct Connect.

![](./media/image51.png){width="6.263888888888889in"
height="3.4583333333333335in"}

[]{#_Toc35170206 .anchor}Figure 48 -- VMware Cloud on AWS -- Adding the
vCenter

After adding the vCenter, it's the turn of the NSX Manager, which is a
bit more involved. Although VMC runs NSX as an on-premises SDDC would
run it; customers only get selective permissions. For instance, you
cannot log into the NSX Manager directly and have to go through the
Cloud Services Portal (CSP) website to manage the networking & security
configuration in VMC. Customers cannot manage the backend configuration,
like the overlay network settings, uplink port bindings, edge nodes,
etc. It makes sense too, because VMware manages that for you; just focus
on what the VMs & applications inside the SDDC need -- simply network
connectivity, security policies, and maybe a load balancer.

Adding Network Insight into the mix does not change the permission
level. When Network Insight is connected to an NSX environment on VMC,
it gets the same privileges as the customer would. That is why the
authentication from Network Insight to the NSX Manager in VMC, works a
little different. Instead of a username and password as credential, VMC
uses a so-called CSP Refresh Token.

With this refresh token, it is possible to converse with the CSP APIs.
The refresh token is tied to a specific user account inside CSP and can
be created with limited permissions, and limited lifespan. You can
create multiple refresh tokens, and I suggest you create one for each
separate purpose -- so you know exactly which token is used by what (and
can revoke it, if needed). More information on how to create the CSP
Refresh Token, check out the [VMware
documentation](https://docs.vmware.com/en/Management-Packs-for-vRealize-Operations-Manager/1.0/vmc/GUID-3B8C8821-FB07-412F-A2E4-C5CA34D8A473.html).

![](./media/image52.png){width="6.263888888888889in"
height="3.484027777777778in"}

[]{#_Toc35170207 .anchor}Figure 49 -- VMware Cloud on AWS -- Adding the
NSX Manager

In short, Network Insight talks to the CSP API in order to get network &
security objects from VMC. However, that API is located on the NSX
Manager that is hosted inside VMC -- meaning the IP address or hostname
can be the external IP address of the NSX Manager, or the internal IP
address, as long as you have VPN or Direct Connect connectivity to the
internal VMC SDDC network.

### Network Flows

Because NSX-T powers the virtual networking of VMware Cloud on AWS,
Network Insight uses the same method to ingest network flows from the
VMC networks; the NSX-T Distributed Firewall generates NetFlow (IPFIX)
and sends it to the Network Insight collector appliance. The flows that
arrive at the collector, get processed (correlated against objects like
VMs, virtual network, geolocation, etc.), and then get send to the
platform appliance **every 10 minutes**.

Connectivity to the vCenter and NSX Manager is something to take into
account when designing your environment. As opposed to AWS and Azure,
the network flows from VMC come from actual NetFlow (IPFIX), and not
from log files existing out of purely text. This has to be a
consideration in where the collector appliance is placed, as NetFlow
takes up more bandwidth over flow log polling with AWS & Azure.
Calculations as to how much traffic you can expect, are in the
[Bandwidth Requirements for Flows]{.underline} chapter.

It's not only more bandwidth usage, NetFlow is transmitted in UDP and
clear text; which is not something you want to send over the internet.
The best course of action is to place the collector appliance for VMC on
the internal network. This can be both the internal network inside the
VMC SDDC, or it can be the internal network in an on-premises SDDC.

When placing the collector appliance inside VMC, make sure there is
connectivity between the collector and the management network where the
vCenter and NSX Manager reside.

When placing the collector appliance on an on-premises infrastructure,
make sure there is either VPN or Direct Connect connectivity to the
management network of VMC, and communication is allowed through the
firewall.

In any case, you want to make sure the NetFlow does not go over the
internet and is kept as close as possible to the NSX Manager.

### Network Path Visibility

While retrieving the networking configuration from NSX inside VMC,
Network Insight also constructs a view of the network topologies that
are available within AWS, and also any VPN connectivity that connects
back to an on-premises (or any of the other platforms that is supported
by Network Insight) infrastructure.

  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Direct Connect is currently not supported as of version 5.0. Network Insight will get all the NSX networking & security configuration but will not be able to draw a network topology from VMC to on-premises via a Direct Connect.
  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

VMware Cloud on AWS is hosted on AWS (duh), meaning we do not have full
access to the actual hardware network appliances that are being used in
their infrastructure. Network Insight will not be able to pull data from
appliances like the top-of-rack switch, or core routers that connect
your SDDC to the internet. However, everything inside the SDDC is fair
game.

NSX provides the virtual networking & security stack for VMC, so we have
insights into the networks the VMs are attached to, and the first two
routed hops (NSX T0 and T1 gateways, or otherwise known Compute Gateway
(CGW) and Provider Gateway (PGW)). On the T0 router, internet is
directly attached, and VPNs can be terminated.

Paths can be drawn from a VM inside VMC to the internet, showing the
routing and firewall rules in between. More interestingly, paths can
also be drawn between a VM on VMC and an EC2 instance in AWS, between a
VM on VMC and an on-premises infrastructure, and between different VMs
that are both hosted on VMC.

The VMC to AWS or on-premises path depend on layer-3 VPN connectivity to
another device that Network Insight supports and is reading out as a
data source. For example, the NSX-v Edge, Palo Alto Firewalls,
CheckPoint Firewalls, or terminated directly on an AWS Virtual Private
Gateway.

Here's an example path between a VM hosted on VMC and an on-premises
SDDC, which are connected via a VPN tunnel that terminates on an NSX-v
Edge appliance:

![](./media/image53.png){width="6.263888888888889in"
height="3.216666666666667in"}

[]{#_Toc35170208 .anchor}Figure 50 -- VMware Cloud on AWS -- Hybrid Path

Just like with AWS, there is not much room for customization on the
network topology and connectivity for VMware Cloud on AWS. The defaults
suffice for most customers. This is a good thing, as you don't have to
worry about setting up the network topology. Because of this approach,
there's not much requirements that Network Insight has, when it comes to
showing VM to VM paths inside VMC or between different locations. Just
have the layer-3 VPN in place and make sure all networking devices are
added as a data source, and Network Insight will discover the VMC
network topologies.

Architecture
============

*...Or how things are put together.*

Network Insight consists of two components;

1)  the Platform,

2)  the Collector (previously known as the Proxy).

In simple terms; the Platform is where you connect your browser to use
the product and retrieve information and view the pretty graphs. It also
The Collector is what connects to the data sources and relays
information to the Platform for processing.

Here's how the architecture looks and how communication flows between
the different components:

![](./media/image54.tiff){width="6.263888888888889in"
height="3.1381944444444443in"}

[]{#_Toc35170209 .anchor}Figure 51 - Platform Architecture Diagram

There are a lot of things happening in both layers, which I'll go
further into in the following chapters.

Platform
--------

When you log into Network Insight via your browser and look at all the
marvelous data that has been collected, you're looking at the interface
of the Platform. It is the doorway into Network Insight and houses the
data that is collected from your environment. Collection itself happens
at the Collector layer, but the Platform keeps the data persistently,
where the Collector only has temporary data.

There are a few options to vertically scale, meaning there's a t-shirt
size to the resources that a single appliance will consume. At the time
of this writing, you've got the option between **medium**, **large** or
**extra-large**. You can also scale out the Platform layer horizontally
to support storing more data, but more on that in chapter [Scalability
and Availability (Clustering)]{.underline}**.** In any case, always
consult the most recent
[documentation](https://docs.vmware.com/en/VMware-vRealize-Network-Insight/index.html)
on which t-shirt size you need to pick and to determine whether you need
to build a cluster to provide support for the size of the environment
it's going to monitor.

The Platform layer can have multiple Collectors from which it receives
data from. Communication between the Platform and Collector only happens
one-way, from the Collector to the Platform. This means there does not
have to be direct connectivity from the Platform towards the Collectors,
which can be put behind a NAT boundary. As long as the Collector can
reach the Platform, you're good to go.

Inside the Platform, there are a few different layers which serve
different purposes. It is a brick and loosely-coupled architecture,
which means multiple Platforms can be placed together and the service
layers will stretch between the different bricks.

Here is a representation of the service layers that live inside a
Platform:

![](./media/image55.tiff){width="6.263888888888889in"
height="3.6555555555555554in"}

[]{#_Toc35170210 .anchor}Figure 52 - Platform VM Internal Architecture

### Presentation Service Layer

The User-Interface (UI), REST API and Search Engine services are
responsible for the presentation of data to the user, whether it via a
browser or an API output. The function of the UI is pretty
straightforward; present an interface to any browser that connects. In
turn, the UI uses the API to retrieve data and configure any setting
you're changing.

The REST API is split up into two sections: a private API and a public
API. More on the public API can be found in the chapter on [Automating
Network Insight]{.underline} -- but the primary goal of the public API
is to let you, or your automation and/or orchestration systems talk to
Network Insight and retrieve data from it.

All UI interactions with data is done via the private API. As the name
suggests, this part should be not used by any automation work that you
would like to build. The format and output are likely to change
throughout different versions.

![](./media/image56.png){width="6.263888888888889in"
height="1.3798611111111112in"}

[]{#_Toc35170211 .anchor}Figure 53 - Private API in action

**Search Engine**

While the search engine is worth a whole separate chapter, in this
context is it worth explaining that the search engine drives all
interactions. Anything that you do in the interface is a search command.
This is also reflected in the search bar:

![](./media/image57.png){width="6.222222222222222in" height="1.25in"}

[]{#_Toc35170212 .anchor}Figure 54 - Searching your data center

Talking to a backend powered by Elastic Search, it takes search queries
in technical natural language. It searches through configuration data,
events, performance stats and can do so in a time machine to get results
for a specific time frame. Unlike the open source database backends, the
search engine is a service entirely built by the Network Insight team.

More details on the search engine (and how to use it) in chapter
[]{.underline}

[\
Using the Search]{.underline} Engine.

### Data Service Layer

Everything about your environment is stored inside the data service
layer. Configuration data, events and performance stats are all stored
as efficient as possible. This means that there are multiple database
systems present.

Searching firstly goes against an Elastic Search database which holds
indexed configuration data that points to a PostgreSQL and HBASE
database where metrics and configuration is held in a timestamped
format. Using Elastic Search and having it index the other databases,
speeds up any search operation and improves the user experience via the
web interface.

Configuration data is stored in PostgreSQL and each configuration is
timestamped with a time & date when this configuration was detected.
Because of these timestamps, this is also where changes in configuration
are held. Virtual Machines, Networks, Firewall rules are examples of the
data available in this PostgreSQL database.

The results from the Elastic Search database also contain index pointers
that link to metrics located in another database; HBASE. For example, a
switchport object would have a link to the HBASE database where the
bandwidth usage metrics are stored. That combination makes that the
switchport configuration (port type, which VLANs, etc.) is presented
along with its bandwidth usage graph.

Collector
---------

The Collector is the artist formerly known as the Proxy. If you come
across any mentions of a proxy appliance in the documentation; the Proxy
was renamed to Collector. Now with that out of the way...

All data comes into Network Insight via the Collector. Whether it's
NetFlow records being sent to it, or it connecting to data sources like
vSphere, physical switches, firewalls, routers, load balancers or
compute systems, it is the entry point for all environmental data.

Collectors can be scaled out by using multiple appliances for your
environment and they can be scaled up in resources by choosing a
different deployment model (**medium**, **large** or **extra-large** at
the time of this writing). Just as with the Platform, always consult the
most recent
[documentation](https://docs.vmware.com/en/VMware-vRealize-Network-Insight/index.html)
to get the latest requirements for your environment.

You can strategically place the Collectors as well. It does a couple of
things to the incoming data to compress it (more on that later) and
allow it to be sent to the Platform more efficiently. Traffic between
the Data Sources and the Collectors is heavier than between the
Collectors and Platform appliances, which makes it more efficient to
place Collectors in remote locations.

![](./media/image58.tiff){width="4.938596894138232in"
height="3.1383628608923884in"}

[]{#_Toc35170213 .anchor}Figure 55 - Platform & Collector relationships

Networking management is usually as locked down as possible to protect
the management interfaces of your network devices. It makes sense to
provide access to Network Insight for people that do not have any
business connecting directly to networking devices, so you would want to
segment those. In this instance, you would put a Collector inside the
networking management segment and only permit it to connect to the
Platform. The Collector would connect directly to the Data Sources
inside the secure segment and you don't have to allow incoming
communication from outside the secure segment.

  ------ -------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   You can have multiple Collectors reporting up to a single Platform. Data Sources cannot be shared and have a one-on-one mapping to a Collector.
  ------ -------------------------------------------------------------------------------------------------------------------------------------------------

### Collector Services

Inside a Collector, there are several services running to make sure Data
Sources are being polled for configuration & metrics and flow records
can be ingested.

The polling agents and Flow Processor are proprietary code, but there
are several open-source services running:

-   PostgreSQL is used to store all collected data, before sending it on
    to the Platform.

-   NGINX to act as a transport to the Platform and receive incoming
    webhooks (just vRealize Log Insight for now).

-   Nfcapd and Sfcapd are used to receive NetFlow and sFlow
    (respectively) records and store them in native capd data files.

    -   These are slightly modified to support IPFIX from the VDS and
        ignore information that Network Insight does not need, to
        improve performance.

![](./media/image59.png){width="5.514851268591426in"
height="4.078666885389326in"}

[]{#_Toc35170214 .anchor}Figure 56 - Collector VM internal architecture

### Flow Processor

The Flow Processor is a custom service that runs on the Collector and
it, surprisingly, processors incoming network flows from the NetFlow and
sFlow sources and translates them into a data format Network Insight can
use.

On the Collector, there are two services running for the incoming
NetFlow (including IPFIX) and/or sFlow: nfcapd and sfcapd. These are
open-source services that collect flow data in a standardized way and
generate data files that are stored on the local filesystem of the
Collector. These data files can be read manually with the nfdump
utility, if needed.

By now, you should have configured a data source that's sending flow
data to a Collector, whether it be vCenter, NSX or a physical network
device; here's what happens with those flows:

![](./media/image60.png){width="6.263888888888889in"
height="3.067361111111111in"}

[]{#_Toc35170215 .anchor}Figure 57 - Collector NetFlow processing

The service nfcapd receives the NetFlow records from the reporting
devices and saves them to memory. **Every minute**, it flushes the
memory contents into nfcapd data files. This is the same for sFlow
records received by sfcapd, except that the output is, surprise, sfcapd
data files.

**Every 5 minutes**, the Flow Processor runs. It reads in the data files
generated by both nfcapd and sfcapd, using bookmarks to remember which
flows it already has seen. This is where the flow records are reduced in
size by ignoring unused fields and going from a 5-tuple (destination IP,
source IP, destination port, source port, protocol) record to a 4-tuple
record and neglecting the source port field.

Attached to each flow, the processor stores a reporter value and any NSX
firewall rule information that's available. Flows coming from the NSX
firewall are enhanced and have the rule-id and action (allow or deny)
embedded in the IPFIX record.

The reporter IP address is stored so that you can relate to where the
flows come from, which would typically be the IP of the vCenter (and
ESXi hosts) or physical network device.

  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   By neglecting for source port, Network Insight typically assumes that you'll be using a stateful firewall when it generates the recommended firewall rules. In this day and age that should be a safe assumption but be aware of this.
  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

The metrics of the flow records (bytes sent, number of packets and
session count) are also split from the flow itself and put into a new
record, specifically used for showing a bandwidth graph with each flow.

During this exercise, the flows are also deduplicated as only the
metrics of multiple flows of the same 4-tuple record are kept. The bytes
sent, number of packets and session counts are simply added up to form a
single flow record with the correct metrics. This

**Every 10 minutes**, the collector service will read out the waiting
queue of processed flow records and sends these to the Platform. After
that, the Collector is done and marks the sent flows to be processed and
eventually archived (it keeps records for 2 days, after which they are
rotated away).

These timers mean that it could be possible that you'll see flows turn
up in the interface at a maximum delay of 16 minutes. This could be
longer if the Collector is overloaded, but you'll see a warning being
raised, if that happens.

Once a flow gets to the Platform, it gets enriched with data from the
rest of the environment that flow relates to. For a virtual machine, the
vNIC is looked up first by using the source and destination IP. It uses
both source and destination IPs to pinpoint the right vNIC, in case of
overlapping IP ranges inside the environment. When it has the vNIC and
virtual machine that the flow belongs to, it retrieves a bit more meta
data (like cluster, resource pool, etc) and stores it with the flow
record. This is all to speed up the search process.

This enrichment process also checks whether there have been any changes
to this meta data (i.e. the virtual machine has vMotioned to another
host) and updates it, if needed.

#### Bandwidth Requirements for Flows 

One of the most frequently asked questions is "how much bandwidth is
this NetFlow thing going to use?" -- Which is a good question! It can
help you with planning out the Network Insight topology and determining
placing of the Collectors. It is, however, a tough question.

Both NetFlow and sFlow are flow based, which maps to a 5-tuple matrix.
Source, destination IPs and port numbers and the protocol will be a
unique flow. Your environment might have bandwidth heavy services (like
a file share, a massive database) that get used by just a few servers.
For example, if there's a single server talking to a single file share,
reading and writing multiple terabytes to that file server; that is a
single flow. If you have 100 servers that are all talking to 100
application servers; you would have 10.000 flows.

It's not a simple calculation and it'll vary per application landscape.
However, we can do some rough calculations. Let's start with the
bandwidth a specific amount of flows could generate.

A NetFlow version 5 packet is 48 bytes and each outgoing packet holds an
average of 20 flow records, with 24 bytes of overhead per packet. That
is 984 bytes per second for 20 flow records.

  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   For 20.000 flow records per second, we can use the following calculation for the bandwidth required: (48 \* 20) + 24 = 984 bytes for a packet with 20 records. Multiply that by 1.000 for 20.000 flow records per second, and we get 984.000 bytes per second and 7.872.000 bits, or 7.8Mbit per second.
  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

However, when the question is; "how many flows will a specific amount of
application bandwidth produce?" -- it becomes a bit more complex. On
average a flow is around 200Kbit per second[^6], based on monitoring
networks of the likes of Google and Facebook (data on enterprise
networks is understandably lacking). This means monitoring 1Gbit of
traffic would produce around 5.242 flows per second, meaning around
2Mbit per second of flow records would be sent from that original 1Gbit
traffic.

+------+--------------------------------------------------------------+
| INFO | To turn 1Gbit of traffic into a number that represents the   |
|      | bandwidth generated by flows, we can use the following       |
|      | calculation:                                                 |
|      |                                                              |
|      | 1Gbit = 1024 \* 1024 = 1.048.576 Kbit / 200Kbit for 1 flow = |
|      | 5.242 flows / 20 flow records per packet = 262 packets with  |
|      | flow records = 257.906 bytes = 2.063.251 bits = 2.06Mbit per |
|      | second.                                                      |
|      |                                                              |
|      | In other words; generated flow traffic is about 0.2% of the  |
|      | actual traffic.                                              |
+------+--------------------------------------------------------------+

Now, this data is based on user and application traffic. When you dive
into the data center, there are a lot of variants. For instance, a
single host talking to a NAS and sending multiple terabytes to that NAS,
is likely to only produce a single flow, which will only be updated with
the amount of bandwidth that flow is consuming. High size transfers in a
single session will generate less flows than low size transfers by 1000s
of users.

Keep in mind that these calculations are based on averages and could
wildly differ from what you'll see in your own network. The best answer
is always; "let's enable network flow collection and see how much
traffic it's actually generating".

So yeah, that's why the default answer for this question is; it depends.

#### AWS & Azure Flow Processing

While NetFlow and sFlow are protocols that push data to the Collector,
the flow records in AWS & Azure is a different story. When enabled,
there is a flow log (per AWS VPC and per Azure Network Security Group)
that keeps all records of network flow inside and outside the public
cloud environment. These flow logs are stored in either AWS CloudWatch,
an AWS S3 storage bucket, or Azure storage account, and can be viewed
via the AWS Console, the Azure Portal, or via their API.

Network Insight uses the applicable public cloud API to collect these
logs periodically from AWS and Azure. It uses the same polling interval
as the regular flow processor uses: every 10 minutes. The Collector
responsible for collecting the rest of the inventory information (EC2
instances, Azure VMs, networks, security policies, etc.) is also the one
that collects the flow logs. It is architected this way, so that the
Collector can make direct links between the flow records and the EC2
instances or Azure VMs to which those flow records belong.

By default, the flow records that come from AWS & Azure are not that
user friendly. For instance, they contain instance IDs and not the
instance names. When the collector downloads the flow logs, it'll link
the right instances (or outside sources like VMs, physical servers that
run on-premises) and add more context details (tags, inter-VPC traffic,
everything that is relatable, it will relate) to the flows, before
sending it to the platform.

When Network Insight retrieves the flow logs, it will read the logs
every **10 minutes**, parse them and correlate them to the related
objects, like the EC2 instance or Azure VM, network interface, AWS VPC,
Azure VNet, etc., etc. The collector appliance remembers the already
retrieves logs, by setting a bookmark on the last log line it reads.
That bookmark is then used the next time it ingests the flow logs and it
will start parsing the logs from the bookmark.

Keep in mind that logging flows in both AWS and Azure, will generate
data per flow. It'll cause storage usage and some resource usage; it
will cost money to have it enabled. It depends on the number of flows
going through the cloud, but it's typically not that much. Both AWS and
Azure charge per GB of logs generated (around 50 cents per GB per
month), and these flow logs are stored in text format.

For reference, in a demo lab I manage, there are **3.300** flows stored
and it is taking up **4.2MB** of storage. It's not going to be the
biggest cost on your cloud bill, but it isn't free. ;-)

### Connecting to Data Sources

Data sources are the virtual and physical devices that are added to
Network Insight, assigned to a Collector, which then starts pulling data
from these devices. It does this by connecting to the device based on
the best suited protocol for the job. Which means that the Collector
will connect over SSH to grab configuration data, it uses SNMP to grab
the metric data (for the bandwidth graphs), or it uses an API if the
device has one.

This means the Collector has to have management access to the devices
that are added to it. Be sure to open up any and all firewalls for
connections from the Collector to these devices over ports 22 (TCP,
SSH), 161 (UDP, SNMP), and 80 and 443 (TCP, HTTP(s)) so that it can
actually connect. Connectivity to these types of devices (i.e. network
switches) are mostly closed, and rightly so. I've seen to many
implementations where it people were side tracked because there was no
connectivity allowed between the Collector and network devices. With the
exception of incoming network flows via NetFlow or sFlow, all
connections are outbound from the Collector.

Polling happens on an interval between 5 and 15 minutes, depending on
the type of data source. Most polling happens every 10 minutes, with the
exception of Brocade VDX (every 15 minutes) and VMware NSX (every 3
minutes for security events, 5 minutes for regular events and 10 minutes
for other configuration items). Every other data source will be polled
every 10 minutes.

SNMP polling happens every 5 minutes on every data source. Of course,
these intervals can change when a new Network Insight version is
released; always double check in the documentation for the exact
intervals. This is just to give you an idea.

  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Polling happens independently per data source and on an interval timer. There is no persistent connection being left open to the data sources; no permanent SSH connection. It will reconnect each time.
  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

There are a few built-in protection systems to protect the data sources
from being overwhelmed by the polling and stressing them out. This
protects them if they are already stressed for some reason, so the
Collector does not push them over the edge and impact the operations of
the device.

One of these protections is that the polling does not actually happen
every 10 minutes. When polling concludes, a timer is started that counts
down to 10 minutes and then another poll is started. Meaning that if the
poll itself takes longer because the device is stressed, there is always
a 10-minute breathing room and polls don't start to overlap.

Another protection layer goes into the specific data source. If
something is known for not handling commands in rapid succession or if
it does not handle bulk data transfer well, there is a throttling
mechanism in place to make sure the Collector does not cross the
threshold and does not stress the device out. For example, the Manager
for NSX for vSphere is known to not to handle rapid fire of API calls
very well (sorry, not sorry); so, the Collector pauses a bit between
each API call. The same is true for Cisco Nexus switches, so, there's
also a pause between commands that are executed on each Nexus switch.

Generally, all that Network Insight needs is a read-only user on the
data sources. It only wants to read in the configuration and operational
data by executing show commands, SNMP reading for metrics, or retrieve
this data via an API. However, there is one notable exception where
running a show command is proxied via another command that does need
more than read-only.

This exception is the CheckPoint firewall integration. To get the
gateway device interfaces and IP routes, Network Insight needs to run
the **run-script** API call; which requires read-write permissions.

Use the reference document called **vRealize Network Insight Data Source
Integration Reference Guide** [^7] to get a list of all commands, SNMP
OIDs and API calls that are executed by Network Insight. You can use
that list to create a customized user that can only execute these
commands and speed up the implementation by quickly getting the approval
of your security department. There will be no discussion about what
impact Network Insight could have on your devices, as it is crystal
clear what it's doing.

### Connecting to the Platform

Previously, I mentioned that the communication between the Platform and
Collectors are one-way. The Collectors initiate the connection and
pushes the data across, unidirectionally. Because of this architecture,
you can place the Collectors behind a firewall and/or NAT configuration,
and it'll work. This resolves some security concerns around the
Collector that needs connectivity to the physical network devices and
management components like vCenter, the NSX Manager, etc. Place the
Collector in the network management zone and only allow it to
communicate to outside the network management zone over port 443 towards
the Platform appliance(s), and your security architect should be happy!

SSL encryption is being used to send data from the Collector to the
Platform. This is done using certificates that are exchanged during the
setup of the Collector, when it first connects to the Platform. The
Platform saves the presented Collector certificate and then proceeds to
verify every future connection and make sure it's verified and secure.
This makes man-in-the-middle attacks on the connection much harder
(nothing is impossible to hack, except for a stone brick).

  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   The certificate that is used for a specific Collector, is also used to encrypt the data source credentials. This is why you have to re-enter the credentials when moving a data source between Collectors.
  ------ ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

#### Data Compression

There's a compression procedure when it comes to ingesting data source
data and the data that's being sent to the Platform. The incoming
network flows are trimmed down, as Network Insight doesn't need all the
fields provided by standard NetFlow, IPFIX or sFlow records. Network
Insight only cares about 4-tuple network flow records (source IP,
destination IP, protocol and destination port), so it trims the standard
5-tuple flow records by removing the source port.

Note: If VMware NSX is integrated and sending network flow data, the
saved flow records also include the firewall rule ID that the traffic
has passed through or been blocked by. This is so Network Insight can
correlate the network flow directly to a firewall rule.

Commands that are executed on physical network devices and called upon
APIs also might contain unnecessary output which it will ignore and not
pass on to the Platform.

The Collector also keeps a local table of state for the objects (VMs,
networks, flows, etc.) that it tracks and only if the state of that
object changes, it sends an update to the Platform. If you have a very
static environment and nothing is changed (i.e. no new VMs, no
vMotions), the Collector will still continuously poll the data sources
for information, but it is possible that the Collector is not pushing
any changes towards the Platform. This saves a bunch of bandwidth
between the Collector and Platform and also saves the Platform from
having to bother with unnecessary updates.

However, to make sure that the Collector keeps the Platform informed, a
keep alive with the latest known status of the data source is sent every
4 hours.

#### Offline Caching

If the Collector can't reach the Platform for any reason (like
connectivity, or the Platform is simply down), it will hold an offline
cache of the data that it's collecting. It will continue polling data
sources and processing data from the incoming network flows and will
store the incoming data in a cache directory. When the Platform reports
back to duty, the Collector will empty out its cache and the history on
the Platform is amended; like it was never gone in the first place.

To determine how long this offline cache will last (so, the amount of
time a Platform can be missing in action), you first need to know that
there are 2 different caches; 1 for network flows and 1 for polled data
(everything else).

I'll go through both offline caches below and try to give you an idea of
how long the Platform can stay offline. In both cases, it's good to know
that the data stored in these caches has a maximum amount of storage and
once that maximum has been reached, the Collector will start pruning the
older data and will keep the newer data coming in.

##### Network Flow Cache

The network flow cache has a maximum size of **15GB**. If you recall, a
packet with 20 NetFlow records is around **984** bytes. To fill up the
caching, it would take around **335.544.320** flow records. Here's how I
got there:

+------+--------------------------------------------------------------+
| INFO | To fill up the network flow cache of 15GB;                   |
|      |                                                              |
|      | 15GB = 15 \* 1024 \* 1024 \* 1024 = 16.106.127.360 bytes /   |
|      | 960 bytes for 20 flows = 16.777.216 \* 20 flows =            |
|      | 335.544.320 total flows.                                     |
+------+--------------------------------------------------------------+

It depends on how much flows the Collector is receiving, but the offline
cache for flows can last a pretty long time! Let's say it's receiving
**5.000** flows per second (roughly 1Gbit p/s of real traffic), that
**15G**B will last for about **18,5** hours.

Each Collector has this network flow cache directory, so do these
calculations based on the usage of the individual collector; not your
entire environment.

You can find this cache directory here: **/var/flows/vds/nfcapd** --
This directory stores raw nfcapd files, which could be read using the
nfdump utility.

##### Polled Data Cache

Now for 'everything else' -- which is comprised out of metrics,
inventory, events, and configuration data that's being pulled from the
data sources the collector has. This cache has a maximum size of
**10GB** and is stored in **/var/BLOB\_STORE** on the Collector. The
data that is stored here, is in Self-Describing-Message format (SDM),
which is proprietary to Network Insight and you can't read it to see
what's in them. They're essentially used as update messages from the
Collector to the Platform to inform the Platform of all metrics and
changes that occur.

It's a little harder to predict how long this cache can stay offline,
though.

This all depends on the churn of the environment it's monitoring; how
many events (i.e. vMotions) there are, how many VM actions (new VMs,
removals, virtual hardware updates, etc.) happen, how many configuration
updates your physical network devices have, how many network topology
updates (including routing updates for new IP subnets). That's just
events and configuration updates; it also depends on how many objects
(VMs, switch ports) Network Insight is pulling metrics from. You get the
point; it depends.

However, to give you an idea of the storage needed for a period of time,
consider the following environment:

3 vCenters with 3 NSX for vSphere Managers, 9 physical network switches,
400 VMs, 500 switch ports for metrics. There's a relatively low VM churn
of 10 VMs deployed each day and 10 removed VMs and about 20 VM updates
happen. Every VM is injected into the network topology by announcing an
IP prefix of /32 for it, so that routing updates happening, each time a
VM gets deployed or removed.

Described above is a small business environment with a relative medium
amount of churn. The experiment we did was to turn off the Platform for
12 hours.

In those **12 hours**, there was a buildup of **400MB** of SDMs. Meaning
this environment could handle a Platform outage of **307 hours** (or 12
days). That should be enough time to get the Platform back up, right?!
;-)

You could use this experiment and get a (very) rough estimate on how
long your own Platform could be offline, before data pruning starts to
happen. Let's focus on the VMs and let's say you've got the maximum of
10.000 VMs that a Collector is monitoring. In that case, we take the
400MB of those 400 VMs in 12 hours and multiple that by 25 (because
10.000 / 400 = 25), and we get **9.8GB** in **12 hours** for offline
caching on **10.000 VMs**.

Again, this is a very rough estimate. The point of this entire chapter
is that you should not worry about data loss when you're performing
Platform upgrades or when the Platform is down for other reasons. You'd
have plenty of time finishing up the upgrade or even restore a full
backup, if the Platform goes belly up completely.

Hosted Architecture (SaaS)
--------------------------

If you're using Network Insight as-a-Service, the appliances used are
exactly the same as the ones you would use on-premises. There are 2
notable differences:

-   Authentication is handled by single-sign-on coupled with the VMware
    Cloud Services Portal,

-   There are a few user-interface changes, for example the styling
    colors have been changed to match the other VMware Cloud Services
    and a couple of settings are not available (LDAP, User Management &
    Mail Server)

Authentication is handled by the VMware Cloud Services Portal, which
explains the missing authentication settings. VMware has its own mail
servers in place for the service, so you don't have to configure a mail
server.

Think of it like this; with Network Insight as-a-Service, VMware hosts
and maintains the Platform, which means you only have to deploy the
Collectors in your own environment. Data flow is also the same, which
means the Collector talks unidirectional to the Platform. In this case
the Platform is hosted on the internet, which means your Collectors need
to have internet access for this to work.

[Fun fact]{.underline}: The Platform appliance of Network Insight is
multi-tenant capable out of the box. It currently takes a lot of effort
(and it's not user-friendly and not supported) to get multiple tenants
activated. I've tried and broke a few Platforms. VMware is using this
multi-tenancy capability in the as-a-Service variant. I'm holding out
hope that multi-tenancy will be activated in the on-premises variant as
well.

![](./media/image61.png){width="6.263888888888889in"
height="3.202777777777778in"}

[]{#_Toc35170216 .anchor}Figure 58 -- Architecture for Network Insight
as a Service

  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   When using Network Insight as-a-Service, you only have to deploy the Collector in your environment. It requires connectivity to the Platform, which means internet connectivity is required for the Collector.
  ------ ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Using the Command Line and Troubleshooting
==========================================

When Network Insight is set up and acting normally, you do not need the
command line interface. Apart from the initial **setup** command, the
command line is not used much. It's mostly used to troubleshoot the
Platform or Collector appliances themselves and change settings, such as
the networking configuration. There are a few commands and other tricks
to call out though, which I'll do in this chapter.

Logging In
----------

During the deployment of Network Insight, specifically during the setup
command, you will be prompted to configure passwords for 2 users:
**support** and **consoleuser**. You will be able to log into the
appliances (both the Platforms and Collectors) using both of these
usernames; but they serve different purposes.

The username **consoleuser** is the one that you would normally use. It
has a nice shell wrapper called the vRealize Network Insight Command
Line Interface (vRNICLI: yes, it needs a cooler name) and managing a
Network Insight appliance should go through this user and shell wrapper.
It has a lot of sanity checks and (almost; there are danger zones) makes
sure that you can't damage the appliance.

Then there's the support username. This one brings you straight to the
underlaying Ubuntu operating system and even allows you to switch to
root by using **"sudo su -**". Don't use this user (or root access)
unless directly so by VMware support or if you know what you're doing.
The potential damage is catastrophic, if the wrong file is modified or
wrong command executed.

I'll be focusing on the vRNI CLI functionality, which has a fair amount
of commands:

![](./media/image62.png){width="6.263888888888889in"
height="4.290277777777778in"}

[]{#_Toc35170217 .anchor}Figure 59 -- Command line list of commands

While the same commands exist on both of the appliances, there are some
specific commands that only apply to the Collector. Run those on the
Platform and it will simply output that it will only work on the
Collector. For now, let's focus on the commands that will work on both.

Commands for Troubleshooting
----------------------------

When something's wrong; it's DNS. Or NTP. Always. But just to be sure
all bases are covered, here are a few steps to troubleshoot a Network
Insight appliance.

If the Network Insight appliance is misbehaving; the web interface is
not responding, connections are timing out, the Platform is not seeing a
Collector and is saying it's offline; any and all issues that have to do
with connectivity or reachability, here's where you start.

![](./media/image63.png){width="2.918588145231846in"
height="3.0742465004374453in"}![](./media/image64.png){width="3.2558136482939632in"
height="2.9838659230096236in"}

[]{#_Toc35170218 .anchor}Figure 60 -- Restarting services via CLI

Start with **show-service-status**, which will give you an overview of
all critical services and their respective status. If a service is not
running, you can get more information on the reason why it's not running
by running **show-service-status \--debug**. This command will reach out
to the service and do a few extra checks on the service and its log
files.

Attempt to correct a not running service, by using **services start
\<service-name\>** and see if the service stays online. If it does not,
move on to checking the networking services of the appliance:

![](./media/image65.png){width="4.472432195975503in" height="2.5in"}

[]{#_Toc35170219 .anchor}Figure 61 -- CLI Output for
show-connectivity-status

Running the show-connectivity-status command will take a few seconds,
but it will save you time in the end because it combines a few other
commands into a single command. It will show you the networking
configuration, so you can check whether it's configured properly, NTP
status (and if it's in sync or not), and it will test connectivity to
the online upgrade and support services in VMwares' cloud. Basically,
the entire networking stack is tested using this command.

If any of the network settings are incorrect (and the above output gives
an error), they can be corrected using the **change-network-settings**
command. Be aware that the appliance will reboot after changing these
settings, but you will be warned by the CLI as well.

If NTP is not in sync, you can dive deeper into the reason by using
**ntp diagnose**. This will go into a deep dive on all aspects of the
NTP service, for instance; what the drift is, what time a sync last
happened, it will actually do a port scan on the NTP server to see if it
can reach it, and more.

### Logs

When the network settings and NTP checks out, it's time to dive into the
logs. The command **log-trace** is available to view a list of different
logs, search inside those logs, and monitor/follow them in real-time.
You can also open up historical logs that have been rotated away. To
make it a little bit easier, Network Insight allows you to look at the
individual log files, but also the component (service) itself and it
will figure out the latest available log file for that component. My
advice is to look at the component level and not the actual log files,
unless you're looking for an event at a specific date and time.

There are 2 relevant components you can look at, whilst doing your own
troubleshooting: **saasservice** and **restapilayer**. These 2 services
are pretty much the most important services in the Platform appliance.
All data is received via the **saasservice** (the Collector sends
updates via it) and the **restapilayer** is the internal API service
that provides the web interface with data. If you're having issues with
data collection or presentation, this is where I would start.

![](./media/image66.png){width="6.263888888888889in"
height="3.7958333333333334in"}

[]{#_Toc35170220 .anchor}Figure 62 -- Listing available log components
and following the saasservice

Using **log-trace list components**, a list of available components is
presented, and you can use these components to **grep** from or
**follow**. In the above screenshot, you can see the list of components
on the Platform appliance and the beginning of a **follow** on the
**saasservice** components. For those who know their way around
Linux/Unix; **follow** is essentially a **tail -f** alias.

You can see a bunch of errors in the above screenshot, related to a
rogue Collector that is sending this Platform updates, whilst it's not
registered with the Platform (meaning the Platform is ignoring its
messages). As there are a lot of possible messages and I don't have to
space to list them all; always look for something in the "ERROR"
category and interpret the message to the best of your ability. The
messages themselves are pretty self-explanatory, most of the time.

If you're looking errors that might have occurred at a specific date and
time, you can either open up the right log file using **log-trace
display** and look for errors manually; or you can search the logs using
**log-trace grep**:

![](./media/image67.png){width="6.263888888888889in"
height="1.0986111111111112in"}

[]{#_Toc35170221 .anchor}Figure 63 -- Searching in logs

If you're still lost and have not found an indicator for what's causing
your issue; it is now time to open a VMware support case and provide
them with the support bundles and open up the support tunnel for them to
have a looksie.

Configuring Syslog
------------------

All Network Insight appliances have a vRealize Log Insight agent
installed, which will forward logs to a syslog server. However, it's not
enabled or configured by default. I highly recommend enabling syslog on
all appliances so there's a central place to look at the logs. Both of
the Network Insight appliance types do keep a history of logs, but they
get rotated away. Busy systems will only keep a few days' worth of logs.
When all logs are forwarded to a central log repository; you can decide
how long to keep them.

![](./media/image68.png){width="6.263888888888889in"
height="3.1319444444444446in"}

[]{#_Toc35170222 .anchor}Figure 64 -- Configuring the vRealize Log
Insight agent

The above command is pretty straightforward; supply the IP address or
fully qualified domain name of the Log Insight instance, provide an
optional port number if the CFAPI protocol is not running on its default
port (9543) and provide optional tags.

These tags are interesting if you would like to pass on extra
information in the log messages. They will be recognized by Log Insight
and you will be able to search and filter on, think of them as
identifiers for the specific appliance you are currently configuring.

  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   When you configure syslog via the web interface, you only have the option to send out syslog over UDP, which is unencrypted. However, if you use the log-insight command to configure syslog to Log Insight; it will be encrypted by default.
  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Configuring a Proxy 
-------------------

When using the Network Insight as a Service deployment model, there's a
chance that the Collector, that is deployed inside your data center, has
to connect out to the Network Insight service via a web proxy. This is
commonly done for security reasons, where outgoing HTTP and HTTPS
connections need to be screened and secured by this proxy service. As
the Platform has outgoing connections towards the VMware cloud to check
for updates and initiate a support tunnel (which goes over HTTPS) on
demand, the Platform could also require a web proxy. In any case, the
web proxy configuration is a per appliance configuration (it needs to be
done on each appliance separately) and only available via the CLI
command **set-web-proxy**.

![](./media/image69.png){width="6.263888888888889in"
height="1.7666666666666666in"}

[]{#_Toc35170223 .anchor}Figure 65 -- Enabling web proxy

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   In the on-premises deployment, communication between the Collector and Platform will not go through the web proxy. Only connections to the upgrade and support tunnel services will be proxied. In the Network Insight as a Service deployment, communication between the Collector and Platform will go through the web proxy (as the Platform in the SaaS deployment is external).
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Platform Specific Commands
--------------------------

Most of the CLI commands are exactly the same between the Platform and
Collector appliances, with only 3 exceptions. I'll discuss these
exceptions in the following chapters.

The Platform only has a single command that is specific to it, and it's
only applicable in a cluster as well. If you have a single Platform node
and have not scaled it to support a large environment; this is not for
you.

A Network Insight cluster can be moved between networks and change IP
addresses, if needed. Let's say it was deployed in a testing environment
first and after a while, you wanted to promote it and move it to the
production environment. The consequence being that it needs to move to a
network (typically a different VLAN) with a different IP range. As all
appliances in a cluster talk to each other based on their IP address,
they all would need to be informed of the network changes, using the
command **update-IP-change**. Here's how the workflow looks like in a
3-node cluster:

1.  Move Platform1 into the new network

    a.  Update its IP address via the CLI using
        **change-network-settings**

2.  Change the IP address of Platform1 on both Platform2 and Platform3
    by using **update-IP-change \<old-Platform1-IP\>
    \<new-Platform1-IP\>**

3.  Move Platform2 into the new network

    a.  Update its IP address via the CLI using
        **change-network-settings**

4.  Change the IP address of Platform2 on both Platform1 and Platform3
    by using **update-IP-change \<old-Platform2-IP\>
    \<new-Platform2-IP\>**

5.  Move Platform3 into the new network

    a.  Update its IP address via the CLI using
        **change-network-settings**

6.  Change the IP address of Platform3 on both Platform1 and Platform2
    by using **update-IP-change \<old-Platform3-IP\>
    \<new-Platform3-IP\>**

After executing these steps on all Platform nodes in the cluster, it
will continue normal operation. If you have a bigger cluster, such as
with 5 or 10 nodes, the same steps apply; just multiply by the number of
nodes are there.

![](./media/image70.png){width="6.263888888888889in" height="1.53125in"}

[]{#_Toc35170224 .anchor}Figure 66 -- Changing the IP address of a
clustered node

In above screenshot, you can see an example where a Platform was moved
from IP address **10.79.41.179** to **10.79.41.180**. This command was
executed on a different Platform and after the changed Platform had its
IP address changed via the **change-network-settings** command.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Warning: the update-IP-change command does not check whether the new IP address is actually valid and the right Platform appliance. Make sure you enter the correct new IP address and that it is up and running before you execute!
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Collector Specific Commands
---------------------------

There are only 2 commands that are specifically relevant to the
Collector appliance: **set-proxy-shared-secret** and **vrni-proxy**. It
can happen that you have to move a collector between different Platform
appliances, or if the Platform appliance went belly up for some reason
(got deleted and needed to be redeployed). You can move an existing
collector that had a previous relation to a Platform, to another
Platform using these commands:

![](./media/image71.png){width="6.263888888888889in"
height="2.0083333333333333in"}

[]{#_Toc35170225 .anchor}Figure 67 -- Moving a Collector between
Platforms

First, generate a shared secret by adding a new Collector VM using the
web interface, under **Settings** and **Install and Support** page. Copy
and paste the newly generated shared secret to the
set-proxy-shared-secret command to that it will be trusted by the new
Platform. Then update the IP address or fully qualified domain name of
the Platform that this Collector this be reporting to using **vrni-proxy
set-platform \--ip-or-fqdn \<ip/fqdn\>**. After a few minutes, you will
see the Collector show up in the web interface and it will be ready to
use.

Command Reference
-----------------

Just for your convenience, here's a recap of the commands that come in
handy when troubleshooting Network insight or commands that are good to
know.

  Appliance   Command                                          Description
  ----------- ------------------------------------------------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------
  Both        log-insight                                      Show, set, enable, disable or diagnose the vRealize Log Insight agent
  Both        log-trace                                        Log files; follow them as they get filled up, grep inside them or display a specific log file
  Both        modify-password                                  Change the password of the support and/or consoleuser users.
  Both        nslookup, ping, ssh-server, telnet, traceroute   Handy troubleshooting commands.
  Both        ntp                                              Show, set, manually sync or diagnose NTP configuration.
  Both        services                                         Start, stop or restart services.
  Collector   set-proxy-shared-secret                          Set a new shared secret on a Collector. Used when moving a Collector.
  Both        show-connectivity-status                         Shows the network configuration and tests the connectivity to VMwares' upgrade and support tunnel services.
  Both        show-service-status                              List the status of all services.
  Both        support-bundle                                   Create, delete or copy a support bundle that contains all logs and configuration for VMware support to troubleshoot with.
  Both        support-tunnel                                   Enables or disables the support tunnel. This initiates a tunnel to VMware support and lets them login to your system to have a look.
  Both        telemetry                                        Enables or disables telemetry. This is performance data that is sent to VMware for analysis. VMware support might ask you to enable this when there's an issue.
  Platform    update-IP-change                                 Update the IP address of another Platform appliance. Used when you have a Platform cluster.
  Collector   vrni-proxy                                       Create a new Platform pairing. Used when moving a Collector.

[]{#_Toc35170258 .anchor}Table 2 -- CLI Commands reference

Want to see the options or sub-commands for the above commands? Just try
the command and it will list the help text associated with it.

Analytics
=========

Almost everything about Network Insight has something to do with
analytics in some form. From correlating flows to infrastructure objects
to creating network topologies from the available network devices; it's
all analyzing the data that's coming in. I like to call these types of
analytics, 'passive' analytics. Mostly because you need to go to a page,
dashboard, or do a search query to look at the data. And you would be
looking at something specific, like troubleshooting issues between 2 VMs
or planning out security for a specific application.

Then there are the 'active' analytics, which will actively start
monitoring a set of VMs, containers, physical servers or any other type
of network flows; and will trigger alerts if something happens. There
are 3 kinds of these active analytics inside Network Insight and here's
a brief overview:

-   **Outliers**: Detect whether a group of VMs, containers or physical
    IP addresses that are supposed to behave the same way, are actually
    not behaving the same way. Think of a group of web servers that are
    behind a load balancer, serving up the same web application. If
    everything is operating normally, each web server should have the
    same load. When an outlier is detected, for instance when 1 of the
    web servers goes berserk and starts sending out tons of network
    traffic, you get alerted.

-   **Thresholds (Static)**: These are pretty straightforward; get an
    alert when a certain threshold is reached. Being network focused,
    triggers can be network traffic rates, network packet counts and
    network packet drops (packet loss). For example; set an alert for
    when an application starts showing more than 2% of packet loss or
    for when an entire tenant or department (all their VMs combined)
    starts receiving or sending out more than 100Mbps of network
    traffic.

-   **Thresholds (Dynamic):** Building on the static thresholds; but
    cooler. These dynamic thresholds take the same approach, but with a
    slight difference in configuration. You don't set an actual
    threshold; Network Insight will determine the thresholds based on
    past behaviour. Just like static thresholds, these are available on
    network traffic rate, network packet counts and drops.

-   **Top Talkers**: This one is a bit of an oddball in my
    self-proclaimed 'active' analytics, as it does not send out alerts.
    It does show a bunch of actively analysed data, such as top talking
    objects, new internet services accessed (in the last 24 hours), new
    VMs talking to the internet, new services exposed to the internet,
    and more.

Let's get in to the particulars of each of these.

Outlier Detection
-----------------

The Cambridge dictionary defines outliers as the following:

> *"a fact, figure, piece of data, etc. that is very different from all
> the others in a set and does not seem to fit the same pattern."* [^8]

That is exactly how it is meant inside Network Insight. Using
self-defined groups of similar VMs, Kubernetes Pods or physical servers,
Network Insight will start to monitor them and raise alerts whenever 1
of breaks the pattern that all of them have. As we grow into a more
distributed and micro service type of infrastructures, more and more
workloads only have 1 job and it is possible to predict its behaviour
and say that it is always supposed to behave the same way as its
brethren.

This does not exclude traditional environments though, as those will
have servers with the same functionality as well; think of DNS servers,
Active Directory controllers, SQL Clusters, etc. Depending on how many
roles these more traditional servers have (can't have too many different
roles, otherwise behaviour would be too different), it also adds value
to monitor these.

It starts by configuring an outlier configuration that has all the
aspects of the group that will be monitored and the metrics that the
monitoring happens on. In the example below, I'll create an outlier
group for 5 DNS servers. First, start by giving it a name (1). In this
case; **DNS Servers**.

![](./media/image72.png){width="6.263888888888889in"
height="3.120833333333333in"}

[]{#_Toc35170226 .anchor}Figure 68 -- Outlier configuration options

Grouping (2 & 3) is done based on application tiers or security groups.
The security groups can be NSX-v, NSX-T, VMware Cloud on AWS, or native
AWS security groups; anything that has the security group concept. While
security groups can be used to indicate tiers in an application, they
are typically used for wildly different purposes as well. Security
groups can be used to segment tenants or departments from each other, or
segmentation between different applications, and so on. That's why I
prefer the use of application tiers for outlier groups. Your application
constructs should already exist inside Network Insight for the
application dashboard, security planning, etc.

  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Make sure a group with a minimum of 3 VMs or physical IP addresses is selected, as that is the minimum for an outlier group. It's not possible to have good results with outlier detection on just 2 members.
  ------ ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Outlier detection uses the data from network flows, where traffic rate,
number of packets, or the number of flow sessions can be used to base
the outliers on (4). Take note that the metrics on **Total Flow
Traffic** and **Network Traffic Rate** are based on the same data; the
only difference is that total flow traffic is the total amount of bytes
and the network traffic rate is the average (basically, the bandwidth
graph) traffic rate. The other options are self-explanatory.

You can decide which direction (5) needs to be monitored: incoming,
outgoing, or both. The reason for picking a single direction could be
simple: either you don't care about incoming traffic and only want to
pick up outgoing traffic (to detect outgoing denial of service attacks),
or if the outgoing traffic is too random to predict (may be the case
with streaming or download servers) and only the incoming traffic is
predictable. If you're going with a specific direction, you usually know
why. Most of the time, selecting both directions is the way to go.

Apart from the traffic direction, the type of traffic (6) is also an
option. Only monitoring East-West traffic, only internet traffic, or all
traffic can be selected. This is useful to limit the monitoring on only
internet traffic, and with that limit the load on the Network Insight
platform, if you fully trust and don't care about the East-West traffic.
Another reason to choose the traffic type, is if the East-West traffic
is predictable and flows between the different application tiers and if
the internet traffic is unpredictable.

At number 7, we have the option to limit outlier detection on a specific
network port. By default, every network port that is detected coming in
and going out from the members are used for detection. But if you're
only interested in web traffic or another application that uses a
specific port; you're free to select these. Fun fact: the configuration
page will detect which network ports are in use for the group you've
selected and will show them.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Another reason for selecting the ports, is that an outlier group currently supports a maximum of 20 ports to monitor simultaneously. A warning will trigger when there are over 20 ports detected when 'All Ports'
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Lastly, the sensitivity (8) can be selected: low, medium or high. The
high sensitivity will trigger more quickly, and the low sensitivity will
trigger less quickly.

Changing the sensitivity setting affects the outlier detection by
changing something called the z-score for the median absolute deviation
(MAD) algorithm [^9] that is used to detect outliers. Median absolute
deviation is a mathematic process to get the median (average) value of a
range of numbers. This process is applied to the metric numbers you've
selected to monitor, such as network traffic.

As a very simple example, consider this number range: 1, 3, 4, 6, 10.
The median value is 4; not only because it's in the middle, but also
because it's the closest to the average of the sum of this number range
(4.8). Then the z-score comes in to determine what percentage above and
below the median is considered to be an outlier.

Low sensitivity means that the median has a **60%** buffer. So, take the
previous number range and get the median, which is 4. Then apply a 60%
buffer below and above that 4. Meaning the lower boundary is 1.6 and the
high boundary is 6.4. In that number range, number 1 and 10 would be
outliers as they fall out of the buffer.

Medium sensitivity has a buffer of **40%**. On the same number range and
the same median, 4, the lower boundary is 2.4 and the higher boundary is
5.6. Meaning 1, 6, and 10 will be classified as outliers.

High sensitivity has a buffer of **30%**. Same exercise on the number
range; lower boundary is 2.8 and the higher boundary is 5.2. Numbers 1,
6, and 10 will be classified as outliers; the same as the medium
sensitivity, in this case.

And this concludes our brief maths class. ;-)

When everything is filled out, you will get a preview of the outlier
graphs. It will use historical data to show a graphical representation
of the selected metric (network rate, packets or flows), which allows
you to preview the result, see any current outliers that are already
detected and save it to the system, when you're happy with the
configuration.

Once saved, the outlier configuration is available under the Outlier
pages and it will start monitoring and generating events when outliers
are detected. Jumping to a specific outlier group is easy by doing this
search query: **Analytics Outlier Configuration \'DNS Servers\'**

![](./media/image73.png){width="6.263888888888889in"
height="2.8194444444444446in"}

[]{#_Toc35170227 .anchor}Figure 69 -- Outlier detection result

Above is the result of the DNS Server outlier detection. It's clear that
2 of the DNS servers (**cmbu-sc2dc-01** and **cmbu-wdcdc-01**) are
behaving completely different than the others and have been marked as an
outlier because of it.

Once the outlier configuration is in place, Network Insight will start
to generate events (alerts) whenever an outlier is detected. The cool
part about these events that the evidence graph is included:

![](./media/image74.png){width="6.263888888888889in"
height="2.808333333333333in"}

[]{#_Toc35170228 .anchor}Figure 70 -- Outlier detection event

Getting alerts from the outliers is a bit trickier than expected. In
order to get either emails or SNMP traps when an outlier is detected,
you have to set up a user defined alert from the **outlier events**
search query. Do so using the alarm bell icon at the top right and you
will be able to choose between getting emails and/or SNMP traps when
there's a new outlier detected. Out of the box alerts for outliers are
currently not there, so this is a work-around.

Static Thresholds
-----------------

Thresholds are relatively straightforward: set a boundary as a threshold
limit and as soon as something goes over it -- trigger an alert.

Network Insight thresholds are the same way. Based on networking metrics
such as, traffic rate, number of packets and packet drops, a boundary
can be set, and alerts will be sent out when a workload (or group of
workloads) crosses that boundary. Static thresholds are really that
simple. Dynamic thresholds have a bit more bite to them, which is why
I'll go into those in the next chapter. But for now, let's focus on what
you can do with static thresholds.

Let's say you've got a workload or group of workloads that should not
over a network traffic rate of 1Gbit per second. This can be a tenant,
department or just a specific web application that's running on a
distributed cluster, or even a streaming application that's running on 1
VM. If it hits that 1Gbit; you want to be notified.

Another example is when a workload should always generate traffic, like
a storage or database replication, or an Active Directory cluster, even
DNS servers should typically always generate traffic. In this case, when
the traffic flatlines or gets under a set boundary; you want to be
notified.

And as a last example, incoming internet traffic can be monitored in a
threshold. If your data center never has more incoming traffic than
1Gbit per second and it suddenly receives 5Gbit per second from the
internet; there's a chance the network is under a denial of service
attack. Which you would like to be notified about.

For these use cases, thresholds can be configured. Thresholds can be
found under the Analytics menu, or you can simply type **threshold
configuration** into the search bar.

The main page of the thresholds will list all configured thresholds and
the related events (threshold breaches) along with options to modify and
remove them. Let's go through the creation of a threshold.

![](./media/image75.png){width="6.263888888888889in"
height="6.010416666666667in"}

[]{#_Toc35170229 .anchor}Figure 71 -- Creating a threshold

There's a lot going on in that page, let's take it step by step. Your
attention in the screenshot will probably go straight to the preview
(5). But to get there, first fill out a name for the threshold (1).
Something to recognize it by when it triggers an event and an alert is
sent out.

Next, thresholds can be based on a few objects. The scope can be set to
either **Virtual Machines**, which has a search definition to is;
meaning it can be any VM with certain characteristics, such as being in
a specific vCenter folder, having a name prefix, residing in an AWS VPC,
with a X number of vCPUs, etc. You can also combine conditions, for
example; all VMs in a certain vCenter folder and in a specific network.

Besides the VM search, the scope can also be set to Flows. This allows
you to search for flows, just as with the VM option. Meaning you can
search for flows with a specific destination port (for example; all
traffic going to DNS servers), destination country, incoming traffic
from the internet, outgoing traffic to the internet; you name it.
Combining conditions is also possible with the flow search, for example;
incoming internet traffic coming from a specific country.

Lastly, the scope can also be set to an **Application**. These are the
applications that explained in the chapter [Application
Constructs]{.underline}.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Typically, the Application scope setting is used to monitor workloads running specific applications. The Flow scope setting is mostly used in cases where specific network traffic has to be monitored (like internet traffic or inter-data center traffic).
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

While select the scope, there's a handy reference (2) to see how many
VMs and/or Physical IP addresses are seen in this scope. Physical IPs
can show up in applications and or flow searches, VMs will show up in
any of the scope options (if applicable, of course).

When the scope is set, move on to the condition (3). This condition is
written in a sentence format with a bunch of option embedded; that's to
easier understand what you're actually configuring.

Here's the default:

This translates to, that by default, it will look at the network traffic
rate on an individual VM basis and will alert when it reaches more than
ZZZ Kbit per second. The default is the setting that is most used, but
there's a world of options here.

### Monitored Metric

First, the metric option can be set to 6 different metrics. I'll explain
each of them in the table below.

  Metric Option                 Description
  ----------------------------- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  network traffic rate          Typical network traffic rate in Kbit per second. This is the last real-time value in the bandwidth graphs of a workload.
  max network traffic rate      ?
  total network traffic         ?
  network packet count          Number of packets. This can be useful to detect denial of service attacks that are based on a lot of smaller packets. The packet count would go up, but not necessarily the bandwidth itself (these smaller packets can be 2-5% of regular traffic).
  network packet drop           Number of packets that are dropped. There are mechanisms in place (TCP has this built in) to recover from dropped packets, and it's pretty common for packet drops to occur. Especially over the internet. Don't put the value at 1 -- you'll go crazy with alerts.
  network packet drop percent   Number of packets that are dropped in percentage form. This is a better option for when looking at packet drops. When network traffic goes up, the packet drops do as well; they usually scale up with the amount of traffic. Packet drops over 5% will impact traffic significantly and between 1 and 2.5% is 'acceptable'. [^10]

[]{#_Toc35170259 .anchor}Table 3 -- Threshold metric options

### Aggregation

The next option, **aggregated over**, determines at what level the
threshold is constructed. If there's a group of workloads selected, you
can decide to put the threshold over this entire group (option **entire
scope**), or to put the threshold on each individual member. For
example, if you're creating a threshold for a tenant/department, which
is not allowed to go over 1Gbit per second; select the **entire scope**
option. If you want to get alerts when any VM inside a bigger group goes
over 500Mbit per second (no matter what the rest of the VMs in the group
do); select **virtual machine** as the aggregation to individualize the
monitoring.

I should note that the options in the aggregation option change per
scope type. If **Application** or **Virtual Machines** is selected, you
can aggregate on the entire scope or per virtual machine. When Flows is
selected, the aggregation option changes to **source VM/IP**,
**destination VM/IP** (these are self-explanatory), **service endpoint**
(a service endpoint is a service, like a webserver running on a
workload. For example; VM webserver-01 port 80 and VM webserver-01 port
443 are two different service endpoints), and **entire scope**.

So, with the Flow scope option, there is more choice to individualize
the monitoring. Which makes sense, because flows have more context into
the traffic and can separate service ports that run on the same
workload.

### Threshold Breach Value

Moving on to the options that determine when the threshold will be
breached. First, the **when** option determines whether it needs to
watch the latest real-time value (option **any value**), or **the**
**average** during a specified time window.

Selecting **any value** will simply monitor the traffic and create an
alert when it crosses the threshold. If there are a lot of spikes in the
network, this could lead to false positives. That's why there's also
**the average** option, which can take the last **30** or **60** minutes
into account when monitoring, grab the average of that time and use that
average as the threshold. This smoothens out the spikes and reduces
alerts.

  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   When selecting **any value** (and not the average of 30/60 minutes), Network Insight will take the average of max value of the last 5 minutes to trigger upon. To be specific, **max network traffic** rate and **total network traffic** take the max value of the last 5 minutes. The rest of the metrics take the average value of the last 5 minutes.
  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Then, select whether you want to create the alert when the metric
**exceeds** the threshold upper bound, or if it **drops below** the
lower bound, or **is outside the range** of a lower and upper bound, or
**deviates from past behavior**. The upper and lower bounds are
something you'll be able to configure at the bottom of the condition and
the fields will change, depending on which option is selected. When
**deviates from past behavior** is selected, the threshold becomes
dynamic and Network Insight will figure out the right threshold values.
More on that later.

### Alerting

Let's not forget to set an alert based on the threshold you're creating.
Whenever a threshold is breached, an event will be created. This event
will be visible in the open problems list and you can search for all
threshold events using this search query:

events where name = \'AnalyticsThresholdEvent'

If the breach showing up in the web interface and you don't want an
email or SNMP Trap when it gets breached; just select a severity
(importance) and you're good to go and save the threshold. It will start
monitoring and let you know in the interface when it breaches. This is
fine for not-that-important workloads and breaches that you don't need
to know right away. Always determine this on a per case basis, as you
definitely don't want to overcrowd the email or SNMP Trap notifications.
If there are too many, people stop paying attention.

When this is one of those important thresholds and someone needs to be
notified on the moment it gets breached; configure 1 or more email
addresses to notify and/or tick the checkbox **Send SNMP Trap** to have
Network Insight pass the event to another system and takes care of the
actual notifications.

Now you're really done; go ahead and save the threshold to the system to
activate it.

Dynamic Thresholds
------------------

As announced, here's a bit more information on what happens when you
select **deviates from past behavior** as the threshold breach trigger.
This is where the system learns a baseline of network behavior of a
workload or group of workloads and uses the baseline of that past
behavior to determine whether it is doing something that is out of
character. For example; if the workload does a steady stream of 10Mbit
per second regularly and then a spike of 100Mbit per second happens, it
is qualified as a threshold breach.

The other way around will also trigger a threshold breach; if the
workload does 10Mbit per second regularly and it suddenly drops to 1Mbit
per second, a threshold breach is raised.

Without setting a static upper or lower boundary value, Network Insight
will simply notify you when workloads divert from their regular routine.

I know I said the mathematics class was over, but I do want to give you
some background on how this works. Bear with me.

It does this by creating a baseline of network traffic behavior, for a
minimum of 7 days and a maximum of 21 days. Before the 7 days of history
is there, Network Insight will keep analyzing the network traffic, but
it will not yet generate any alerts based on suspected threshold
breaches. Data that is older than 21 days will be aged out of the
dataset and not be used for the analytics. This is typically enough time
to get a clear view of the intended behavior of a workload and alert
when it goes out of bound.

The baseline data is a so-called moving mean[^11] and standard
deviation[^12] dataset. The mean (average) is calculated over the
network traffic of the last 21 days. This mean value is then used as the
benchmark to calculate the standard deviation. In somewhat plain
English, the standard deviation is a measurement that quantifies the
amount of variation within a dataset. There are examples in the
Wikipedia article I linked in the footnote, but it gives a numbered
value to compare a value with the average.

Dynamic thresholds have the option to be configured with a **high**,
**medium**, and **low** sensitivity. The **high** sensitivity uses a
standard deviation value of **2**; meaning if the current network
traffic value is **2** times as much or less than the average of the
last 21 days, the threshold is triggered. The **medium** sensitivity
uses the standard deviation value of **2.5**; meaning **2.5** times as
much or less than the average of the last 21 days. The **low**
sensitivity uses a standard deviation value of **3**; meaning, well, you
get it.

To make it a little more complicated, you can also select whether to use
the average of the last 30 or 60 minutes or use the maximum or average
of the last 5 minutes. This is the same concept as we saw in the INFO a
few pages above, in the chapter [Threshold Breach Value]{.underline}.

Using the Search Engine
=======================

**This chapter was authored by Rohit Reja, Senior Staff Engineer on
Network Insight. He was part of the original ArkinNet team.\
**Contact Rohit here: <https://www.linkedin.com/in/rohit-reja-1b11335/>

Edited by: Martijn Smit

vRealize Network Insight provides a datacenter semantics aware search
engine to quickly find objects of interest based on their configuration.
This search engine is built on top of a highly scalable Elastic Search
cluster, and it can provide rich insights into complex virtual and
physical data center compute and network fabric.

The search engine is powered by an Elastic Search cluster, which is the
first service that gets addressed when a search is requested. Elastic
Search can point to other databases from where Network Insight will pull
data. For example, index pointers for metric refer to the HBASE
database, while configuration items (like VM properties) get referred to
PostgreSQL. Indexing happens on a continuous basis; each time an object
is updated in any database, Elastic Search will update its index.

It is possible for this index process to lag a few seconds, causing old
data to still show up or new data to not show up yet. That's why you can
monitor the indexer lag from the **Install and Support** page in the
**Settings**.

The syntax is technical natural language, and the search bar helps by
doing autocomplete on keywords and values (i.e. VM names). You can
simply start typing what you need into the search bar and chances are,
you will find the search query you need. Think of it as a Google for
your data center.

Configuration objects, metrics, pinboards, static pages, and flows can
all be searched for. Configuration objects are single values that
typically don't change every second (e.g. *CPU Count*, *Host*, *VM*,
*Distributed Virtual Portgroup*, etc.). Metrics have multiple values on
a timeline and tend to change a lot (e.g. *CPU Usage*, *Network Rate*,
*Write Latency*, etc.). The ability to search for pinboards and static
pages (such as the Security Planner page), makes it so that you can
navigate entirely by using the search bar, just like on a command line
interface.

The technical natural language that is being used, is almost exactly
like database query syntax. If you have a data base administrator (DBA)
background (or DBA colleague sitting next to you), the syntax will be
even more intuitive.

Let's look at some examples:

Find all virtual machines with 4 vCPUs.

vm where cpu count = 4

Display a sum of traffic flow for all servers (virtual and physical) in
VLAN 2003

sum(bytes) of flows where source l2 network = vlan-2003

Find all virtual machines to whom VMs in VXLAN 5001 are talking to.

list(dst vm) of flows where src l2 network = vxlan-5001

Find all applications that are talking to the application 3TierApp02 and
display how much traffic is being sent.

sum(bytes) of flow where Destination Application = \'3TierApp02\' group
by Source Application

![](./media/image76.png){width="6.263888888888889in"
height="2.9611111111111112in"}

[]{#_Toc35170230 .anchor}Figure 72 -- Search query & results example

The cool part about the search engine is, is that all results and
searches are reusable. You can create pinboards from different searches,
personalizing these pinboards completely. You can also create
search-based events and get alerts whenever the result of a search
changes (get notified whenever firewall rule changes happen) or when
there are no results (get notified when something is deleted).

Search is also exposed via the public APIs for automation, making it
possible to programmatically execute searches and get back the results
for further processing. Considering all data inside Network Insight is
available via the search, this means that you can export and process any
and all information for your own purposes. Organizations have built
automation processes around Network Insight to import data into Security
Event & Information Management (SIEM) systems, Security Operation
Centers (SOC) get notified on any firewall rule changes and verify them
against the change management trackers, service providers pull network
bandwidth calculations to use for billing purposes, the list goes on.
More information on how to automate with Network Insight and examples in
the chapter [Automating Network Insight.]{.underline}

Building Searches
-----------------

vRealize Network Insight provides a structured query with components
illustrated in below diagram. I'll explain the different components in
this chapter.

![](./media/image77.jpeg){width="5.3086395450568675in"
height="0.7407403762029746in"}

[]{#_Toc35170231 .anchor}Figure 73 -- Search query structure

Consider the following query:

VMs where ip address = '10.10.10.0/24\` order by vCPUs

Let's break it down and align it with the query structure.

-   *"VMs"* is the entity type,

-   *"where ip address = 10.10.10.0/24"* is the filter clause,

-   *"order by vCPUs"* is the order by clause (sorting).

Entity Types 
------------

An entity type represents the type of object that we want to search for.
This is the base for the results that will come back, and is the
starting point for the filter. In the above example, VMs is the entity
type on which the results are based on. Then it goes on and filters the
results based on a property (*ip address*) that is attached to that base
entity.

The entity type can be in singular and plural form; VM or VMs. The
entity type is the only mandatory property in a search query. The
projection, filter, group by and order by clauses are optional.

Some common entity types are:

-   VM (Virtual Machine)

-   Host (ESXi Host and other Hosts)

-   Datastore

-   Vxlan / Vlan

-   Pnics (Physical nics)

-   Vnics (VM nics)

-   VRF (Logical Routers)

-   Route

-   Application

-   Flow

A full list of entity types can be found inside Network Insight. Simply
search for 'help' or click the link "Learn more about supported
properties" that is placed on the bottom of each search (see Figure 74).

![](./media/image78.tiff){width="2.962962598425197in"
height="1.2386964129483815in"}

[]{#_Ref22480916 .anchor}Figure 74 -- Search help: find all supported
properties

To give you a few more examples of how to spot what the entity type is,
the table below lists a few.

  Search query                                             Entity Type
  -------------------------------------------------------- ------------------
  Router Interface where IP Address like '192.168.10.\*'   Router Interface
  Application where Problem = \'Threshold Event\'          Application
  Datastore where Free Space Percent \< 10%                Datastore
  Flows where Source Application = CRM                     Flows
  Network Rate of Switch Ports order by Network Rate       Switch Ports

[]{#_Toc35170260 .anchor}Table 4 -- Search examples, mapping out entity
types

**Note**: The last example will become more clear when we go through the
[Property]{.underline} explanation.

Meta Entity Types 
-----------------

The meta entity type can refer to multiple concrete types. For example,
VM refers to VMware VM, Azure VM, and AWS EC2 Instance. The same goes
for Firewall Rule, which will include NSX Firewall Rules, AWS Firewall
Rules, Palo Alto firewall rules, basically any firewall rules that
Network Insight discovers. When searching for a meta entity type, the
interface will show all included entity types. This allows you to filter
on the exact firewall rules types you're searching for.

![](./media/image79.png){width="2.1296292650918636in"
height="1.863426290463692in"}

[]{#_Toc35170233 .anchor}Figure 75 -- Search for a meta entity type and
get all included entity types

Meta types exist to make the experience holistic, transparent to you.
Considering the vast amount of different configurations and entity types
an infrastructure engineer deals with, it's almost necessary to allow
you to search for firewall rule and let the underlaying tool figure out
on which actual platform (whether it be NSX, a physical firewall, or the
cloud (and then which cloud)) you need to be.

Entity Property 
---------------

Properties on entities are the details you're typically interested in.
These properties can be grouped into the following categories:

### Configuration Property 

Configuration properties of entity is something that typically does not
change that often. It would need an interaction on the infrastructure in
order to change.

For example, CPU Count, Memory, OS, in VMs. Or, Destination Port,
Protocol, Source IP, in Flows. These properties tend not to change a
lot.

### Reference Property

These are rather interesting. Objects inside Network Insight get
correlated to other objects that relate to it, and these related objects
get linked to the object in question. To make that a little less vague;
an VM is directly related to the host it lives on, the datastore where
it stores its data, the network and portgroup that it is connected to,
etc.

These reference properties will appear as a link when looking at an
object. On the VM dashboard, or when looking at VM search results, you
will notice that you can click on a bunch of properties and get taken to
their dashboard. Those are reference properties.

You can also use these reference properties in searches, but more on
that in [Reference Traversal Queries]{.underline}.

### Metric Property

Metrics are properties that do change a lot and have a timeseries
attached to it. Examples for VMs are CPU Usage, Packet Drop Rate, Write
Latency.

To get an idea of what metric properties are available for an entity
type, head to its dashboard and look at the Metrics heading. Figure 76
gives an example for the metric properties on a switch port.

![](./media/image80.png){width="6.263888888888889in"
height="2.2180555555555554in"}

[]{#_Ref22484064 .anchor}Figure 76 -- Search Metric Properties: example
on switch port

### Meta Property

Remember the [Meta Entity Types]{.underline}? Meta properties are the
same thing, only attached to another entity. This is a group of
properties that's consolidated under a single property.

For example, the Flow entity has a meta property called VM. This refers
to both Source VM and Destination VM. Here's an example:

Flow where VM = 'my-vm'

Above search is equivalent to:

Flow where Source VM = 'my-vm' or Destination VM = 'my-vm'

Similarly: Flow where IP Address = '192.168.10.0/24'

is equivalent to:

Flow where Source IP Address = '192.168.10.0/24' or Destination IP
Address = '192.168.10.0/24'

These meta properties make it easier to execute searches and optimize
the amount of typing you have to do.

Filter
------

A filter clause is used to filter search results. The condition in a
filter clause consists of an entity property, comparison operator, and
value. This is also where all previous discussed properties can be used
to narrow down the results.

Here's an example: VMs where CPU Usage \> 80%

In this search query, VMs is the entity type and the filter is based on
the metric property for CPU Usage. Using the comparison operator
(**\>**) and value, the returned VM list is filtered on VMs that have a
CPU Usage higher than 80%.

There's a lot possible with the filter conditions and comparison
operators. Here is a graphical overview of the syntax:

![](./media/image81.jpeg){width="4.25in" height="4.902777777777778in"}

[]{#_Toc35170235 .anchor}Figure 77 -- Search filters; condition and
comparison operators

It is possible to use multiple filter conditions in a single search and
you can mix and match however you would like. To get a little more
feeling with how these operators work and for examples on how they work,
see the table below.

  Operator     Description                          Example
  ------------ ------------------------------------ -----------------------------------------------------------
  AND          Multiple conditions need to be met   VM where Account = \'AWS\_xx\' and AWS VPC = 'My-VPC'
  OR           Single condition should be met       Flow where Port = 80 OR Port = 443
  LIKE         Wildcard search                      VM where name LIKE 'web'
  =            Exact search                         VM where name = 'web01'
  !=           Anything but                         VM where name != 'web01'
  \<           Lower than                           Datastore where Free Space Percent \< 10%
  \<=          Lower than or equal to               VMs where CPU Count \<= 2
  \>           Higher than                          VMs where CPU Usage \> 80%
  \>=          Higher than or equal to              VMs where Memory \>= 8GB
  IN()         Values in this list                  Flows where Port IN(80, 443)
  NOT IN()     Values not in this list              Datastore where Filesystem Type NOT IN(\'NFS\', \'VSAN\')
  IS SET       Value has to be set                  Flow where Firewall Rule IS SET
  IS NOT SET   Value has not to be set              VM where Security Group IS NOT SET

[]{#_Toc35170261 .anchor}Table 5 -- Search filter condition examples

Projections
-----------

A projection clause in a search query decides what fields must be
displayed from the filtered entities. By default, the search results
will list commonly used properties of an object. For example, if you
search for VMs, the results list will show the VM name, network it's
attached to, disk information, and IP address. You can then either
expand the result or go to the VM dashboard to get the rest of property
information (such as CPU, memory, power state, etc.).

Using the projection clause, you can bring up a specific property
directly in the results. Projections are an optional clause. If the
projection clause is not specified, then the default set of properties
are shown for entities in the results. Projection clause may contain one
or more of following items:

a)  Property

b)  Count

c)  List

d)  Aggregation

e)  Series

### Property

If you search for an entity default set of properties are shown in the
search results. If you want to see other properties (including metric
properties), you can use property projection. For example, consider the
following search query:

OS, CPU Cores of VMs where Name = myvm

The above search query will show the operating system and the number of
CPU Cores of the VM named 'myvm', as shown below:

![](./media/image82.png){width="6.23373031496063in"
height="2.268893263342082in"}

[]{#_Toc35170236 .anchor}Figure 78 -- Searching with property projection

As you can see, the requested properties are now shown first, in a
highlighted fashion.

A projection clause can also include metric properties, combined with
configuration properties. This will automatically show a line graph with
the requested metric on the results page. If no time window is provided,
the metrics will be shown for the last 24 hours.

Here's an example:

CPU Cores, CPU Usage Rate of VMs where Name = myvm

![](./media/image83.png){width="5.628435039370078in"
height="2.323530183727034in"}

[]{#_Toc35170237 .anchor}Figure 79 -- Searching with property
projection, including metrics

The above example can be done on any object, whether it be a VM, flow,
datastore, switch port, etc. You can also add multiple metrics to the
search query, making multiple line graphs appear in the results. A good
use case for that, would be to search for network rate and packet loss
on switch ports.

Using the Network Insight search engine is by far the quickest way to
get specific information from your environment, dependent on that you
know what you are looking for. This can be a specific object
(troubleshooting a switch or VM), or specific metrics.

### Count 

Mostly used when building pinboards, the Count projection can return the
sum the number of objects in a search query result. It can be used to
count the number of VMs inside a cluster, network flows coming from a
specific region, ports or source IP range, number of datastores that
have a write latency higher than 5 milliseconds, the list goes on.

Here are a few examples:

count of VMs where Security Group = \'sg-1\' and CPU Usage Rate \> 60%

count of Flows where Source IP = 10.152.30.208/24.

count of Switch Port where Total Packet Drops \> 100

count of Datastore where Write Latency \> 5ms

![](./media/image84.png){width="5.708333333333333in"
height="1.7361111111111112in"}

[]{#_Toc35170238 .anchor}Figure 80 -- Searching with a count operator

Considering the result will be a number, these search queries are
perfect to put on an auto refreshing pinboard that is glued to the wall
of your office.

### List 

This is another interesting one. The list operator should be used
whenever the filter condition cannot be applied or if it is related to
the object you want back. To make that a little more concrete, here's an
example:

list(Host) of VMs where CPU Usage Rate \> 95%

![](./media/image85.png){width="5.934722222222222in"
height="2.082352362204724in"}

[]{#_Toc35170239 .anchor}Figure 81 -- Searching with a list operator

In this case, a list of Hypervisors is returned that host any VM that
has a higher CPU usage of 95%.

The object inside the list operator needs to be directly associated with
the object in the filter, and not indirectly associated. Meaning you can
get a list of Hosts from VMs, Datastores from Hosts (and VMs), Switch
Ports from Hosts, etc. However, you cannot get a list of Switch Ports
from VMs, as the direct association of Switch Ports will be with Hosts.

Alternatively, you can use reference queries, which can go deeper (and
do indirect associations), but also have more overhead. More on that in
the chapter [Reference Traversal Queries]{.underline}.

### Aggregate Functions

Just as the Count operator, an aggregate function allows you to
calculate a single value from multiple sources. This retrieves
*numerical* or *metric* properties and execute a calculation on them.
The outcome of that calculation will be the search result.

I'll go into the supported aggregate functions below.

#### Max

Get the highest value out of the search results. Consider the search
will return vCPU numbers for your VMs, the max operator will be able to
tell you what the highest number of vCPUs is.

Example: max(vCPUs) of VMs

![](./media/image86.png){width="1.8136778215223097in"
height="1.821428258967629in"}

[]{#_Toc35170240 .anchor}Figure 82 -- Searching with a max operator

The above result indicates that out of 789 VMs, the highest number of
vCPUs that those VMs have, is 16 vCPUs.

#### Sum

Sometimes humans keep it simple and straightforward. These aggregate
functions are an example of this. The sum operation, well, returns the
sum of the requested values. You can use this to get the number of VMs
attached to a VLAN, the amount of memory in use by VMs on a specific
host, the amount of traffic going towards the internet (or certain
geographical regions), etc. The possibilities seem to be only limited by
imagination.

Example: sum(Bytes) of Flow where Source Continent = 'Europe'

![](./media/image87.png){width="3.72543416447944in"
height="2.0119050743657043in"}

[]{#_Toc35170241 .anchor}Figure 83 -- Searching with a sum operator

#### Min

The min operator is effectively the same as the max operation; it just
gets the minimum value of the search results. Ever wondered which switch
has the lowest number of switch ports in use? Ever wondered which blade
chassis has the least blades in use? The min operator can help.

#### Avg

Lastly, the avg operator can be used to get an average value from the
search results. Just like the previously discussed operators, Network
Insight will go through the results of the search query and return the
average of those results. What is the average count of vCPUs or vMemory
for VMs on a cluster, what is the average transfer bytes for a flow in
your VDI cluster, compared to the production server cluster, etc.

Here's an example: avg(vCPUs) of VMs group by Host order by avg(vCPUs)

![](./media/image88.png){width="6.263888888888889in"
height="2.5458333333333334in"}

[]{#OLE_LINK9 .anchor}Figure 84 -- Searching with an avg operator

The above example returns the average count of vCPUs of VMs on each
host.

Before I forgot; all aggregation operators can also be used in the
**group by** clause, as you can see in the above example. When these
operators are combined with the **group by** clause, there's an
opportunity to **order by** something. More on ordering search results
later on but know that the aggregation operators are included.

### Series

This is one of the coolest projection functions, by far. Network Insight
can show line graphs for any metric that it collects. From network
bandwidth usage, to CPU usage, to memory usage, you name it. The one
thing that the out of the box metrics have in common, is that those line
graphs will show only one metric type for a single object in the same
graph.

Meaning, there will be different line graphs for the CPU, memory, and
network usage on the VM dashboard. There will also be a different line
graph for the network usage per each VM. That is where the series
projection comes in.

It can combine metrics from multiple objects into a single line graph.
For example; it can combine all network flows coming from VMs in the
same cluster, or all network flows going towards the internet, of all
CPU usageof all VMs in a specific cluster, etc.

Here's an example, combining all internet traffic into a single line
graph:

series(sum(Byte Rate)) of Flows where Flow Type = \'Destination is
Internet\'

![](./media/image89.png){width="6.263888888888889in"
height="1.0972222222222223in"}

[]{#OLE_LINK15 .anchor}Figure 85 -- Search; using the series()
projection to combine metrics

The metrics inside the series projection can be any of the metrics
available in Network Insight. You can also request multiple series in
the same search, to compare different metrics on the same time line. An
example of this, might be looking for the averaged used CPU and Memory
metrics for all servers with 'db' in their name:

series(avg(CPU Usage)), series(avg(Memory Usage)) of VMs where Name like
db

![](./media/image90.png){width="6.263888888888889in"
height="1.9854166666666666in"}

[]{#OLE_LINK11 .anchor}Figure 86 -- Search; using multiple series()
projections to combine metrics

Ordering
--------

All search results can be sorted by using the **order by** clause. This
clause takes one parameter, and results can be ordered descending or
ascending (the default is descending).

Ordering becomes handy when you are looking for objects that are using
the most resources. A few examples below.

Looking for the workloads that send the most network traffic? Order by
Bytes

Looking for the VMs with the most vCPUs? Order by CPU Count

Looking for the VMs that use the least memory? Order by Memory Usage asc

The web interface can also be used to define the **order by** clause, by
using the Sort selection

Grouping
--------

When you're using the search engine to identify trends, you typically
want to group objects together, to get the right data. For example, you
can group network flows by Country, list the number of VMs inside
Security Groups, list the amount of bandwidth used by network ports,
list the number of VMs on different operating systems (find the 2 VMs
that are still running Windows 2003), the list goes on.

The **group by** operator can be used to group entities together, when
they are grouped by a property. When using this operator, the group name
and the number of entities found, will be shown.

Here's an example that list the number of VMs in each security group:

VMs group by Security Group

![](./media/image91.png){width="6.263888888888889in"
height="1.8173611111111112in"}

[]{#OLE_LINK17 .anchor}Figure 87 -- Search; using the group by operator

It gets more interesting when you start combining grouping with the
previously explained Aggregate Functions. By combining these two, you
are able to retrieve the sum, maximum, minimum, or average of a property
while grouping it on another property. Let's look at a few examples
below.

Retrieving the amount of bandwidth that comes out of each L2 network:

sum(Bytes) of Flows group by Source L2 Network

![](./media/image92.png){width="6.263888888888889in"
height="1.582638888888889in"}

[]{#OLE_LINK21 .anchor}Figure 88 -- Search; using the group by operator
and aggregate functions for L2 traffic

Retrieving the number of incoming firewall rules inside your AWS
accounts, grouping by VPC. This will display the number of rules, and
the number of security groups inside each AWS VPC:

sum(Incoming Rule Count) of AWS Security Group group by AWS VPC

![](./media/image93.png){width="6.263888888888889in"
height="3.1743055555555557in"}

[]{#OLE_LINK35 .anchor}Figure 89 -- Search; using the group by operator
and aggregate functions for AWS rules

Limiting
--------

When you order a search, sometimes you're only interested in the top 10
flows. Or the top 5 VMs that are using the most storage, CPU, or memory.
To limit the search results by a specific number of results, simply add
the **limit** operator. For example:

VMs order by CPU Cores limit 5

Flows where Flow Type = \'Destination is Internet\' order by Bytes limit
10

Reference Traversal Queries
---------------------------

Let's say you want to filter the search results based on a property that
is not directly attached to the entity you're searching for. An example
of this would be to filter on the CPU usage of the Host, while searching
for VMs. In this case, reference traversal queries can be used to do
refer to the property that you want to filter on.

To refer to the properties of a referenced object use a DOT(.) operator
with the primary property. Behind the 'parent' property, the child
properties can be used normally. Think of this traversal as going a
folder deeper into the entities.

Let's look at a few examples, in order to give you a better
understanding of how this looks.

Find all VMs on hosts with a high CPU utilization:

VMs where Host.CPU Usage Rate \> 95%

Find all VMs on a specific compute blade:

VMs where Host.Blade =
\'\[ucs-1.vrni.cmbu.local\]-\[sys/chassis-1/blade-7\]\'

Find all VMs that are located on a cluster that does not have the NSX
Distributed Firewall enabled:

VMs where Cluster.Firewall Feature Enabled = false

Take note of the DOT (.) in between the entity (Host or Cluster) that is
directly attached to the entity that is being searched on (VM) and the
property that is being filtered on. Because Network Insight only
correlates and stores properties that are directly related to a specific
entity, the VM entity does not have the CPU Usage Rate of the Host that
it is on. The Host can change with a vMotion, so it doesn't make sense
to directly relate to the Host CPU usage. However, using these reference
traversal queries, you can still filter based on the properties of the
Host (or Cluster, or anything else that comes up in the VM filters).

  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Reference Traversal Queries are heavy on the database. Just like joined queries in relational databases, these queries will cause Network Insight to traverse through multiple database tables and compare records. Try to avoid using them often, and don't be surprised if they take a few seconds.
  ------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Nested Queries
--------------

As an alternative to reference traversal queries, nested queries are
also possible. The results of a nested query can be used to filter in
the original query. Nested queries will be executed first, meaning
you'll have the results available in order to filter on the main query.
While this is similar to reference traversal queries, it's written in a
different way.

To make this tangible, let's have a look at the examples of the previous
chapter, only in nested query form:

Find all VMs on hosts with a high CPU utilization:

VMs where Host in (Host where CPU Usage Rate \> 95%)

Find all VMs on a specific compute blade:

VMs where Host in (Host where Blade =
\'\[ucs-1.vrni.cmbu.local\]-\[sys/chassis-1/blade-7\]\')

Find all VMs that are located on a cluster that does not have the NSX
Distributed Firewall enabled:

VMs where Cluster in (Cluster where Firewall Feature Enabled = false)

As you can see, it's a bit more text -- but to me, this is more
readable.

Time Control
------------

You can use the time control to change the time point of the results. By
default, searches involving configuration will return the last known
configuration ('now'), and metrics will be returned for the last 24
hours.

For example, bytes of flows will show traffic for flows over a period of
24 hours, and firewall rules will return the firewall rules that
currently exist. Time control can be used to return configuration
properties at a specific point in time, or to modify the time span of
returned metrics.

This can be done from the time indicator that is on the right of the
search query, inside the web interface. It can also be done from inside
the search query itself.

![](./media/image94.png){width="2.448869203849519in"
height="3.4523807961504813in"}
![](./media/image95.png){width="2.9785247156605426in"
height="3.4523807961504813in"}

[]{#_Ref24291822 .anchor}Figure 90 -- Search; time control in the web
interface

As shown in [Figure 90]{.underline} above, it's easy to jump from the
current time to some most used points, such as **Yesterday**, **Last 3
Days**, etc. You can also use the **At** option to jump to a very
specific time, used for getting to know the exact configuration at that
time. Then there's the **Between** option, where you can specific a time
range; mostly used for metrics to show graphs of a specific time period.

You can also specify the time control inside a search query, by using
the following syntax:

*search query* in last X (minutes\|hours\|days\|weeks\|months)

Here's an example: Flow in last 48 hours or something like: changes in
last 3 hours

The above example uses searches that return results (metrics or change
events) in a time range. You can do something similar to search for
configuration of a specific time in point, like this:

Firewall Rules at November 5 14:00

The above example will return all firewall rules that existed on
November 5^th^ at 14:00 (sorry, it does not take pm/am times, have to
provide the 24-hours format. ;-) ).

When you start combining configuration and metric results, while using
time control; it will pick the highest value of time. For some examples,
see below.

VMs where CPU Usage \> 80%

The result of the above query will be all the VMs that have had a CPU
usage higher than 80% in the last 24 hours.

VMs where CPU Count = 4

The result of the above query will show all VMs that currently have a
CPU count of 4.

VMs where CPU Count = 4 and CPU Usage \> 80%

The result of the above query will be all the VMs that have had CPU
usage higher than 80% and where the CPU count 4 in last 24 hours.

Automating Network Insight
==========================

We've now come to a topic that's very close to my heart: automation.
Because deep, deep, deep down I'm really lazy. But mostly because I
don't like having to do repetitive tasks.

Automation helps you be more efficient; it gets things done faster and
does each time exactly the same. This mostly helps in bringing the
control closer to the users of your products and services and freeing up
the IT staff to do better things than just provisioning virtual machines
and installing applications manually. Like architecting the
infrastructure to become more resilient, explore new technologies to
push your infrastructure further. You know, doing more fun stuff.

In the data center world, we're usually talking about deploying
application stacks using virtual machines with all kinds of
configurations including storage, networking & compute options via an
automation and orchestration layer.

Now I hear you wondering, "What does that have to do with a
troubleshooting & monitoring tool?". Well, a lot!

Pushing Data In
---------------

There are a few reasons to push data into Network Insight. They all have
to do with providing more context or pushing in configuration data.
Let's start with the context reason first.

As you've learned in the chapter **Application Security Planning**,
application context can be discovered from metadata straight from the
infrastructures' inventory, or it can be created manually (or via the
API). While application discovery works like a charm, it is also good to
eliminate the (manual) discovery step by pushing the application
construct into Network Insight directly from the infrastructure
automation system that is provisioning the application onto the
infrastructure. That way, you've got instant context for any newly
deployed application.

The other reason to push data into Network Insight is to keep
configuration synchronized. Data sources is a good example of this
configuration. If you have a lot of physical switches, routers or
firewalls deployed in the infrastructure and new ones are added
regularly, you could automate the creation of those devices in Network
Insight when they are added to the network. That way, they will be
instantly monitored and available for troubleshooting exercises, without
having to add them manually.

Pulling Data Out
----------------

At the other end of the spectrum, pulling data out of Network Insight
for other systems is another reason to start automating. It is a
treasure trove of information and other systems you might have put in
place could benefit from it.

One widely used example is to take the network traffic flows for very
specific virtual machines (the "highly confidential" or "at risk" ones)
and forward the details of those flows to a Security Information and
Event Management (SIEM) system to correlate those flows to other events
that application or other systems generate. Because Network Insight is
context rich, you can be very specific with which flows you export. In
one of the real-world examples I'll get to later (Exporting Network
Flows for Security Analytics), it is as simple as setting a simple tag
on a virtual machine for it to be included in the broader security
scrutiny.

Another example is to take virtual machine information and export it
into a Configuration Management Database (CMDB) and make sure the
virtual machine details are always in sync with the actual environment.

If that's not of interest, how about generating a daily report of all
the configuration changes that happened in your environment? Every
changed firewall rule, every created or deleted virtual machine, virtual
machine hardware upgrades, any changes that created a problem inside the
infrastructure, you name it.

I could go on with examples but seeing the range of things you can do
should spark some ideas. Take any bit of information Network Insight has
and combine it with your own systems; endless possibilities.

Automation makes it all possible.

API
---

Now that we've covered why you would want to automate Network Insight,
let's take a look at how. Network Insight has a private and public REST
API hosted on the Platform appliance.

Taking one step back, a REST API stands for Representational State
Transfer Application Programming Interface. This has become an industry
standard in the last few years, simply because it's so dead simple. You
do extremely advanced automation with REST APIs but in the basics, it's
just HTTP calls and you can use any HTTP client (like a browser or cURL)
to call on these APIs. When testing with APIs, I recommend you use the
[Postman](https://www.getpostman.com/) client, which is perfect for API
development.

Inside REST, there's a reference architecture that lets you do HTTP
calls in different ways that have different effects. If that sounds
fuzzy, here's a technical explanation:

HTTP has several different methods, like GET to retrieve information,
POST to deliver information (the content should be put in the body of
the request), PUT to modify information and DELETE to remove
information. These methods translate to the action you want to take in
the API. If you do a GET request, you'll get information back from the
API. If you do a DELETE request, the API knows that you want to delete
an object.

When receiving the response from the API, there are a few aspects to
take into account. The response HTTP status code (200, 400, etc.) will
indicate whether the API call was a success (200), or if the request was
formatted incorrectly (400), or if you don't have an authorized session
(401), or if the API broke something (500). There are other codes, but
these will be the most relevant. If you requested content (GET), the
returning body will contain the requested information.

Officially (as not all APIs adhere to this), REST APIs should use
JavaScript Object Notation (JSON) as the format in which the data is
transferred between client and server. This is also an industry
standard, which has the benefit that about every programming or
scripting language knows how to read JSON and present it back to you in
a usable form. It also helps that it's human readable.

This book isn't about teaching you about these standards and
technologies and for the rest of this chapter, I'm going to assume you
have a basic grasp of REST calls and JSON. I'm also not going through
all API calls and functionalities but will give you enough information
to get started. Complement this chapter by reading the vRealize Network
Insight API Guide.

  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   Currently, Network Insight rate limits the amount of API calls per second to 20. When doing API calls, rate limit your own script to not overload the API. You will be throttled, and the API will start giving out error code **429**.
  ------ -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### API Explorer

As with many of the VMware products these days, Network Insight has an
API Explorer built in to the interface. This API Explorer holds the
reference documentation for each API call that's available. If you're
looking for parameters to include into the API call, this is the place.
It also has a very handy feature where you can try out the API call
directly from the interface to help in the process of formatting the
right structure for a successful API call.

It can be found under the gear icon on the top right; API Documentation.
There will be 2 tabs: API Reference and Documentation. The reference tab
lists all API calls and their format and parameters (you'll use this one
the most) and the documentation tab contains links to the API Guide and
OpenAPI specification.

  ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------
  ![](./media/image96.png){width="1.2012478127734034in" height="1.964601924759405in"}   ![](./media/image97.png){width="4.743362860892389in" height="2.584659886264217in"}
  ------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------

[]{#_Toc35170249 .anchor}Figure 91 -- Built in API Explorer

### Swagger / OpenAPI Specification

An [OpenAPI](https://swagger.io/specification/) (previously known as
Swagger) specification is a description format for an API which can
describe the contents of an API. Each endpoint, input and output
parameters, authentication methods and other details around the API.
This specification is what the developers use to describe all API
endpoints and it is used to generate the documentation you see in the
API Explorer.

It can also be used to automatically generate code for client libraries,
or otherwise known as software development kits (SDK). While Network
Insight does not have those SDKs yet, I'm holding out hope for future
availability.

The OpenAPI specification is a very good reference source when you're
building automation that consumes the custom objects that the API
provides. For instance, when retrieving information about entities (VMs,
IP Sets, Hosts, all objects from your infrastructure), there will be an
**entity\_type** field inside the returned object data. This
**entity\_type** describes the schema of data that will be included in
the result. By looking up the entity type inside the OpenAPI
specification, you know what schema you can expect to be able to use.

For example, here's a snippet of the "VirtualMachine" entity type:

These definitions can be nested, which the field **allOf** is
referencing too. The **VirtualMachine** entity inherits everything from
**BaseVirtualMachine**. Then we have the fields that are specific to a
VM, like **cpu\_count** and **memory**, but also references to other
entities.

If you look at the **cluster** field, it has **Reference** as value.
This means that the result will contain references to other entity IDs
which you can request separately. In this case, the entity ID that will
be returned in the cluster field will be the vSphere DRS Cluster and you
can retrieve the details about that DRS cluster by referencing that ID.

### Authentication

Before you can do any other API calls, you need to authorize your
session and get an authentication token. This token will be used
throughout any subsequent API calls that you want to execute.

To get an authentication token, use the **/auth/token** API endpoint.
This is the only place where you'll need to specify a username and
password; all the other endpoints rely on the authentication token for
proper authorization.

As we're sending data (the credentials) across, the /auth/token endpoint
takes a POST request. Formatting the POST body is fairly straight
forward using JSON:

This example uses a credentials that is tied to a LDAP directory with
the domain name **example.com**. If you were to use credentials that are
local to the Network Insight platform, you would use something like
this:

If the call is successful (right credentials, formatted correctly and
the API or backend isn't on fire), you will receive a HTTP code 200 back
and the response body will look something like this:

An authorization token is valid for 5 hours after you've requested it.
Usually API calls are done on demand, but if you're scheduling calls
continuously; keep in mind to refresh the token at least every 5 hours.
Otherwise it will expire, and your subsequent API calls will return a
401 (unauthorized). The **expiry** field is the exact time that the
token will expire. It is really exact, as it is formatted as an epoch
timestamp in milliseconds (epoch usually stands for the seconds from
January 1^st^, 1970 at 00:00:00 GMT). You can use this timestamp to see
if your token is due for a refresher.

Then there's the **token** field. This base64 encoded string is to be
used in any following API calls in the HTTP headers, like so:

Save the authentication token to a variable that you can reuse inside
the script or workflow that you are building.

**Network Insight as a Service Authentication**

As you may remember from the chapter []{.underline}

[Hosted Architecture (SaaS]{.underline}), there is a difference in
authentication between the on-premises Network Insight and the one
that's delivered as SaaS. There is a single-sign-on platform in place
for all VMware Cloud Services (CSP) products, meaning there is no user
management within Network Insight, and you'll need to go through CSP to
get an authentication token to use in the Network Insight API calls.

CSP works with so-called refresh tokens as a way of authentication. When
using the API, you need to exchange a refresh token for an
authentication token and use that when talking to the Network Insight
API (or any other Cloud Service).

Refresh tokens are linked to an CSP account. To create one, log into
<https://cloud.vmware.com> and go to your Console. Then open up your
personalized menu (top right) and click **My Account**. Select the **API
Tokens** tab and click **Generate a new API token** to get a refresh
token. It'll look something like this:
**ax22ea9i-139b-344x-lif7-ex6856ce57fa**

These refresh tokens are valid for 6 months, which you need to keep in
mind when building automation based on these tokens.

After getting a refresh token, there's a single CSP API call you need to
call to exchange a refresh token for an authentication token:

<https://console.cloud.vmware.com/csp/gateway/am/api/swagger-ui.html#/Authentication/getAccessTokenByApiRefreshTokenUsingPOST>

Executing this API call successfully, will give you a result like this:

The **access\_token** is the important field here, which you need to
save and consider as the authentication token for the Network Insight
API calls. There is, however, a slight difference in how you send this
token across to the API. Instead of sending the **Authorization** header
in your API call, you'll need to insert a header called
**csp-auth-token** with the value of the authentication token that
you've retrieved from the CSP API. Like so:

As a final note, it is also worth noting that the URL for the Network
Insight as-a-Service API is the same for all environments:
<https://api.mgmt.cloud.vmware.com/ni/$api-endpoint>

Once you're authenticated, return to the API Explorer and find the API
call that you need to retrieve or push the information you want.

### A Few Examples

When using the API, you most likely have a fixed goal and know what you
need to do in order to get there. The API Explorer will be your best
friend for getting examples. Below are a few examples which are to
illustrate how to work with the API in a broad sense. There are some
gotchas you need to take into account.

#### Retrieving a list of VMs

Using Network Insight to get a list of VMs might be useful if you have a
large environment with multiple vCenters. Network Insight aggregates all
data in one place, so you'd only have to do a single API call to get
every VM.

First, we need to find the right API call to get this list. Turn to the
API Explorer and you will find a call to the endpoint **/entities/vms**.
This has the description "List vms", so it's probably the one we're
looking for. If you then look at the available parameters, this is what
shows:

![](./media/image98.png){width="6.263888888888889in"
height="1.1784722222222221in"}

[]{#_Toc35170250 .anchor}Figure 92 -- Parameters for API endpoint
/entities/vms

For all the Entity endpoints, you'll see that the parameters are pretty
much the same. There is a **size** parameter for the amount of results
returned on a page, a **cursor** parameter to indicate from which page
you want to start getting results and a **start\_time** and
**end\_time**, which can be used to go back in time. Remember that there
is a timeline to show historical data? Using **start\_time** and
**end\_time** can get the list of VMs that existed a week ago, including
the ones that have been deleted since.

The **cursor** is important to get full results. By default, the results
for returned entities are paged in pages of the indicated **size**
(default 10 results) and with every returned page, there'll also be a
next **cursor** value in there, which you can use to request the next
page. Have a look at this example:

![](./media/image99.png){width="6.263888888888889in"
height="3.3222222222222224in"}

[]{#_Toc35170251 .anchor}Figure 93 -- Using Postman to execute API
endpoint /entities/vms

In this example, I'm using Postman to get a list of VMs, limited by 2
results. The first thing you'll notice is that there are actually any VM
attributes listed in the results, just **entity\_id**s. This works the
same with all entities; it returns a list of references to entities. You
can take the **entity\_id** and get detailed information by using the
specific entity type API endpoint. In the case of the first result this
will be **/entities/vms/17603:1:1010454414**, but we'll get to that.

Inside the result, the "results" array contains the resulting entities
(thanks, captain obvious!). I'd like to get your attention to the other
results. As said, there's a **cursor** value that indicates the next
page, a **total\_count** with the amount of total results available
(regardless the page limit) and the timeline values. The timeline is by
default set to the current time, if you do not give a timeline yourself.

We've got 2 results now and there are 109 in total, which makes this
next API call:

The result will be the next 2 VMs in the list and another cursor value.
Continue on like this until you've got all 109 VMs returned. Do this
inside a loop and dynamically look for the **total\_count** and the
current count of results in order to determine to do another API call or
be satisfied with the results. You could also look out for the
**cursor** value. If there's no more pages, this cursor value will be
empty.

#### Creating an Application

Now you know how to retrieve information, let's take a look at creating
something via the API. Of all API calls that push data towards Network
Insight, creating applications is the most used one as it can be used on
an ongoing basis. Applications are the most dynamic factor in most
environments, usually in a way that there are new applications being
spun up all the time.

If you want to get the right context for troubleshooting and monitoring,
you need to populate those new applications inside Network Insight.
Couple this process closely to your application deployment automation
and use the Network Insight API to provision applications while the
application is being deployed. Automagically.

There are two steps required to create an application container:

1)  Create the application itself

2)  Create a tier within the newly created application with a filter
    that points to workloads (using tags, VM names, folders, any logical
    object in the virtualization layer).

In the API Explorer, there's an entire section devoted to application
management. You'll quickly find the endpoints **/groups/applications**
(POST) and **/groups/applications/{id}/tiers** (POST), which are needed
to create an application.

Creating an application via /groups/application (POST) doesn't require
much; just an application name. The result will contain the
**entity\_id** that it has given the new application. Store that for the
next call. Here's an example using the name **My-New-Application**. The
top text area is the body that is being sent to the API and the bottom
text area is the result that the API returns:

![](./media/image100.png){width="6.263888888888889in"
height="3.3243055555555556in"}

[]{#_Toc35170252 .anchor}Figure 94 -- Using Postman to create an
application via the API

You now have an empty application without any tiers. Let's add some!

Here's where the previously saved **entity\_id** comes in handy, as the
API endpoint looks like this:
**/groups/applications/17603:561:840848559/tiers**

The body of this endpoint is a bit more elaborate though, as it needs
not only a name but also a filter to determine which workloads will be
added to this tier. The filter is basically a search query, so you can
filter on any logical object (tags, VM names, folders, etc.) to get the
right VMs in the tier. In this example, I'll use a simple search based
on VM name. Here's the formatted API call:

![](./media/image101.png){width="6.263888888888889in"
height="3.3243055555555556in"}

[]{#_Toc35170253 .anchor}Figure 95 -- Using Postman to create an
application tier via the API

As you can see, there is a **name** field (which is the name the new
tier is given) in the body and an array called
**group\_membership\_criteria**. This is where you define the search
query that looks for workloads to put into the tier.

I've used an **entity\_type** called **BaseVirtualMachine** and a filter
that looks for the names **VM01** and **VM02**. The filter can be
formatted using the search query logic (throwback to chapter
[]{.underline}

[\
Using the Search]{.underline} Engine) and the you can find the
**entity\_type** options in the OpenAPI specification under the
\"definitions\" structure (examples are: Cluster, SecurityTag,
EC2SecurityGroup, etc., etc.).

The result of creating the application tier is the tier definition
echoed back plus the newly assigned **entity\_id** along with a
reference to the parent application.

You now have a new application with a single tier with 2 VMs in it. If
you need multiple tiers, rinse and repeat the second call.

Using PowerShell (PowervRNI)
----------------------------

Moving on from using raw APIs, there are tools available to get you
faster up and running. When you're integrating with an existing
automation or orchestration platform, you might need to use the API
directly, but if you just want to execute a simple script to speed up a
task; abstraction tools are the way to go. With these, you can simply
fire a command and it handles the API endpoint calls for you. Just focus
on the bare minimum input and get on with the results.

In this chapter I'm going to walk you through using PowerShell to talk
to the Network Insight API.

### Why PowerShell?

This is a question I get a lot. There are a lot of scripting frameworks
available and there are usually two camps: Linux based and Windows based
tools. This is mostly because these scripting frameworks are built into
the operating system itself.

People from the Linux world usually default to scripting languages like
python, ruby, or even perl. Because these are (usually) installed by
default on a Linux distribution.

People from the Windows world usually default to PowerShell. Again,
because it's available by default on the newer versions of Windows.

But there's more. One of the reasons PowerShell is a popular scripting
language to use, is because it uses a natural language design of its
features. All functions that you can use, are named in a very natural
way. If you want to get some information, the function will start with
**Get-**. If you want to set an option or parameter, the function will
start with **Set-**. If you want to invoke a command of some sort, the
function will start with **Invoke-**.

PowerShell is also easily extendable with modules. Modules are basically
just text files with custom functions that you can download and load or
create yourself and publish. There is a central repository located on
[powershellgallery.com](https://www.powershellgallery.com/), from which
you can download modules manually and install them or simply install
them directly from a PowerShell window with **Install-Module
moduleName**. There are currently over 4.200 modules on the
PowerShellGallery, so plenty to choose from.

It also helps that PowerShell was made a multi-platform tool for
Windows, Linux and MacOS with version 6.0 in the beginning of 2018. I've
been running it on MacOS ever since and haven't looked back at my
Windows virtual machine. ;-)

If you would like to learn more around PowerShell, I highly recommend
the [PowerShell: Getting
Started](https://app.pluralsight.com/library/courses/powershell-getting-started/table-of-contents)
course by Michael Bender on Pluralsight.

### PowervRNI

Most of the VMware related PowerShell modules, official and community
developed, start with the prefix **Power** to relate it to PowerShell.
For example, we have [PowerNSX](https://github.com/vmware/powernsx),
[PowerCLI](https://code.vmware.com/tool/vmware-powercli),
[PowervRA](https://github.com/jakkulabs/PowervRA), and a couple others.

When Network Insight 3.6 with the first version of the public API came
out in November 2017, the PowerShell module to make use of this API was
already in the making, as it was highly requested amongst the companies
I was working with. Adhering to the unofficial naming convention; the
module was named [PowervRNI](https://github.com/PowervRNI/powervrni).

It currently has 44 functions and around 95% of API coverage.

My goal with PowervRNI was pretty straight forward: make it easy to get
started with the Network Insight public API and make it easy to
integrate with other systems. I'm proud to say that it has been used to
solve a breath of use cases involving data sharing issues between
multiple systems. From security use cases where extra data around
network traffic flows and infrastructure info is sent to a SIEM system
to better collation, to importing a large amount of data sources
(usually physical network devices) into Network Insight during the
initial set up, to integrations with CMDB systems to synchronize the
CMDB inventory with the real-life situation. I will go into a few
example use cases in the upcoming chapters, but up-to-date examples can
be found [on my blog](http://lostdomain.org/tag/powervrni/).

#### Getting Started with PowervRNI

There are two ways to get PowervRNI on your system: a manual and
automated way.

##### Installing Manually

Installing it manually can be a good option on systems where you don't
have permissions to use the cmdlet **Install-Module**. Although the
newer PowerShell versions have to ability to install modules just for
yourself (parameter "*-Scope CurrentUser*"), it can still be locked
down.

A manually install simply means downloading the module source files and
placing them locally, where you can load them.

Get the module source files from here: <https://powervrni.github.io/>

And then open up a PowerShell window, change directory to where you have
put the module source files and load PowervRNI like this:

##### Installing Automagically

Using the built-in cmdlet **Install-Module** will download the module
source files for you and place them somewhere where PowerShell knows to
load them. Open up a PowerShell window and execute these commands:

The first command is to make the PowerShellGallery a trusted source.
You'll only have to do this once and it prevents showing a notice that
asks you for permission to download from the PowerShellGallery because
it's an untrusted repository. You can still install the module without
adding it to the trusted repositories, but it's just cleaner this way.

After the installation has completed, load PowervRNI like this:

Notice that there's a slight difference in loading the PowervRNI module.
When installing a module via **Install-Module**, you can load the
modules from anywhere and you don't have to give the relative path to
the module source files. That's why I recommend doing it via the
automagical way, if you have the option.

##### Getting Familiar

Now that PowervRNI is on your system and loaded, take a little time to
explore the available cmdlets to see what's available and which ones you
would like to try. Get a complete list of available cmdlets by executing
this:

Every cmdlet in PowervRNI is well-documented and has examples of its
usage and you can get that documentation via PowerShell:

##### Connecting to Network Insight

In the previous chapters, you've learned about the way Network Insight
handles authentication (via authorization tokens). PowervRNI uses the
authorization tokens for all API calls, which means you need to connect
and authorize first.

There are two cmdlets to connect a Network Insight instance. There's
**Connect-vRNIServer** to connect to vRealize Network Insight (the
on-prem variant) and there's **Connect-NIServer** to connect to the
Network Insight as a Service variant.

**Connect-NIServer** is extremely simple to use and only required the
Refresh Token that you have created in chapter
[Authentication]{.underline}.

This exchanged the Refresh Token for an authentication token and that
will be used for subsequent API calls and you are now free to use the
rest of the cmdlets inside PowervRNI.

**Connect-vRNIServer** takes a few more parameters, as the on-premises
instance would have more details like the IP or hostname of the Platform
VM and the credentials to connect.

There are two ways to handle the credentials. You can input the username
and password when you connect (either pass them as parameters or be
prompted on them) or you can create a
[PSCredential](https://blog.kloud.com.au/2016/04/21/using-saved-credentials-securely-in-powershell-scripts/)
file once and refer to that file when connecting. This would be the
preferred way to connect if you're running a scheduled task. Remember,
plain text passwords make babies cry.

If the connection was a success, you will see the authentication token
being returned which is stored and used for subsequent API calls.

Automation Use Cases
--------------------

Now that we've covered the **how** of automation with Network Insight in
the previous chapters, let's focus on the **why**.

In the upcoming chapters, I'll give you 4 examples of use cases which
might give some inspiration. These examples are not all there is, of
course, the amount of value you can get out of automation are as vast as
the data that's being collected by Network Insight. The following
examples are real-life use cases that I've helped organizations to
implement.

### Integrating with Infrastructure Automation & Orchestration systems

Beginning with the first of 2 application focused use cases, let's have
a look at an integration between an infrastructure automation and/or
orchestration system. In the context of this integration, an
infrastructure automation system is used to deploy applications and all
its dependencies. From the virtual machines with their compute, storage
and network properties, to installing required software packages and
configuring them. Full application deployment.

Why is that important? Well, remember that having the application
context in Network Insight enriches your experience immensely. How great
would it be to have the application context be created at the same time
as the actual application is being deployed? That's where an integration
to your automation system comes into play.

#### Example

vRealize Automation (vRA) is an infrastructure lifecycle management and
automation platform, which can be compared to an octopus; it extends its
reach to other systems to execute actions (like deploying a virtual
machine) and can grow extra (custom) arms to systems that it does not
out of the box talk to.

As an example, I'll be using a 3-tiered application blueprint that
contains a web server, application server, and database server tier. Of
the web and application tiers, there can be multiple VMs deployed but
there's just one database server. They are linked to vSphere templates
which will be cloned when a deployment is requested.

![http://lostdomain.org/wp-content/uploads/2018/11/vrni-vra-blueprint-tiers-1024x550.png](./media/image102.png){width="6.263888888888889in"
height="3.3618055555555557in"}

[]{#_Toc35170254 .anchor}Figure 96 -- Example vRealize Automation
3-tiered Application Blueprint

This blueprint design relates directly to an application construct
within Network Insight, using the blueprint name as application name and
the different types of machine deployments (Web, App, DB) as the names
for the tiers. When this blueprint is deployed by someone, vRA will
deploy the virtual machines, networks, storage and the software packages
on the newly created virtual machines. After that work is done, we can
insert a custom vRealize Orchestrator (vRO, the octopus' engine)
workflow that will take this newly created application and creates the
application context inside Network Insight.

Inside vRA, there's an Event Broker which you can use to kick off
workflows during specific stages of a deployment. You can create a
subscription on the event that signals that a deployment is done, and
all virtual machines have been deployed. This subscription also
indicates which vRO workflow should be started.

  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  INFO   The vRO workflow and a step by step guidance of how to install it, can be [found on my blog](http://lostdomain.org/2018/11/08/integrating-vrealize-automation-with-network-insight/). The actual code is not the point of this chapter; I'm giving you an example of how it can work with vRA, but this can be applied with any and all infrastructure automation & orchestration systems.
  ------ --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Here's a graphical overview of how the process works, so you can
translate it to your own system.

![](./media/image103.tiff){width="6.263888888888889in"
height="2.4131944444444446in"}

[]{#_Toc35170255 .anchor}Figure 97 -- Push Applications from Automation
workflow

### Importing Applications from Configuration Management Databases

Application Discovery is important to get the right application context
in Network Insight. While you can natively integrate the ServiceNow
CMDB, there are ways to integrate other CMDBs using the API. If you are
not using ServiceNow for your CMDB needs, don't fret. I think it's
pretty safe to say that all relevant CMDB systems have a way to export
data from its systems and most will even have an API to talk to.

If it has an API; good! You can set up a periodical synchronization
between the CMDB and Network Insight. This workflow should retrieve a
list of application names, optional tiers and all the virtual machines
and/or physical IP addresses attached to that application. You then use
that list and ask the Network Insight API if this application already
exists and compare the virtual machines and physical IP addresses to see
if anything has changed (and then update it). If the application doesn't
exist; create it with the info from the CMDB.

Here's a visual representation of this workflow:

![](./media/image104.tiff){width="6.263888888888889in"
height="3.1930555555555555in"}

[]{#_Toc35170256 .anchor}Figure 98 -- Import Applications from CMDB
workflow

#### Example

Importing data from a CMDB can be easy when it has an API. iTop is an
open source CMDB system which can track infrastructure inventory and
changes to it. I use it to track my own inventory (yes, I need a system
for that. Don't judge me. ;-)).

In the examples directory of PowervRNI, there is an example script that
pulls out application items from iTop, traverses the relationship tree
and discovers VMs that are attached to that application. Then it adds
that application tree as an application construct into Network Insight.

As the script is just a bit too big to paste here, I'll leave you with a
link to it:

### Exporting Network Flows for Security Analytics

Getting out of the application realm, let's focus on a security use
case. As Network Insight gathers all network flows going through the
network, it has visibility on what's actually happening with your
applications. Is it behaving accordingly, sending and receiving traffic
that it is supposed to? For instance, a web server should only send out
connections that it needs to support its website (usually just
HTTP\[S\]). If it starts sending out SSH traffic, it's probably
compromised and is trying to compromise other systems.

While you can create user-defined events based on anomalies like that
and have an alert sent out when that starts happening, it's usually more
prevalent to send the network flow information to a SIEM system. That
system would also be able to take the application generated logs and
correlate them together for an end to end view.

Sending all network flows all the time might not be a preferable
situation, as the amount of data can overwhelm the SIEM and it might not
be interesting to record every network flow. Instead, what I've seen is
more a reactive setup based on other events. The SIEM or other
monitoring system catches something that seems off and sets a tag on a
virtual machine, which in turn triggers the network flow import to SIEM.

Of course, you can customize this to your own requirements.

#### Example

Using PowervRNI, exporting flows and sending them to another system is
fairly simple as there's a cmdlet needed to retrieve the network flows:
**Get-vRNIFlow**. Here's an example:

Flow records have a bunch of correlated information attached, as you can
see in the example above. I'd like to highlight a few fields on which
you could filter, which would be beneficial when looking for specific
flows:

  **Field**              **Description**
  ---------------------- ----------------------------------------------------------------------------------------------------------------------
  **traffic\_type**      Which way is the traffic going? **INTERNET\_TRAFFIC** or **EAST\_WEST\_TRAFFIC** are possibilities.
  **source\_\***         Source of traffic; not only IP address, but also context like **vm**, **vnic**, **datacenter**, etc.
  **destination\_\***    Same as above, only for the destination (including context)
  **firewall\_action**   When integrated with VMware NSX Data Center, this can show flows which are blocked by the Distributed Firewall (DFW)

### Tenant Bandwidth Chargeback / Showback

Using the network flow data in Network Insight, you can also make money.
I used to work for a provider which had a range of services, like
leasing out physical data center room and network connectivity to or
simple virtual machines. All services had something in common; we
charged for bandwidth. This is fairly common in provider land and
everyone has their way of metering, we had a custom application (that I
created) that listened on a mirror (span) port and looked at the actual
traffic of our tenants. It saved the byte size of the packets linked to
a source IP and saved that number to a database. At the end of every
month, we generated reports from this database in order to invoice the
customers for the amount of bandwidth they used, that month.

While we had our issues, this was a pretty clean approach. Other service
providers didn't have the option of creating their own program to do
this and relied on multiple data sources to tell them the total
bandwidth usage. I've heard many stories about losing revenue because
they couldn't get the right data to invoice their customers.

This bandwidth data is available within Network Insight and there are
ways to get a clean list of bandwidth usage per IP (source or
destination) in several formats. Using the API is one of those formats.
In the below example, I'll go through an extremely simple example on how
to use the API and retrieve bandwidth usage per source IP address.

####  Example

There is an API endpoint called aggregation
([/api/ni/search/aggregation]{.underline}), which can be used to fetch
sums or averages of a specified metric. In this case, we'll be using the
aggregation endpoint to retrieve the sum of flows coming and going to a
specific IP address. To understand what's going on in that script,
here's the API call:

Inside this call, the aggregations field is where we specify the
operation the aggregation needs to perform. In this case, it's a **SUM**
operation on the field **flow.totalBytes.delta.summantion.bytes**. This
translates to "SUM(Bytes) of Flow" in the regular UI search bar, as the
API search uses the internal naming convention of objects.

Also take note of the filter, where the search condition is given. This
can be a single condition as in the example above, but also multiple
conditions. For example, if you don't care about splitting out download
and upload and want a single number for all bandwidth combined, use:

You can modify the filter to use VMs or any other of the objects inside
Network Insight. Get creative!

Lastly, the **start\_time** and **end\_time** fields indicate the time
window that the result should be based on.

As a result of this API call, you will get a recap of the aggregation
request and the value of the query:

The field **aggregations.value** is the number of bytes that matches the
filter.

You can find the PowervRNI example script here:
<https://github.com/PowervRNI/powervrni/blob/master/examples/get-bandwidth-usage-per-ip.ps1>

Automation Conclusion
---------------------

I hope the examples in the previous pages have been helpful to get your
imagination going on what is possible when you start automating Network
Insight. These examples have just scraped the surface of what's
possible, and there's a whole integration ecosystem possible that takes
advantage of the data.

If you have any other use-cases that you are building -- please do reach
out to me via any of my communication channels; I'd like to learn from
you!

Shout Outs
==========

This book wouldn't be possible without the amazing team behind Network
Insight. From providing me with insights what's going on behind the
scenes to putting up with my incessive stream of questions, these people
stood by me and have credit in making this book happen. Let me introduce
them:

Shiv Agarwal

Abhijit Sharma

Rohit Reja

Dave Overbeek

Manish Virat

Karthic Kumar

Naveen Chaudhary

Taruna Gandhi

Thank you for your support and putting up with my continuous stream of
questions.

Keyword Index
=============

**API Endpoint** URL of an API that calls a specific function (i.e.
/api/ni/groups/applications)

**Cloud** A collection of computers that are not your own. Typically
paid for per usage.

**CMDB** Configuration Management DataBase

**CSP** Cloud Services Portal -- VMwares' management portal for their
cloud services

**DBA** DataBase Administrator

**DFW** VMware NSX Data Center -- Distributed Firewall

**DMZ** De-Militarized Zone

**East-West** Network traffic that stays within the boundary of the data
center.

**EC2** Elastic Compute Cloud -- virtual machines in AWS.

**ENI** Elastic Network Interface -- virtual network interface,
typically attached to an

EC2 instance

**REST API** A REpresentational State Transfer API is an application
program interface

> (API) that uses HTTP requests to GET, PUT, POST and DELETE data.

**JSON** JavaScript Object Notation

**PII** Personally Identifiable Information

**S3** Simple Storage Service -- AWS object storage services. Delivered
in buckets.

**SDDC** Software Defined Data Center

**SDK** Software Development Kit

**SDN** Software Defined Networking

**SIEM** Security Information and Event Management

**NI** Network Insight

**North-South** Network traffic that goes beyond the boundary of the
data center. Usually

> internet traffic.

**VPC** Virtual Private Cloud -- AWS container for compute resources

**vRA** vRealize Automation

**vRNI** vRealize Network Insight

**vRO** vRealize Orchestrator

**PKS** Pivotal Container Service

**Workload** Something that runs an application: VM, container, cloud
instance or

> physical server.

Figures
=======

[Figure 1 - Global numbers of Network Traffic movement
12](#_Toc35170156)

[Figure 2 -- Recommended Firewall Rules -- Grouped by Application
13](#_Toc35170157)

[Figure 3 - Topology chart: gluing physical and virtual together
14](#_Toc35170158)

[Figure 4 - Health Check and Health Alerts 15](#_Toc35170159)

[Figure 5 -- CNCF 2018 Survey results 17](#_Toc35170160)

[Figure 6 -- VMware NSX Portfolio 20](#_Toc35170161)

[Figure 7 -- VMware Virtual Cloud Network 21](#_Toc35170162)

[Figure 8 -- Micro-Segmention; logical security boundaries between
applications. 23](#_Toc35170163)

[Figure 9 -- Enabling NetFlow on a vCenter data source
26](#_Toc35170164)

[Figure 10 -- Adding a Physical Flow Collector data source
26](#_Toc35170165)

[Figure 11 -- High level overview of network traffic behaviour
27](#OLE_LINK3)

[*Figure 12 -- Micro-Segmentation Planner; the donut of joy*
28](#_Toc35170167)

[Figure 13 -- Recommended Firewall Rules grouped by Application
30](#_Toc35170168)

[Figure 13 -- Recommended Firewall Rules YAML export 32](#_Toc35170169)

[Figure 14 -- Recommended Firewall Rules grouped by Tier
35](#_Toc35170170)

[Figure 15 -- Example application construct 38](#_Toc35170171)

[Figure 16 -- vCenter Custom Attribute definition 40](#_Toc35170172)

[Figure 17 -- Custom Attributes on a VM 40](#_Toc35170173)

[Figure 18 -- Application Discovery using Tags 41](#_Toc35170174)

[Figure 19 -- Application Discovery Results 43](#_Ref13144669)

[Figure 20 -- Application Discovery Results - Form 44](#_Toc35170176)

[Figure 21 -- Application Discovery with a Naming Convention
47](#_Toc35170177)

[Figure 22 -- Application Discovery -- Pattern Builder
47](#_Toc35170178)

[Figure 23 -- Application Discovery -- ServiceNow Application Map
49](#_Toc35170179)

[Figure 24 -- Application Discovery -- ServiceNow Result
50](#_Toc35170180)

[Figure 25 -- Application Migration Planning -- Dependency mapping
52](#_Ref29044160)

[Figure 26 -- Application Migration Planning -- Application Details
53](#_Ref29044197)

[Figure 27 -- Application Migration Planning -- Traffic per Country
54](#_Toc35170183)

[Figure 28 -- Application Migration Planning -- Egress traffic per
Country 55](#_Ref29045562)

[Figure 29 -- Application Migration Planning -- Egress traffic total
55](#_Ref29045561)

[Figure 30 -- Application Migration Planning -- All application traffic
56](#_Toc35170186)

[Figure 31 -- Application Migration Planning -- Migration Wave
Dependency Mapping 59](#_Toc35170187)

[Figure 32 -- Application Migration Planning -- CPU & Memory
requirements 60](#_Toc35170188)

[Figure 33 -- Application Migration Planning -- Internet Traffic of
Migrate Wave 1 61](#_Toc35170189)

[Figure 34 -- Application Migration Planning -- Peak internet Traffic of
Migrate Wave 1 61](#_Toc35170190)

[Figure 35 -- Application Migration Planning -- Flow Types
62](#_Toc35170191)

[Figure 36 -- Application Migration Planning -- Internet Packets p/s of
Migrate Wave 1 62](#_Toc35170192)

[Figure 34 -- Application Migration Planning -- Peak internet packets
p/s of Migrate Wave 1 63](#_Toc35170193)

[Figure 34 -- Application Migration Planning -- Validate Application
with the Time Machine 63](#_Toc35170194)

[Figure 37 -- AWS Master account link diagram 68](#_Toc35170195)

[Figure 38 -- AWS: Setting up VPC Flow Logs 69](#_Toc35170196)

[Figure 39 -- Adding AWS Account 70](#_Ref24444888)

[Figure 40 -- AWS Search options 71](#_Toc35170198)

[Figure 41 -- AWS CloudWatch listing network flow logs
72](#_Toc35170199)

[Figure 42 -- AWS Network topology between two VMs in different VPCs
73](#_Toc35170200)

[Figure 43 -- AWS Network topology between on-premises and an AWS VPC
73](#_Ref24463962)

[Figure 44 -- Adding an Azure data source 77](#_Toc35170202)

[Figure 45 -- Azure Search options 78](#_Toc35170203)

[Figure 46 -- Azure flow logs structure 79](#_Toc35170204)

[Figure 47 -- VMware Cloud on AWS -- spanning networking & security
across clouds 81](#_Toc35170205)

[Figure 48 -- VMware Cloud on AWS -- Adding the vCenter
82](#_Toc35170206)

[Figure 49 -- VMware Cloud on AWS -- Adding the NSX Manager
83](#_Toc35170207)

[Figure 50 -- VMware Cloud on AWS -- Hybrid Path 85](#_Toc35170208)

[Figure 51 - Platform Architecture Diagram 86](#_Toc35170209)

[Figure 52 - Platform VM Internal Architecture 87](#_Toc35170210)

[Figure 53 - Private API in action 88](#_Toc35170211)

[Figure 54 - Searching your data center 88](#_Toc35170212)

[Figure 55 - Platform & Collector relationships 90](#_Toc35170213)

[Figure 56 - Collector VM internal architecture 91](#_Toc35170214)

[Figure 57 - Collector NetFlow processing 92](#_Toc35170215)

[Figure 58 -- Architecture for Network Insight as a Service
101](#_Toc35170216)

[Figure 59 -- Command line list of commands 103](#_Toc35170217)

[Figure 60 -- Restarting services via CLI 104](#_Toc35170218)

[Figure 61 -- CLI Output for show-connectivity-status
104](#_Toc35170219)

[Figure 62 -- Listing available log components and following the
saasservice 105](#_Toc35170220)

[Figure 63 -- Searching in logs 106](#_Toc35170221)

[Figure 64 -- Configuring the vRealize Log Insight agent
107](#_Toc35170222)

[Figure 65 -- Enabling web proxy 108](#_Toc35170223)

[Figure 66 -- Changing the IP address of a clustered node
109](#_Toc35170224)

[Figure 67 -- Moving a Collector between Platforms 109](#_Toc35170225)

[Figure 68 -- Outlier configuration options 113](#_Toc35170226)

[Figure 69 -- Outlier detection result 115](#_Toc35170227)

[Figure 70 -- Outlier detection event 116](#_Toc35170228)

[Figure 71 -- Creating a threshold 118](#_Toc35170229)

[Figure 72 -- Search query & results example 124](#_Toc35170230)

[Figure 73 -- Search query structure 125](#_Toc35170231)

[Figure 74 -- Search help: find all supported properties
126](#_Ref22480916)

[Figure 75 -- Search for a meta entity type and get all included entity
types 126](#_Toc35170233)

[Figure 76 -- Search Metric Properties: example on switch port
127](#_Ref22484064)

[Figure 77 -- Search filters; condition and comparison operators
129](#_Toc35170235)

[Figure 78 -- Searching with property projection 130](#_Toc35170236)

[Figure 79 -- Searching with property projection, including metrics
131](#_Toc35170237)

[Figure 80 -- Searching with a count operator 132](#_Toc35170238)

[Figure 81 -- Searching with a list operator 132](#_Toc35170239)

[Figure 82 -- Searching with a max operator 133](#_Toc35170240)

[Figure 83 -- Searching with a sum operator 133](#_Toc35170241)

[Figure 84 -- Searching with an avg operator 134](#OLE_LINK9)

[Figure 85 -- Search; using the series() projection to combine metrics
135](#OLE_LINK15)

[Figure 86 -- Search; using multiple series() projections to combine
metrics 135](#OLE_LINK11)

[Figure 87 -- Search; using the group by operator 136](#OLE_LINK17)

[Figure 88 -- Search; using the group by operator and aggregate
functions for L2 traffic 136](#OLE_LINK21)

[Figure 89 -- Search; using the group by operator and aggregate
functions for AWS rules 137](#OLE_LINK35)

[Figure 90 -- Search; time control in the web interface
139](#_Ref24291822)

[Figure 91 -- Built in API Explorer 143](#_Toc35170249)

[Figure 92 -- Parameters for API endpoint /entities/vms
147](#_Toc35170250)

[Figure 93 -- Using Postman to execute API endpoint /entities/vms
148](#_Toc35170251)

[Figure 94 -- Using Postman to create an application via the API
150](#_Toc35170252)

[Figure 95 -- Using Postman to create an application tier via the API
151](#_Toc35170253)

[Figure 96 -- Example vRealize Automation 3-tiered Application Blueprint
158](#_Toc35170254)

[Figure 97 -- Push Applications from Automation workflow
159](#_Toc35170255)

[Figure 98 -- Import Applications from CMDB workflow 160](#_Toc35170256)

Tables
======

[Table 1 -- PCI Dashboard; PCI sections explained 37](#_Toc35170257)

[Table 2 -- CLI Commands reference 110](#_Toc35170258)

[Table 3 -- Threshold metric options 119](#_Toc35170259)

[Table 4 -- Search examples, mapping out entity types
126](#_Toc35170260)

[Table 5 -- Search filter condition examples 130](#_Toc35170261)

[^1]: <https://www.cncf.io/blog/2018/08/29/cncf-survey-use-of-cloud-native-technologies-in-production-has-grown-over-200-percent/>

[^2]: <https://www.vmware.com/content/dam/digitalmarketing/vmware/en/pdf/support/product-lifecycle-matrix.pdf>

[^3]: <https://en.wikipedia.org/wiki/Regular_expression>

[^4]: In 2018, according to Gartner:
    <https://www.gartner.com/en/newsroom/press-releases/2019-07-29-gartner-says-worldwide-iaas-public-cloud-services-market-grew-31point3-percent-in-2018>

[^5]: In 2018, according to Gartner:
    <https://www.gartner.com/en/newsroom/press-releases/2019-07-29-gartner-says-worldwide-iaas-public-cloud-services-market-grew-31point3-percent-in-2018>

[^6]: Online Flow Size Prediction for Improved Network Routing:
    <https://cs.uwaterloo.ca/~pjaini/downloads/main.pdf>

[^7]: This guide is currently not available publicly; ask your VMware
    representative for it.

[^8]: <https://dictionary.cambridge.org/dictionary/english/outlier>

[^9]: <https://en.wikipedia.org/wiki/Median_absolute_deviation>

[^10]: <https://en.wikipedia.org/wiki/Packet_loss>

[^11]: <https://en.wikipedia.org/wiki/Mean>

[^12]: <https://en.wikipedia.org/wiki/Standard_deviation>
